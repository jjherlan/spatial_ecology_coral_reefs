[
  {
    "objectID": "content/percent_cover.html",
    "href": "content/percent_cover.html",
    "title": "Percent Cover",
    "section": "",
    "text": "Wrote a function to create a table from betreg object that can be used in xtable()"
  },
  {
    "objectID": "content/percent_cover.html#methods-for-analyzing-percent-cover-of-pocilloporid-coral",
    "href": "content/percent_cover.html#methods-for-analyzing-percent-cover-of-pocilloporid-coral",
    "title": "Percent Cover",
    "section": "Methods for analyzing percent cover of pocilloporid coral",
    "text": "Methods for analyzing percent cover of pocilloporid coral\nOne option for dealing with the 0 and 1 values is to transform them to be slightly less than one or more than zero. This approach assumes that the data are consistent with a common beta distribution. We fit five models to the data: three variations on the beta model and two linear model approaches.\nA beta regression assuming a common spatial aggregation \\(\\delta\\) or precision parameter (\\(\\phi\\)) (object named: mod.beta1). Notice that \\(\\delta= \\frac{1}{1+\\phi}\\) and \\(\\phi=\\frac{(1-\\delta)}{\\delta}\\). A beta regression assuming each year had a different \\(\\phi\\) parameter (object named: mod.beta2).\nAnother option for modeling the data is to use a zero-one augmented beta model. Currently, the betareg package does not implement this model directly. Therefore, we follow the theoretical results shown in Ospina and Ferrari (2010) that suggest a three-part model can be fit to the data. Basically, we use logistic regression with response an indicator variable for whether or not the plot had zero recorded cover, another logistic regression with response an indicator for whether or not the plot had 100\\(\\%\\) recorded percent cover, and then the beta regression is used to model the continuous percent cover observations ranging from greater than 0 and less than 1.\nOther options based on assuming that the residuals are normally distributed is to use a linear model with a logit-transformed response (object named: mod.lmlogit) or a linear model with response untransformed proportions (object named: mod.lmraw).\nFor comparison this applies a logit-transformation to the empirical proportions and then uses a standard linear regression model.\n\np_cover_mod.aov1 <- aov(pland_decimal ~ Site, data = p_cover)\nsummary(p_cover_mod.aov1)\n\n             Df Sum Sq Mean Sq F value Pr(>F)    \nSite          2  7.342   3.671   837.5 <2e-16 ***\nResiduals   450  1.972   0.004                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\np_cover_mod.lm1 <- lm(pland_decimal ~ Site, data = p_cover)\nsummary(p_cover_mod.lm1)\n\n\nCall:\nlm(formula = pland_decimal ~ Site, data = p_cover)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.267087 -0.030588 -0.003669  0.032792  0.212867 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.015845   0.006793   2.333 0.020101 *  \nSiteman     0.036108   0.009312   3.877 0.000121 ***\nSitevhu     0.274054   0.007979  34.345  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06621 on 450 degrees of freedom\nMultiple R-squared:  0.7882,    Adjusted R-squared:  0.7873 \nF-statistic: 837.5 on 2 and 450 DF,  p-value: < 2.2e-16\n\n\n\npar(mfrow = c(2, 2))\nplot(p_cover_mod.lm1)\n\n\n\n\n\nAnova(p_cover_mod.lm1, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: pland_decimal\n            Sum Sq  Df  F value Pr(>F)    \n(Intercept) 0.0239   1   5.4417 0.0201 *  \nSite        7.3418   2 837.5053 <2e-16 ***\nResiduals   1.9724 450                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLogit-transformation\n\np_cover_mod.lm2 <- lm(logit(pland_decimal) ~ Site, data = p_cover)\nsummary(p_cover_mod.lm2)\n\n\nCall:\nlm(formula = logit(pland_decimal) ~ Site, data = p_cover)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.3048 -0.2632  0.1011  0.4540  2.4202 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -4.6747     0.1099 -42.535  < 2e-16 ***\nSiteman       1.2334     0.1507   8.186 2.81e-15 ***\nSitevhu       3.7312     0.1291  28.900  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.071 on 450 degrees of freedom\nMultiple R-squared:  0.6875,    Adjusted R-squared:  0.6862 \nF-statistic: 495.1 on 2 and 450 DF,  p-value: < 2.2e-16\n\n\n\npar(mfrow = c(2, 2))\nplot(p_cover_mod.lm2)\n\n\n\n\n\nAnova(p_cover_mod.lm2, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: logit(pland_decimal)\n             Sum Sq  Df F value    Pr(>F)    \n(Intercept) 2075.99   1  1809.2 < 2.2e-16 ***\nSite        1136.20   2   495.1 < 2.2e-16 ***\nResiduals    516.35 450                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\np_cover_mod.beta1 <- betareg(pland_decimal ~ Site, data = p_cover, link = c(\"logit\"), \n                             link.phi = NULL, type = c(\"ML\"))\n\n\np_cover_mod.beta2 <- betareg(pland_decimal ~ Site | Site, data = p_cover, link = c(\"logit\"), link.phi = NULL, type = c(\"ML\"))\n\nGeneralized-linear model\n\np_cover_mod.glm1 <- glm(pland_decimal ~ Site, family = binomial, data = p_cover)\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\nsummary(p_cover_mod.glm1)\n\n\nCall:\nglm(formula = pland_decimal ~ Site, family = binomial, data = p_cover)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-0.71274  -0.11009  -0.02114   0.09634   0.69909  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -4.1289     0.8216  -5.025 5.02e-07 ***\nSiteman       1.2248     0.9290   1.318 0.187340    \nSitevhu       3.2330     0.8333   3.880 0.000105 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 74.911  on 452  degrees of freedom\nResidual deviance: 14.405  on 450  degrees of freedom\nAIC: 191.73\n\nNumber of Fisher Scoring iterations: 7\n\n\n\npar(mfrow = c(2, 2))\nplot(p_cover_mod.glm1)\n\n\n\n\n\nAnova(p_cover_mod.glm1, type = \"III\")\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: pland_decimal\n     LR Chisq Df Pr(>Chisq)    \nSite   60.506  2  7.266e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "content/percent_cover.html#interpreting-results-for-pocilloporid-corals",
    "href": "content/percent_cover.html#interpreting-results-for-pocilloporid-corals",
    "title": "Percent Cover",
    "section": "Interpreting results for pocilloporid corals",
    "text": "Interpreting results for pocilloporid corals\nIn order to choose between the beta regression model with a common \\(\\phi\\) (Table B2) versus different \\(\\phi\\) (Table B3), I used AIC but a likelihood ratio or wald test could be used. Using AIC, the model with varying \\(\\phi\\) values had a lower AIC (-464 compared to -432) and therefore more support. We consider our simple two year or group case to explain how to interpret the output from beta regression.\nThe model we fit assumes \\[logit(\\mu_j)=\\beta_0+\\beta_1 Ind_{grp2},\\] where \\(Ind_{grp2}\\) is an indicator for group 2 and \\(j\\) denotes the group membership so \\(j=1\\) or \\(j=2\\). We have \\(logit(\\mu_2)-logit(\\mu_1)=\\beta_1\\), which is equivalent to \\[log(\\frac{\\mu_2}{1-\\mu_2})-log(\\frac{\\mu_1}{1-\\mu_1})= \\beta_1.\\]\nThe \\(\\frac{\\mu_j}{1-\\mu_j}\\) is interpreted as the odds of proportion cover in group \\(j\\). Therefore,\n\\[log(\\frac{\\mu_2}{1-\\mu_2}/\\frac{\\mu_1}{1-\\mu_1})=\\beta_1\\] is the log- odds ratio of cover in group 2 compared to group 1, \\[(\\frac{\\mu_2}{1-\\mu_2}/\\frac{\\mu_1}{1-\\mu_1})=exp(\\beta_1).\\]\nThen \\(exp(\\beta_1)\\) is the factor increase/decrease in odds of proportion cover for group 2 compared to group 1, where \\(exp(\\beta_1)>1\\) is an increase and \\(exp(\\beta_1)<1\\) is a decrease, and \\(exp(\\beta_1) \\approx 1\\) means essentially no change.\n\n\n\n\n\n\nResults from using betareg package in R by transforming the 0 and 1’s. These are on the logit-scale for \\(\\mu\\) with a common \\(\\phi\\) parameter\n\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nz value\n\n\nPr(>|z|)\n\n\n\n\n(Intercept)\n\n\n-3.713\n\n\n0.098\n\n\n-38.011\n\n\n0.000\n\n\n\n\nSiteman\n\n\n0.707\n\n\n0.117\n\n\n6.035\n\n\n0.000\n\n\n\n\nSitevhu\n\n\n2.810\n\n\n0.100\n\n\n28.024\n\n\n0.000\n\n\n\n\n(phi)\n\n\n26.253\n\n\n1.815\n\n\n14.464\n\n\n0.000\n\n\n\n\nThe function, Fcn.CreateSummary.betareg, doesn’t work with phi varying, so just fixed labels manually.\n\np_cover_mod.glm1 <- glm(pland_decimal ~ Site, family = binomial, data = p_cover)\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\nprint(xtable(summary(p_cover_mod.glm1), digits = 3, caption = \" . \"), type = \"html\")\n\n<!-- html table generated in R 4.2.2 by xtable 1.8-4 package -->\n<!-- Mon Feb 13 16:27:41 2023 -->\n<table border=1>\n<caption align=\"bottom\">  .  </caption>\n<tr> <th>  </th> <th> Estimate </th> <th> Std. Error </th> <th> z value </th> <th> Pr(&gt;|z|) </th>  </tr>\n  <tr> <td align=\"right\"> (Intercept) </td> <td align=\"right\"> -4.129 </td> <td align=\"right\"> 0.822 </td> <td align=\"right\"> -5.025 </td> <td align=\"right\"> 0.000 </td> </tr>\n  <tr> <td align=\"right\"> Siteman </td> <td align=\"right\"> 1.225 </td> <td align=\"right\"> 0.929 </td> <td align=\"right\"> 1.318 </td> <td align=\"right\"> 0.187 </td> </tr>\n  <tr> <td align=\"right\"> Sitevhu </td> <td align=\"right\"> 3.233 </td> <td align=\"right\"> 0.833 </td> <td align=\"right\"> 3.880 </td> <td align=\"right\"> 0.000 </td> </tr>\n   </table>\n\n\n\n\n\n\n\n\n.\n\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nz value\n\n\nPr(>|z|)\n\n\n\n\n(Intercept)\n\n\n-4.129\n\n\n0.822\n\n\n-5.025\n\n\n0.000\n\n\n\n\nSiteman\n\n\n1.225\n\n\n0.929\n\n\n1.318\n\n\n0.187\n\n\n\n\nSitevhu\n\n\n3.233\n\n\n0.833\n\n\n3.880\n\n\n0.000\n\n\n\n\n\n\n\n\n\nExample diagnostic plots for beta regression)\n\n\n\n\n\n\n\n\n\nExample diagnostic plots for beta regression, variable phi)\n\n\n\n\nBuilt-in diagnostic plots for linear regression models\nLogit-transformed\n\npar(mfrow = c(3, 2), pty = 'm')\nplot(p_cover_mod.lm2)\nplot(cooks.distance(p_cover_mod.lm2))\n\n\n\n\nUntransformed\n\npar(mfrow = c(3, 2), pty = 'm')\nplot(p_cover_mod.lm1)\nplot(cooks.distance(p_cover_mod.lm1))\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of default qqplots for beta and linear models. Beta models use weighted residuals 2 recommended in and linear model are the response residuals.\n\n\n\n\n\npar(mfrow = c(2,1), pty = 'm', cex = 1)\n\nplot(p_cover_mod.beta2, which = 5, type = \"sweighted2\", main = \"\")\nplot(p_cover_mod.lm2, which = 2, main = \"\")\n\n\n\n\n\nClassical Analysis\nFrom Douma & Weedon (2019)\n\n\np_cover.aov1 <- aov(pland_decimal ~ Site, data = p_cover)\nsummary(p_cover.aov1)\n##              Df Sum Sq Mean Sq F value Pr(>F)    \n## Site          2  7.342   3.671   837.5 <2e-16 ***\n## Residuals   450  1.972   0.004                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\np_cover.aov2 <- aov(pland_decimal ~ Site + Error(plot_id), data = p_cover)\nsummary(p_cover.aov2)\n## \n## Error: plot_id\n##            Df Sum Sq Mean Sq F value Pr(>F)    \n## Site        2  1.679  0.8395   157.7 <2e-16 ***\n## Residuals 247  1.315  0.0053                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Error: Within\n##            Df Sum Sq Mean Sq F value Pr(>F)    \n## Site        2  5.663  2.8317   866.2 <2e-16 ***\n## Residuals 201  0.657  0.0033                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA very similar analysis can be conducted using the library nlme for mixed effects modeling.\n\np_cover.lme1 <- lme(pland_decimal ~ Site, random = ~ 1 | plot_id, data = p_cover)\n\n\nanova(p_cover.lme1)\n\n            numDF denDF   F-value p-value\n(Intercept)     1   249 2952.9126  <.0001\nSite            2   201  920.5271  <.0001\n\n\n\np_cover.lme_null <- lme(pland_decimal ~ 1, random = ~ 1 | plot_id, data = p_cover)\n\n\nlmtest::lrtest(p_cover.lme1, p_cover.lme_null)\n\nLikelihood ratio test\n\nModel 1: pland_decimal ~ Site\nModel 2: pland_decimal ~ 1\n  #Df LogLik Df  Chisq Pr(>Chisq)    \n1   5 577.06                         \n2   3 232.95 -2 688.22  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nBeta regression with no variable precision \\(\\phi\\)\nWe now turn to the beta regression model, that models the response variable as being generated from a beta distribution (i.e. that is bounded at 0 and 1).\nThe observations of percent cover are based on replicate quadrats replicated within three experimental plots.\nWe begin by attempting to fit a beta regression model, with pland_decimal as the response, and Site as the categorical predictor.\n\np_cover.bm1 <- betareg(pland_decimal ~ Site, data = p_cover)\n\nbetareg will not accept values of 0 and 1 in the response variable.\nThere are two possible solutions here, rescaling the data to remove 0s and 1s, or fitting zero-inflated models. We start here with the rescaling solution. A suggested rescaling equation is:\n\\[ x^*_{i} = \\frac{x_i(n-1)+0.5}{n} \\]\nWhere \\(x^*_i\\) is the transformation of \\(x_i\\) and \\(n\\) is the total number of observations in the dataset.\nFor convenience we define this as a custom function tranform01 and apply it to the dataset:\n\ntransform01 <- function(x) {\n  (x * (length(x) - 1) + 0.5) / (length(x))\n}\n\nWith this scaled data we can now successfully fit the model. And test its significance relative to a null model that assumes no effect of wave power on percent cover of pocilloporid corals. For reference we also fit a classical ANOVA model assuming normally distributed errors using lm.\n\np_cover.bmnull <- betareg(pland_decimal ~ 1, data = p_cover)\nsummary(p_cover.bmnull)\n\n\nCall:\nbetareg(formula = pland_decimal ~ 1, data = p_cover)\n\nStandardized weighted residuals 2:\n    Min      1Q  Median      3Q     Max \n-5.6692 -0.7474  0.4788  0.8374  1.2399 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -1.6059     0.0546  -29.41   <2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(>|z|)    \n(phi)   4.1759     0.2831   14.75   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:   373 on 2 Df\nNumber of iterations: 11 (BFGS) + 2 (Fisher scoring) \n\n\n\np_cover.lm1 <- lm(pland_decimal ~ Site, data = p_cover)\nsummary(p_cover.lm1)\n\n\nCall:\nlm(formula = pland_decimal ~ Site, data = p_cover)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.267087 -0.030588 -0.003669  0.032792  0.212867 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.015845   0.006793   2.333 0.020101 *  \nSiteman     0.036108   0.009312   3.877 0.000121 ***\nSitevhu     0.274054   0.007979  34.345  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06621 on 450 degrees of freedom\nMultiple R-squared:  0.7882,    Adjusted R-squared:  0.7873 \nF-statistic: 837.5 on 2 and 450 DF,  p-value: < 2.2e-16\n\n\n\nlmtest::lrtest(p_cover.bm1, p_cover.bmnull)\n\nLikelihood ratio test\n\nModel 1: pland_decimal ~ Site\nModel 2: pland_decimal ~ 1\n  #Df LogLik Df  Chisq Pr(>Chisq)    \n1   4 751.26                         \n2   2 372.96 -2 756.59  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nAIC(p_cover.bm1, p_cover.lm1, p_cover.bmnull)\n\n               df        AIC\np_cover.bm1     4 -1494.5243\np_cover.lm1     4 -1169.2387\np_cover.bmnull  2  -741.9293\n\n\nAccording to the likelihood-ratio test there is a significant difference betwen the null model and the treatment model. The AIC analysis supports this conclusion, but also highlights the improved model fit with beta regression relative to normal ANOVA (lm1). From this initial analysis we would tentatively conclude that using beta regresson improves our ability to model the algal cover, but that there is no effect of grazer manipulation treatment.\nIt is useful to plot the predictions derived from the model and compare them to the observed data. First we define two new functions to allow us to use the dbeta and rbeta functions with the \\(\\mu\\) and \\(\\phi\\) parameterization.\n\n\ndbeta2 <- function(X, mu, phi, ...) {\n  dbeta(X, shape1 = mu * phi, shape2 = (1 - mu) * phi, ...)\n}\n\nrbeta2 <- function(N, mu, phi, ...) {\n  rbeta(N, shape1 = mu * phi, shape2 = (1 - mu) * phi, ...)\n}\n\n\nWith this function we can plot the distributions corresponding to the MLE parameters for each treatment :\n\n\n# extract coefficients of beta regression model\ncoefs.bm1 <- coef(p_cover.bm1)\n\n# create vector spanning the transformed 0-1 interval\n\nn.bm2 <- length(fitted(p_cover.bm1))\nx.range <- seq(0.5/n.bm2 , 1-0.5/n.bm2 , length.out = 200)\nx.range.bt <- (x.range*n.bm2 - 0.5)/(n.bm2-1)\n\n\n# Anakena\nplot(x.range.bt, dbeta2(x.range, inv.logit(coefs.bm1[\"(Intercept)\"]), coefs.bm1[\"(phi)\"]),\n     type = \"l\", lty = 2, lwd = 2,\n     ylab = \"Probability density\", xlab = \"Proportion cover\",\n     ylim=c(0, 10)\n)\n\n# Manavai\nlines(x.range.bt, dbeta2(x.range, inv.logit(coefs.bm1[\"(Intercept)\"] + coefs.bm1[2]), coefs.bm1[\"(phi)\"]),lwd = 2, col = \"red\")\n\n# Vaihu\nlines(x.range.bt, dbeta2(x.range, inv.logit(coefs.bm1[\"(Intercept)\"] + coefs.bm1[3]), coefs.bm1[\"(phi)\"]), col = \"blue\", lwd = 2)\n\nrug(p_cover$pland_decimal[p_cover$Site == \"ana\"], lwd = 1.5, pos = 10)\n\nrug(p_cover$pland_decimal[p_cover$Site == \"man\"],col=\"red\", pos = 9.75, side = 3,lwd=1.5)\n\nrug(p_cover$pland_decimal[p_cover$Site == \"vhu\"], col=\"blue\", pos = 9.5, side = 3, lwd=1.5)\n\nlegend(\"topright\", lwd = 2, lty = c(2, 1, 1, 1), col = c(\"black\", \"red\", \"blue\"), legend = c(\"Anakena\", \"Manavai\", \"Vaihu\"), bty = \"n\")\n\n\n\n\n\nWe have added the original observations as ticks of the appropriate colour, and back-transformed the densities to allow fair visual comparisons between the fitted distributions and the original data using:\n\\[ x_{i} = \\frac{x^*_in-0.5}{(n-1)} \\]\nNote that the vertical positioning of the dots is merely to prevent overplotting.\nFrom this plot we can see that the model does a reasonable job of fitting beta distributions to each of the treatment levels… And that likewise, the variance of the groups …. This can be confirmed with a residual plot, using residuals calculated relative to their predicted variance.\n\nplot(resid(p_cover.bm1) ~ fitted(p_cover.bm1))\n\n\n\n\nIs this statement accurate?\nThe spread of the standardized residuals is strongly related to the fitted values, suggesting that variance is not being adequately modeled. This observation suggests the possible utility of allowing for the precision parameter \\(\\phi\\) to vary between treatment groups. The following section will show extension of the beta regression model to allow for this.\n\n\nVariable precision \\(\\phi\\)\nWe can repeat the above analysis using a model that allows \\(\\phi\\) to vary with predictors. This is achieved by adding a second part to the right hand side of the formula, separated with the | symbol. All covariates to the right of this | symbol will be used to model \\(\\phi\\). Note that they do not have to be the same covariates used to model \\(\\mu\\) (specified to the left of the |).\n\np_cover.bm2 <- betareg(pland_decimal ~ Site | Site, data = p_cover)\n\nsummary(p_cover.bm2)\n\n\nCall:\nbetareg(formula = pland_decimal ~ Site | Site, data = p_cover)\n\nStandardized weighted residuals 2:\n    Min      1Q  Median      3Q     Max \n-6.4696 -0.3937  0.1444  0.6941  1.8854 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -4.1313     0.1005 -41.097   <2e-16 ***\nSiteman       1.2299     0.1387   8.867   <2e-16 ***\nSitevhu       3.2299     0.1041  31.012   <2e-16 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   4.1888     0.1612  25.987  < 2e-16 ***\nSiteman      -1.2182     0.2188  -5.568 2.58e-08 ***\nSitevhu      -0.9607     0.1837  -5.231 1.69e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood: 765.3 on 6 Df\nPseudo R-squared: 0.686\nNumber of iterations: 15 (BFGS) + 2 (Fisher scoring) \n\n\nFrom the Coefficients table we see that the estimate for \\(\\mu\\) in the Control treatment is inv.logit(-4.1313) = X = X% coral cover. Moreover, the estimates of \\(\\mu\\) for the other two Sites (treatments) are each significantly higher.\nFrom the Phi coefficients table we can see that the maximum likelihood estimate of the precision is highest in the Control treatment and is reduced significantly relative to this baseline in each of other treatment groups. In other words, the model fit confirms our impression from the previous two graphs that a fixed \\(\\phi\\) model overestimates variance in the Control treatment, and underestimates it in the other three treatments.\nWe can use likelihood-ratio tests to compare the new model to the fixed-\\(\\phi\\) and null models.\n\nlmtest::lrtest(p_cover.bm1, p_cover.bm2)\n\nLikelihood ratio test\n\nModel 1: pland_decimal ~ Site\nModel 2: pland_decimal ~ Site | Site\n  #Df LogLik Df  Chisq Pr(>Chisq)    \n1   4 751.26                         \n2   6 765.28  2 28.044  8.136e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlmtest::lrtest(p_cover.bmnull, p_cover.bm1, p_cover.bm2)\n\nLikelihood ratio test\n\nModel 1: pland_decimal ~ 1\nModel 2: pland_decimal ~ Site\nModel 3: pland_decimal ~ Site | Site\n  #Df LogLik Df   Chisq Pr(>Chisq)    \n1   2 372.96                          \n2   4 751.26  2 756.595  < 2.2e-16 ***\n3   6 765.28  2  28.044  8.136e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe likelihood ratio tests indicate that the model with varying \\(\\phi\\) is significantly better than both the previous fixed \\(\\phi\\) model, and the null model. In this case the conclusion is that including the model for \\(\\phi\\) led to a better fitting model than both the fixed \\(\\phi\\) model and the null model.\nIt is possible to apply post-hoc tests to identify which pariwise contrasts of treatments levels are significant.\n\ntest(pairs(emmeans(p_cover.bm2, ~ Site, mode = \"link\")))\n\n contrast  estimate     SE  df z.ratio p.value\n ana - man    -1.23 0.1387 Inf  -8.867  <.0001\n ana - vhu    -3.23 0.1041 Inf -31.012  <.0001\n man - vhu    -2.00 0.0994 Inf -20.127  <.0001\n\nResults are given on the log odds ratio (not the response) scale. \nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nWe conclude from this analysis that each Site treatment is significantly different to each other. This is an important point: correct modeling of \\(\\phi\\) can often be important for accurate inference on \\(\\mu\\).\nResidual plots confirm our conclusion that p_cover.bm2 provides a better fit to the observed data than p_cover.bm1. This is seen by the more even spread of residuals in the second plot below.\n\n\npar(mfrow = c(2, 1), oma = c(0, 0, 0, 0), mar = c(4, 4, 0.2, 0.2))\nplot(residuals(p_cover.bm1) ~ fitted(p_cover.bm1))\nplot(residuals(p_cover.bm2) ~ fitted(p_cover.bm2))\n\n\n\n\n\nAs above we can plot the MLE distributions for each of the treatments, based on the variable \\(\\phi\\) model:\n\n\n# plot distributions\nmuphi.bm2 <- unique(data.frame(\n  mu = fitted(p_cover.bm2),\n  phi = predict(p_cover.bm2, type = \"precision\"),\n  treatment = p_cover$Site\n))\n\n\n\n\nplot(x.range.bt , dbeta2(x.range, muphi.bm2[1, 1], muphi.bm2[1, 2]),\n     type=\"l\",\n     xlab = \"Proportion cover\", ylab = \"Probability density\",\n     lty = 2, lwd = 2)\n\nfor (i in 2:3) {\n  lines(x.range.bt, dbeta2(x.range, muphi.bm2[i, 1], muphi.bm2[i, 2]), col = c(\"black\", \"red\", \"blue\")[i], lty = 1, lwd = 2)\n}\n\nlegend(\"topright\", lwd = 2, lty = c(2, 1, 1, 1), col = c(\"black\", \"red\", \"blue\"), legend = c(\"Anakena\", \"Manavai\", \"Vaihu\"), bty = \"n\")\n\n\n\n\n\nDue to the much narrower variance of the Control treatment group in this model, the probability density plots of the other treatments are rather distorted. The graph below rescales the Y axis for comparison to the fixed \\(\\phi\\) model above.\n\n\nplot(x.range.bt , dbeta2(x.range, muphi.bm2[1, \"mu\"], muphi.bm2[1, \"phi\"]),\n     type=\"l\",\n     xlab = \"Proportion cover\", ylab = \"Probability density\",\n     lty = 2, lwd = 2, ylim = c(0,10))\n\nfor (i in 2:3) {\n  lines(x.range.bt, dbeta2(x.range, muphi.bm2[i, \"mu\"], muphi.bm2[i, \"phi\"]), col = c(\"black\", \"red\", \"blue\")[i], lty = 1, lwd = 2)\n}\n  \nlegend(\"topright\", lwd = 2, lty = c(2, 1, 1, 1), col = c(\"black\", \"red\", \"blue\"), legend = c(\"Anakena\", \"Manavai\", \"Vaihu\"), bty = \"n\")\n\nrug(p_cover$pland_decimal[p_cover$Site == \"ana\"], lwd = 1.5, pos = 10)\n\nrug(p_cover$pland_decimal[p_cover$Site == \"man\"], col = \"red\", pos = 9.75, side = 3,lwd = 1.5)\n\nrug(p_cover$pland_decimal[p_cover$Site == \"vhu\"], col = \"blue\", pos = 9.5, side = 3, lwd = 1.5)\n\n\n\n\n\nThese plots support the conclusion from the likelihood ratio tests above. The best-fit distributions from the variable \\(\\phi\\) model better match the observed differences in dispersion between the different groups.\n\npoci_cover <-\np_cover %>%\n  as_tibble() %>%\n#  mutate(size_cm = area*10000) %>%\n  group_by(Site) %>%\n  dplyr::summarize(mean = mean(pland_decimal), \n                   sd = sd(pland_decimal), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %>%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%\n  mutate_at(vars(Site), factor) %>%\n  add_column(\n          location = c('Anakena', 'Manavai', 'Southeast')\n          ) %>%\n  mutate_at(vars(location), factor)\n\n\npoci_cover2 <- \npoci_cover %>%\n  add_column(\n          cld = c('a', 'b', 'c')\n          ) %>%\nmutate_at(vars(cld), factor)\n\n\npoci_cover2\n\n# A tibble: 3 × 9\n  Site    mean     sd     n      se lower.ci upper.ci location  cld  \n  <fct>  <dbl>  <dbl> <int>   <dbl>    <dbl>    <dbl> <fct>     <fct>\n1 ana   0.0158 0.0128    95 0.00131   0.0132   0.0184 Anakena   a    \n2 man   0.0520 0.0512   108 0.00493   0.0422   0.0617 Manavai   b    \n3 vhu   0.290  0.0821   250 0.00519   0.280    0.300  Southeast c    \n\n\n\nx_labels = c(\"Anakena\", \"Manavai\", \"Vaihu\")\n# label_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\", \"25 m\" = \"25 m\")\n\n\npoci_cover.ggbarplot <- ggplot(poci_cover2, aes(x = location, y = mean)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", fill = \"#333399\", size = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = lower.ci, ymax = upper.ci), size = 0.75) +\n  scale_y_continuous(expression(paste(\"Mean Percent Cover (%)\")), limits = c(0, 1)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n#  scale_fill_manual(breaks = c(\"North\", \"West\",\n#                               \"Southeast\"),\n#                    values = c(\"red\", \"blue\", \n#                                    \"green\"), \n#                                    labels = c(\"North\", \"West\",\n#                                               \"Southeast\")) +\n#  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  geom_text(aes(label = cld, y = upper.ci), vjust = -0.5) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = \"top\",\n        plot.title = element_text(size = 11),\n        axis.title.y = element_text(size = 11),\n        legend.title = element_blank())\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\npoci_cover.ggbarplot"
  },
  {
    "objectID": "content/publishing.html",
    "href": "content/publishing.html",
    "title": "Publishing",
    "section": "",
    "text": "To get your Quarto webpage to show up with the url\nyou have a few steps."
  },
  {
    "objectID": "content/publishing.html#turn-on-github-pages-for-your-repo",
    "href": "content/publishing.html#turn-on-github-pages-for-your-repo",
    "title": "Publishing",
    "section": "Turn on GitHub Pages for your repo",
    "text": "Turn on GitHub Pages for your repo\n\nTurn on GitHub Pages under Settings > Pages . You will set pages to be made from the gh-pages branch and the root directory.\nTurn on GitHub Actions under Settings > Actions > General\n\nThe GitHub Action will automatically recreate your website when you push to GitHub after you do the initial gh-pages set-up"
  },
  {
    "objectID": "content/publishing.html#do-your-first-publish-to-gh-pages",
    "href": "content/publishing.html#do-your-first-publish-to-gh-pages",
    "title": "Publishing",
    "section": "Do your first publish to gh-pages",
    "text": "Do your first publish to gh-pages\nThe first time you publish to gh-pages, you need to do so locally.\n\nOn your local computer, open a terminal window and cd to your repo directory. Here is what that cd command looks like for me. You command will look different because your local repo will be somewhere else on your computer.\n\ncd ~/Documents/GitHub/NOAA-quarto-simple\n\nPublish to the gh-pages. In the terminal type\n\nquarto publish gh-pages\nThis is going to render your webpage and then push the _site contents to the gh-pages branch."
  },
  {
    "objectID": "content/publishing.html#dont-like-using-gh-pages",
    "href": "content/publishing.html#dont-like-using-gh-pages",
    "title": "Publishing",
    "section": "Don’t like using gh-pages?",
    "text": "Don’t like using gh-pages?\nIn some cases, you don’t want your website on the gh-pages branch. For example, if you are creating releases and you want the website pages archived in that release, then you won’t want your website pages on the gh-pages branch.\nHere are the changes you need to make if you to avoid gh-pages branch.\n\nAt the top of _quarto.yml add the following:\n\nproject: \n  type: website\n  output-dir: docs\n\nOn GitHub under Settings > Pages set pages to be made from the main branch and the docs directory.\nMake sure docs is not listed in .gitignore\nPublish the site the first time locally using quarto publish from the terminal\nChange the GitHub Action because you can’t use quarto publish gh-pages. You’ll need to push to the main branch yourself (in the GitHub Action)\n\non:\n  push:\n    branches: main\n\nname: Render and Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v2 \n        \n      - name: Set up R (needed for Rmd)\n        uses: r-lib/actions/setup-r@v2\n\n      - name: Install packages (needed for Rmd)\n        run: Rscript -e 'install.packages(c(\"rmarkdown\", \"knitr\", \"jsonlite\"))'\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        with:\n          # To install LaTeX to build PDF book \n          # tinytex: true \n          # uncomment below and fill to pin a version\n          # version: 0.9.600\n      \n      - name: Render Quarto Project\n        uses: quarto-dev/quarto-actions/render@v2\n        with:\n          to: html\n\n      - name: Set up Git\n        run: |\n          git config --local user.email \"actions@github.com\"\n          git config --local user.name \"GitHub Actions\"\n\n      - name: Commit all changes and push\n        run: |\n          git add -A && git commit -m 'Build site' || echo \"No changes to commit\"\n          git push origin || echo \"No changes to commit\""
  },
  {
    "objectID": "content/dispersion_presentation.html#different-patterns-of-dispersion",
    "href": "content/dispersion_presentation.html#different-patterns-of-dispersion",
    "title": "Pocilloporid Dispersion at Rapa Nui",
    "section": "Different patterns of dispersion",
    "text": "Different patterns of dispersion\n\nEnvironmental heterogeneity"
  },
  {
    "objectID": "content/rendering.html",
    "href": "content/rendering.html",
    "title": "Rendering",
    "section": "",
    "text": "The repo includes a GitHub Action that will render (build) the website automatically when you make changes to the files. It will be pushed to the gh-pages branch.\nBut when you are developing your content, you will want to render it locally."
  },
  {
    "objectID": "content/rendering.html#step-1.-make-sure-you-have-a-recent-rstudio",
    "href": "content/rendering.html#step-1.-make-sure-you-have-a-recent-rstudio",
    "title": "Rendering",
    "section": "Step 1. Make sure you have a recent RStudio",
    "text": "Step 1. Make sure you have a recent RStudio\nHave you updated RStudio since about August 2022? No? Then update to a newer version of RStudio. In general, you want to keep RStudio updated and it is required to have a recent version to use Quarto."
  },
  {
    "objectID": "content/rendering.html#step-2.-clone-and-create-rstudio-project",
    "href": "content/rendering.html#step-2.-clone-and-create-rstudio-project",
    "title": "Rendering",
    "section": "Step 2. Clone and create RStudio project",
    "text": "Step 2. Clone and create RStudio project\nFirst, clone the repo onto your local computer. How? You can click File > New Project and then select “Version Control”. Paste in the url of the repository. That will clone the repo on to your local computer. When you make changes, you will need to push those up."
  },
  {
    "objectID": "content/rendering.html#step-3.-render-within-rstudio",
    "href": "content/rendering.html#step-3.-render-within-rstudio",
    "title": "Rendering",
    "section": "Step 3. Render within RStudio",
    "text": "Step 3. Render within RStudio\nRStudio will recognize that this is a Quarto project by the presence of the _quarto.yml file and will see the “Build” tab. Click the “Render website” button to render to the _site folder.\nPreviewing: You can either click index.html in the _site folder and specify “preview in browser” or set up RStudio to preview to the viewer panel. To do the latter, go to Tools > Global Options > R Markdown. Then select “Show output preview in: Viewer panel”."
  },
  {
    "objectID": "content/code.html",
    "href": "content/code.html",
    "title": "Rendering with Code",
    "section": "",
    "text": "You can have code (R, Python or Julia) in your qmd file. You will need to have these installed on your local computer, but presumably you do already if you are adding code to your qmd files."
  },
  {
    "objectID": "content/code.html#modify-the-github-action",
    "href": "content/code.html#modify-the-github-action",
    "title": "Rendering with Code",
    "section": "Modify the GitHub Action",
    "text": "Modify the GitHub Action\nYou will need to change the GitHub Action in .github/workflows to install these and any needed packages in order for GitHub to be able to render your webpage. The GitHub Action install R since I used that in code.qmd. If you use Python or Julia instead, then you will need to update the GitHub Action to install those.\nIf getting the GitHub Action to work is too much hassle (and that definitely happens), you can alway render locally and publish to the gh-pages branch. If you do this, make sure to delete or rename the GitHub Action to something like\nrender-and-publish.old_yml\nso GitHub does not keep trying to run it. Nothing bad will happen if you don’t do this, but if you are not using the action (because it keeps failing), then you don’t need GitHub to run it."
  },
  {
    "objectID": "content/code.html#render-locally-and-publish-to-gh-pages-branch",
    "href": "content/code.html#render-locally-and-publish-to-gh-pages-branch",
    "title": "Rendering with Code",
    "section": "Render locally and publish to gh-pages branch",
    "text": "Render locally and publish to gh-pages branch\nTo render locally and push up to the gh-pages branch, open a terminal window and then cd to the directory with the Quarto project. Type this in the terminal:\nquarto render gh-pages"
  },
  {
    "objectID": "content/acknowledgements.html",
    "href": "content/acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "This repo and GitHub Action was based on the tutorial by Openscapes quarto-website-tutorial by Julia Lowndes and Stefanie Butland."
  },
  {
    "objectID": "content/rmarkdown.html",
    "href": "content/rmarkdown.html",
    "title": "R Markdown",
    "section": "",
    "text": "You can include R Markdown files in your project."
  },
  {
    "objectID": "content/rmarkdown.html#r-markdown",
    "href": "content/rmarkdown.html#r-markdown",
    "title": "R Markdown",
    "section": "R Markdown",
    "text": "R Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00"
  },
  {
    "objectID": "content/rmarkdown.html#including-plots",
    "href": "content/rmarkdown.html#including-plots",
    "title": "R Markdown",
    "section": "Including Plots",
    "text": "Including Plots\nYou can also embed plots, for example:\n\n\n\n\n\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot."
  },
  {
    "objectID": "content/customizing.html",
    "href": "content/customizing.html",
    "title": "Customization",
    "section": "",
    "text": "Quarto allow many bells and whistles to make nice output. Read the documentation here Quarto documentation."
  },
  {
    "objectID": "content/customizing.html#examples",
    "href": "content/customizing.html#examples",
    "title": "Customization",
    "section": "Examples",
    "text": "Examples\nLooking at other people’s Quarto code is a great way to figure out how to do stuff. Most will have a link to a GitHub repo where you can see the raw code. Look for a link to edit page or see source code. This will usually be on the right. Or look for the GitHub icon somewhere.\n\nQuarto gallery\nnmfs-openscapes\nFaye lab manual\nquarto-titlepages Note the link to edit is broken. Go to repo and look in documentation directory."
  },
  {
    "objectID": "content/coral_size.html",
    "href": "content/coral_size.html",
    "title": "Coral Size",
    "section": "",
    "text": "poci_size <- read.csv('coral_size.csv')\n\n\npoci_size.gg <- read_csv(\"poci_size_main.csv\")\n\nRows: 3639 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): level, Site, cover\ndbl (7): layer, class, id, area, enn, para, size_cm\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nggplot(poci_size.gg, aes(x = size_cm)) +\n  geom_histogram(fill = \"#333399\") + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(NULL) +\n  ggtitle(expression(\"Coral size \" (cm**2))) +\n  theme_bw() +\n  facet_wrap(~ Site, ncol = 1) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(size = 14), \n        axis.title.y = element_text(size = 14), \n        axis.text.y  = element_text(size= 10),\n        axis.text.x  = element_text(size = 12), \n        legend.text = element_text(size = 12),\n        legend.title = element_text(size = 12),\n        plot.title = element_text(hjust = 0.5, size = 14),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill = \"white\"),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major = element_blank(),\n        plot.background = element_rect(fill = \"white\"),\n        legend.background = element_rect(fill = \"white\"),\n        strip.text.x = element_text(size = 12, colour = \"#FFFFFF\"),\n        strip.background = element_rect(fill = '#000066')\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\npoci_size2 <-\npoci_size %>%\n  as_tibble() %>%\n  mutate(size_cm = area*10000) %>%\n  group_by(Site) %>%\n  dplyr::summarize(mean = mean(size_cm), \n                   sd = sd(size_cm), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %>%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%\n  mutate_at(vars(Site), factor) %>%\n  add_column(\n          location = c('Anakena', 'Manavai', 'Southeast')\n          ) %>%\n  mutate_at(vars(location), factor)\n\n\npoci_size.gg <-\n  poci_size %>%\n  mutate(size_cm = area*10000) %>%\n  as_tibble() %>%\n  mutate_at(vars(Site), factor)\n\n\nmodel_1.lm <- lm(size_cm ~ Site, data = poci_size.gg)\n\n\nmodel_1.lm\n\n\nCall:\nlm(formula = size_cm ~ Site, data = poci_size.gg)\n\nCoefficients:\n(Intercept)      Siteman      Sitevhu  \n     110.67        40.18       120.81  \n\n\n\nsummary(model_1.lm)\n\n\nCall:\nlm(formula = size_cm ~ Site, data = poci_size.gg)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-231.46  -91.09  -16.44   70.33 1160.47 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   110.67      11.18   9.896  < 2e-16 ***\nSiteman        40.18      13.07   3.074  0.00212 ** \nSitevhu       120.81      11.42  10.575  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 130.4 on 3636 degrees of freedom\nMultiple R-squared:  0.05804,   Adjusted R-squared:  0.05752 \nF-statistic:   112 on 2 and 3636 DF,  p-value: < 2.2e-16\n\n\n\npar(mfrow = c(2, 2))\nplot(model_1.lm)\n\n\n\n\n\nAnova(model_1.lm, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: size_cm\n              Sum Sq   Df F value    Pr(>F)    \n(Intercept)  1665764    1  97.933 < 2.2e-16 ***\nSite         3810826    2 112.022 < 2.2e-16 ***\nResiduals   61845547 3636                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\npost_hoc.model_1.lm <- glht(model_1.lm, linfct = mcp(Site = 'Tukey'))\n\n\nmodel_1.aov <- aov(size_cm ~ Site, data = poci_size.gg)\n\n\n# Tukey's test\ntukey <- TukeyHSD(model_1.aov)\n\n\n# compact letter display\ncld <- multcompLetters4(model_1.aov, tukey)\n\n\ncld\n\n$Site\nvhu man ana \n\"a\" \"b\" \"c\" \n\n\n\npoci_size3 <- \npoci_size2 %>%\n  add_column(\n          cld = c('a', 'b', 'c')\n          ) %>%\nmutate_at(vars(cld), factor)\n\n\npoci_size3\n\n# A tibble: 3 × 9\n  Site   mean    sd     n    se lower.ci upper.ci location  cld  \n  <fct> <dbl> <dbl> <int> <dbl>    <dbl>    <dbl> <fct>     <fct>\n1 ana    111.  73.8   136  6.33     98.2     123. Anakena   a    \n2 man    151.  82.7   372  4.29    142.      159. Manavai   b    \n3 vhu    231. 137.   3131  2.44    227.      236. Southeast c    \n\n\n\nx_labels = c(\"Anakena\", \"Manavai\", \"Vaihu\")\n# label_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\", \"25 m\" = \"25 m\")\n\n\npoci_size.gg.barplot <- ggplot(poci_size3, aes(x = location, y = mean)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", fill = \"#333399\", size = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = lower.ci, ymax = upper.ci), size = 0.75) +\n  scale_y_continuous(expression(paste(\"Mean Colony Size (\",\" \", cm^2, \")\")), limits = c(0, 300)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n#  scale_fill_manual(breaks = c(\"North\", \"West\",\n#                               \"Southeast\"),\n#                    values = c(\"red\", \"blue\", \n#                                    \"green\"), \n#                                    labels = c(\"North\", \"West\",\n#                                               \"Southeast\")) +\n#  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  geom_text(aes(label = cld, y = upper.ci), vjust = -0.5) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = \"top\",\n        plot.title = element_text(size = 11),\n        axis.title.y = element_text(size = 11),\n        legend.title = element_blank())\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\npoci_size.gg.barplot"
  },
  {
    "objectID": "content/add-content.html",
    "href": "content/add-content.html",
    "title": "Customize",
    "section": "",
    "text": "Edit the qmd or md files in the content folder. qmd files can include code (R, Python, Julia) and lots of Quarto markdown bells and whistles (like call-outs, cross-references, auto-citations and much more).\nEach page should start with\n---\ntitle: your title\n---\nand the first header will be the 2nd level, so ##. Note, there are situations where you leave off\n---\ntitle: your title\n---\nand start the qmd file with a level header #, but if using the default title yaml (in the --- fence) is a good habit since it makes it easy for Quarto convert your qmd file to other formats (like into a presentation)."
  },
  {
    "objectID": "content/add-content.html#add-your-pages-the-project",
    "href": "content/add-content.html#add-your-pages-the-project",
    "title": "Customize",
    "section": "Add your pages the project",
    "text": "Add your pages the project\n\nAdd the files to _quarto.yml"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NOAA quarto simple with R",
    "section": "",
    "text": "This is a template for a simple Quarto website that looks like a “book”. This is a common format for documentation. It includes a GitHub Action that will build the website automatically when you make changes to the files. The NOAA palette and fonts has been added to theme.scss. The webpage will be on the gh-pages branch. Serving the website files from this branch is a common way to keep all the website files from cluttering your main branch.\nThe GitHub Action installs R so you can have R code in your qmd or Rmd files. Note, you do not need to make changes to your Rmd files unless your need Quarto features like cross-references."
  },
  {
    "objectID": "index.html#github-set-up",
    "href": "index.html#github-set-up",
    "title": "NOAA quarto simple with R",
    "section": "GitHub Set-up",
    "text": "GitHub Set-up\n\nClick the green “use template” button to make a repository with this content. Make sure to make your repo public (since GitHub Pages doesn’t work on private repos unless you have a paid account) and check box to include all the branches (so that you get the gh-pages branch). \nTurn on GitHub Pages under Settings > Pages . You will set pages to be made from the gh-pages branch and root directory. \nTurn on GitHub Actions under Settings > Actions > General \nEdit the repo description and Readme to add a link to the webpage. When you edit the description, you will see the link url in the url box or you can click on the Actions tab or the Settings > Pages page to find the url."
  }
]