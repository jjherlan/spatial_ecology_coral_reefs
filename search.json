[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NOAA quarto simple with R",
    "section": "",
    "text": "This is a template for a simple Quarto website that looks like a “book”. This is a common format for documentation. It includes a GitHub Action that will build the website automatically when you make changes to the files. The NOAA palette and fonts has been added to theme.scss. The webpage will be on the gh-pages branch. Serving the website files from this branch is a common way to keep all the website files from cluttering your main branch.\nThe GitHub Action installs R so you can have R code in your qmd or Rmd files. Note, you do not need to make changes to your Rmd files unless your need Quarto features like cross-references."
  },
  {
    "objectID": "index.html#github-set-upp",
    "href": "index.html#github-set-upp",
    "title": "NOAA quarto simple with R",
    "section": "GitHub Set-upp",
    "text": "GitHub Set-upp\n\nClick the green “use template” button to make a repository with this content. Make sure to make your repo public (since GitHub Pages doesn’t work on private repos unless you have a paid account) and check box to include all the branches (so that you get the gh-pages branch). \nTurn on GitHub Pages under Settings &gt; Pages . You will set pages to be made from the gh-pages branch and root directory. \nTurn on GitHub Actions under Settings &gt; Actions &gt; General \nEdit the repo description and Readme to add a link to the webpage. When you edit the description, you will see the link url in the url box or you can click on the Actions tab or the Settings &gt; Pages page to find the url."
  },
  {
    "objectID": "content/bleaching.html",
    "href": "content/bleaching.html",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "",
    "text": "rpn_plob\n\n# A tibble: 12 × 8\n   location depth transect group total_count total_points cover failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;       &lt;int&gt;        &lt;int&gt; &lt;dbl&gt;    &lt;int&gt;\n 1 north    dp    one      PLOB          104          126 0.825       22\n 2 north    dp    two      PLOB          113          126 0.897       13\n 3 north    sh    one      PLOB           83          126 0.659       43\n 4 north    sh    two      PLOB           88          126 0.698       38\n 5 se       dp    one      PLOB           34          124 0.274       90\n 6 se       dp    two      PLOB           28          105 0.267       77\n 7 se       sh    one      PLOB           35          126 0.278       91\n 8 se       sh    two      PLOB           15          126 0.119      111\n 9 west     dp    one      PLOB           89          126 0.706       37\n10 west     dp    two      PLOB           73          126 0.579       53\n11 west     sh    one      PLOB           74          126 0.587       52\n12 west     sh    two      PLOB          101          126 0.802       25"
  },
  {
    "objectID": "content/bleaching.html#porites",
    "href": "content/bleaching.html#porites",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Porites",
    "text": "Porites\n\nGeneralized linear model\n\nplob.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_plob)\n\n\npar(mfrow = c(2, 2))\nplot(plob.glm)\n\n\n\n\n\nsummary(plob.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_plob)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            1.8245     0.1822  10.017  &lt; 2e-16 ***\nlocationse            -2.8154     0.2352 -11.973  &lt; 2e-16 ***\nlocationwest          -1.2368     0.2246  -5.506 3.68e-08 ***\ndepthsh               -1.0773     0.2267  -4.753 2.00e-06 ***\nlocationse:depthsh     0.6719     0.3138   2.142   0.0322 *  \nlocationwest:depthsh   1.3105     0.2956   4.434 9.25e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 396.020  on 11  degrees of freedom\nResidual deviance:  31.694  on  6  degrees of freedom\nAIC: 102.95\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nAnova(plob.glm, type = 'III')\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(total_count, failures)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        186.616  2  &lt; 2.2e-16 ***\ndepth            24.219  1  8.599e-07 ***\nlocation:depth   20.391  2  3.735e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_plob$groups &lt;- interaction(rpn_plob$location, rpn_plob$depth)"
  },
  {
    "objectID": "content/bleaching.html#create-a-post-hoc-model",
    "href": "content/bleaching.html#create-a-post-hoc-model",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_plob &lt;- with(rpn_plob, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest",
    "href": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_plob, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (north.dp) = 0\",\n                       \"(west.sh) - (west.dp) = 0\",\n                       \"(se.sh) - (se.dp) = 0\",\n                       \"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (north.dp) == 0 -1.07733    0.22666  -4.753 1.20e-05 ***\n(west.sh) - (west.dp) == 0    0.23319    0.18970   1.229    0.657    \n(se.sh) - (se.dp) == 0       -0.40539    0.21695  -1.869    0.247    \n(north.sh) - (west.sh) == 0  -0.07377    0.19208  -0.384    0.795    \n(north.sh) - (west.dp) == 0   0.15943    0.18835   0.846    0.795    \n(north.sh) - (se.sh) == 0     2.14346    0.20771  10.319  &lt; 2e-16 ***\n(north.sh) - (se.dp) == 0     1.73807    0.20078   8.657  &lt; 2e-16 ***\n(north.dp) - (west.sh) == 0   1.00357    0.22777   4.406 5.27e-05 ***\n(north.dp) - (west.dp) == 0   1.23676    0.22464   5.506 2.58e-07 ***\n(north.dp) - (se.sh) == 0     3.22079    0.24110  13.359  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0     2.81541    0.23515  11.973  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0     -2.21723    0.20893 -10.612  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0     -1.98403    0.20551  -9.654  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0     -1.81184    0.20204  -8.968  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0     -1.57865    0.19850  -7.953 1.42e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nplob_mult &lt;- summary(glht(model_plob, \n             linfct = mcp(groups = \"Tukey\")), test = adjusted(\"holm\"))\n\n\nletter_display &lt;- cld(plob_mult)\n\n\nletter_display\n\nnorth.dp    se.dp  west.dp north.sh    se.sh  west.sh \n     \"a\"      \"b\"      \"c\"      \"c\"      \"b\"      \"c\" \n\n\n\nwith(rpn_plob, interaction.plot(location, depth, cover))"
  },
  {
    "objectID": "content/bleaching.html#create-a-post-hoc-model-1",
    "href": "content/bleaching.html#create-a-post-hoc-model-1",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_plob_pale &lt;- with(rpn_plob_pale.main, glm(cbind(total_count, failures) ~ groups, family = binomial))\n\n\nmodel_plob_pale\n\n\nCall:  glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nCoefficients:\n   (Intercept)     groupsse.dp   groupswest.dp  groupsnorth.sh     groupsse.sh  \n        0.2071         -2.4132         -2.0997         -1.2638         -1.9355  \n groupswest.sh  \n       -1.3702  \n\nDegrees of Freedom: 11 Total (i.e. Null);  6 Residual\nNull Deviance:      295.6 \nResidual Deviance: 119.2    AIC: 185.7"
  },
  {
    "objectID": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-1",
    "href": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-1",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_plob_pale, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (north.dp) = 0\",\n                       \"(west.sh) - (west.dp) = 0\",\n                       \"(se.sh) - (se.dp) = 0\",\n                       \"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (north.dp) == 0  -1.2638     0.1918  -6.590 4.83e-10 ***\n(west.sh) - (west.dp) == 0     0.7294     0.2382   3.062 0.015388 *  \n(se.sh) - (se.dp) == 0         0.4777     0.2746   1.740 0.327651    \n(north.sh) - (west.sh) == 0    0.1064     0.2064   0.516 1.000000    \n(north.sh) - (west.dp) == 0    0.8358     0.2358   3.545 0.003144 ** \n(north.sh) - (se.sh) == 0      0.6717     0.2274   2.953 0.018858 *  \n(north.sh) - (se.dp) == 0      1.1494     0.2552   4.503 6.69e-05 ***\n(north.dp) - (west.sh) == 0    1.3702     0.1947   7.037 2.36e-11 ***\n(north.dp) - (west.dp) == 0    2.0997     0.2256   9.305  &lt; 2e-16 ***\n(north.dp) - (se.sh) == 0      1.9355     0.2169   8.925  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0      2.4132     0.2459   9.815  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0      -0.5652     0.2299  -2.458 0.069778 .  \n(se.sh) - (west.dp) == 0       0.1642     0.2566   0.640 1.000000    \n(se.dp) - (west.sh) == 0      -1.0429     0.2574  -4.051 0.000459 ***\n(se.dp) - (west.dp) == 0      -0.3135     0.2816  -1.113 0.796500    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)"
  },
  {
    "objectID": "content/bleaching.html#pocillopora",
    "href": "content/bleaching.html#pocillopora",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Pocillopora",
    "text": "Pocillopora\n\nrpn_poci_bleach &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'BL') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_bleach\n\n# A tibble: 6 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                1\n2 se       dp    one                1\n3 se       dp    two                2\n4 se       sh    two                1\n5 west     dp    one                4\n6 west     sh    two                2\n\n\n\nrpn_poci_bleach2 &lt;-\nas.data.frame(rpn_poci_bleach) %&gt;%\n  add_row(location = 'north', depth = 'sh', transect = 'one', total_count = 0) %&gt;%\n  add_row(location = 'north', depth = 'sh', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'north', depth = 'dp', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'west', depth = 'sh', transect = 'one', total_count = 0) %&gt;%\n  add_row(location = 'west', depth = 'dp', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'se', depth = 'sh', transect = 'two', total_count = 0)\n\n\nrpn_poci_bleach2\n\n   location depth transect total_count\n1     north    dp      one           1\n2        se    dp      one           1\n3        se    dp      two           2\n4        se    sh      two           1\n5      west    dp      one           4\n6      west    sh      two           2\n7     north    sh      one           0\n8     north    sh      two           0\n9     north    dp      two           0\n10     west    sh      one           0\n11     west    dp      two           0\n12       se    sh      two           0\n\n\n\nrpn_poci_bleach.main &lt;- rpn_poci_bleach2 %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_poci_bleach.main \n\n   location depth transect total_count       cover failures\n1     north    dp      one           1 0.007936508      125\n2        se    dp      one           1 0.007936508      125\n3        se    dp      two           2 0.015873016      124\n4        se    sh      two           1 0.007936508      125\n5      west    dp      one           4 0.031746032      122\n6      west    sh      two           2 0.015873016      124\n7     north    sh      one           0 0.000000000      126\n8     north    sh      two           0 0.000000000      126\n9     north    dp      two           0 0.000000000      126\n10     west    sh      one           0 0.000000000      126\n11     west    dp      two           0 0.000000000      126\n12       se    sh      two           0 0.000000000      126\n\n\n\nrpn_poci_pb &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'PB') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_pb\n\n# A tibble: 8 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                2\n2 north    dp    two                1\n3 se       dp    one               27\n4 se       dp    two                9\n5 se       sh    one                2\n6 se       sh    two                5\n7 west     dp    two                2\n8 west     sh    one                1\n\n\n\nrpn_poci_pb2 &lt;-\nas.data.frame(rpn_poci_pb) %&gt;%\n  add_row(location = 'north', depth = 'sh', transect = 'one', total_count = 0) %&gt;%\n  add_row(location = 'north', depth = 'sh', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'west', depth = 'sh', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'west', depth = 'dp', transect = 'one', total_count = 0)\n\n\nrpn_poci_pb2\n\n   location depth transect total_count\n1     north    dp      one           2\n2     north    dp      two           1\n3        se    dp      one          27\n4        se    dp      two           9\n5        se    sh      one           2\n6        se    sh      two           5\n7      west    dp      two           2\n8      west    sh      one           1\n9     north    sh      one           0\n10    north    sh      two           0\n11     west    sh      two           0\n12     west    dp      one           0\n\n\n\nrpn_poci_pb.main &lt;- rpn_poci_pb2 %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_poci_pb.main \n\n   location depth transect total_count       cover failures\n1     north    dp      one           2 0.015873016      124\n2     north    dp      two           1 0.007936508      125\n3        se    dp      one          27 0.214285714       99\n4        se    dp      two           9 0.071428571      117\n5        se    sh      one           2 0.015873016      124\n6        se    sh      two           5 0.039682540      121\n7      west    dp      two           2 0.015873016      124\n8      west    sh      one           1 0.007936508      125\n9     north    sh      one           0 0.000000000      126\n10    north    sh      two           0 0.000000000      126\n11     west    sh      two           0 0.000000000      126\n12     west    dp      one           0 0.000000000      126\n\n\n\nrpn_poci_pale &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'P') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_pale\n\n# A tibble: 10 × 4\n# Groups:   location, depth [5]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one                3\n 2 north    dp    two                1\n 3 se       dp    one               19\n 4 se       dp    two               16\n 5 se       sh    one               59\n 6 se       sh    two               45\n 7 west     dp    one                7\n 8 west     dp    two                8\n 9 west     sh    one               13\n10 west     sh    two                9\n\n\n\nrpn_poci_pale2 &lt;-\nas.data.frame(rpn_poci_pale) %&gt;%\n  add_row(location = 'north', depth = 'sh', transect = 'one', total_count = 0) %&gt;%\n  add_row(location = 'north', depth = 'sh', transect = 'two', total_count = 0)\n\n\nrpn_poci_pale2\n\n   location depth transect total_count\n1     north    dp      one           3\n2     north    dp      two           1\n3        se    dp      one          19\n4        se    dp      two          16\n5        se    sh      one          59\n6        se    sh      two          45\n7      west    dp      one           7\n8      west    dp      two           8\n9      west    sh      one          13\n10     west    sh      two           9\n11    north    sh      one           0\n12    north    sh      two           0\n\n\n\nrpn_poci_pale.main &lt;- rpn_poci_pale2 %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_poci_pale.main \n\n   location depth transect total_count       cover failures\n1     north    dp      one           3 0.023809524      123\n2     north    dp      two           1 0.007936508      125\n3        se    dp      one          19 0.150793651      107\n4        se    dp      two          16 0.126984127      110\n5        se    sh      one          59 0.468253968       67\n6        se    sh      two          45 0.357142857       81\n7      west    dp      one           7 0.055555556      119\n8      west    dp      two           8 0.063492063      118\n9      west    sh      one          13 0.103174603      113\n10     west    sh      two           9 0.071428571      117\n11    north    sh      one           0 0.000000000      126\n12    north    sh      two           0 0.000000000      126\n\n\n\nrpn_poci_healthy &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'H') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_healthy\n\n# A tibble: 9 × 4\n# Groups:   location, depth [6]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                1\n2 north    sh    two                1\n3 se       dp    one               10\n4 se       sh    one               14\n5 se       sh    two                9\n6 west     dp    one                2\n7 west     dp    two                4\n8 west     sh    one                1\n9 west     sh    two                7\n\n\n\nrpn_poci_healthy2 &lt;-\nas.data.frame(rpn_poci_healthy) %&gt;%\n  add_row(location = 'north', depth = 'sh', transect = 'one', total_count = 0) %&gt;%\n  add_row(location = 'north', depth = 'dp', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'se', depth = 'dp', transect = 'two', total_count = 0)\n\n\nrpn_poci_healthy.main &lt;- rpn_poci_healthy2 %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_poci_healthy.main\n\n   location depth transect total_count       cover failures\n1     north    dp      one           1 0.007936508      125\n2     north    sh      two           1 0.007936508      125\n3        se    dp      one          10 0.079365079      116\n4        se    sh      one          14 0.111111111      112\n5        se    sh      two           9 0.071428571      117\n6      west    dp      one           2 0.015873016      124\n7      west    dp      two           4 0.031746032      122\n8      west    sh      one           1 0.007936508      125\n9      west    sh      two           7 0.055555556      119\n10    north    sh      one           0 0.000000000      126\n11    north    dp      two           0 0.000000000      126\n12       se    dp      two           0 0.000000000      126\n\n\n\nGeneralized linear model\n\nrpn_poci\n\n# A tibble: 12 × 8\n   location depth transect group total_count total_points   cover failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;       &lt;int&gt;        &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;\n 1 north    dp    one      POCI            7          126 0.0556       119\n 2 north    dp    two      POCI            2          126 0.0159       124\n 3 north    sh    one      POCI            0          126 0            126\n 4 north    sh    two      POCI            1          126 0.00794      125\n 5 se       dp    one      POCI           57          124 0.460         67\n 6 se       dp    two      POCI           58          105 0.552         47\n 7 se       sh    one      POCI           75          126 0.595         51\n 8 se       sh    two      POCI           60          126 0.476         66\n 9 west     dp    one      POCI           13          126 0.103        113\n10 west     dp    two      POCI           14          126 0.111        112\n11 west     sh    one      POCI           15          126 0.119        111\n12 west     sh    two      POCI           18          126 0.143        108\n\n\n\npoci.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                family = binomial(link = \"logit\"), \n                data = rpn_poci)\n\n\npar(mfrow = c(2, 2))\nplot(poci.glm)\n\n\n\n\n\nsummary(poci.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_poci)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -3.2958     0.3395  -9.709  &lt; 2e-16 ***\nlocationse             3.3046     0.3643   9.072  &lt; 2e-16 ***\nlocationwest           1.1756     0.3959   2.970  0.00298 ** \ndepthsh               -2.2296     1.0579  -2.108  0.03507 *  \nlocationse:depthsh     2.3640     1.0736   2.202  0.02767 *  \nlocationwest:depthsh   2.4573     1.0934   2.247  0.02462 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 436.578  on 11  degrees of freedom\nResidual deviance:  10.347  on  6  degrees of freedom\nAIC: 69.293\n\nNumber of Fisher Scoring iterations: 5\n\n\nAnova function from the car package\n\nAnova(poci.glm, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(total_count, failures)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        178.902  2  &lt; 2.2e-16 ***\ndepth             7.491  1   0.006201 ** \nlocation:depth    8.513  2   0.014171 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_poci$groups &lt;- interaction(rpn_poci$location, rpn_poci$depth)"
  },
  {
    "objectID": "content/bleaching.html#create-a-post-hoc-model-2",
    "href": "content/bleaching.html#create-a-post-hoc-model-2",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_poci &lt;- with(rpn_poci, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-2",
    "href": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-2",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_poci, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  -3.6329     1.0192  -3.564  0.00117 ** \n(north.sh) - (west.dp) == 0  -3.4052     1.0225  -3.330  0.00173 ** \n(north.sh) - (se.sh) == 0    -5.6686     1.0099  -5.613 1.19e-07 ***\n(north.sh) - (se.dp) == 0    -5.5342     1.0107  -5.476 2.18e-07 ***\n(north.dp) - (west.sh) == 0  -1.4033     0.3874  -3.622  0.00117 ** \n(north.dp) - (west.dp) == 0  -1.1756     0.3959  -2.970  0.00298 ** \n(north.dp) - (se.sh) == 0    -3.4389     0.3622  -9.495  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0    -3.3046     0.3643  -9.072  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0      2.0357     0.2254   9.030  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0      2.2634     0.2397   9.444  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0      1.9013     0.2288   8.311  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0      2.1290     0.2428   8.769  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_poci_bleach &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'BL') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_bleach\n\n# A tibble: 6 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                1\n2 se       dp    one                1\n3 se       dp    two                2\n4 se       sh    two                1\n5 west     dp    one                4\n6 west     sh    two                2\n\n\n\nrpn_poci_pb &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'PB') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_pb\n\n# A tibble: 8 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                2\n2 north    dp    two                1\n3 se       dp    one               27\n4 se       dp    two                9\n5 se       sh    one                2\n6 se       sh    two                5\n7 west     dp    two                2\n8 west     sh    one                1\n\n\n\nrpn_poci_pale &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'P') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_pale\n\n# A tibble: 10 × 4\n# Groups:   location, depth [5]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one                3\n 2 north    dp    two                1\n 3 se       dp    one               19\n 4 se       dp    two               16\n 5 se       sh    one               59\n 6 se       sh    two               45\n 7 west     dp    one                7\n 8 west     dp    two                8\n 9 west     sh    one               13\n10 west     sh    two                9\n\n\n\nrpn_poci_healthy &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'H') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_healthy\n\n# A tibble: 9 × 4\n# Groups:   location, depth [6]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                1\n2 north    sh    two                1\n3 se       dp    one               10\n4 se       sh    one               14\n5 se       sh    two                9\n6 west     dp    one                2\n7 west     dp    two                4\n8 west     sh    one                1\n9 west     sh    two                7"
  },
  {
    "objectID": "content/bleaching.html#examine-bleaching-response-of-coral-groups",
    "href": "content/bleaching.html#examine-bleaching-response-of-coral-groups",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Examine bleaching response of coral groups",
    "text": "Examine bleaching response of coral groups\n\nPorites\n\nrpn_bleach &lt;- read.csv('rpn_coral_bleach.csv') %&gt;%\n  as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  mutate_at(vars(location, depth, transect, species), factor) %&gt;%\n  mutate(\n  bl = coral_count - bl_count,\n  pb = coral_count - pb_count,\n  p  = coral_count - p_count,\n  h  = coral_count - h_count,\n    )\n\n\nrpn_bleach\n\n# A tibble: 24 × 13\n   species location depth transect bl_count pb_count p_count h_count coral_count\n   &lt;fct&gt;   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;       &lt;int&gt;    &lt;int&gt;   &lt;int&gt;   &lt;int&gt;       &lt;int&gt;\n 1 plob    north    dp    one             0        5      87      12         104\n 2 plob    north    dp    two             0       49      52      12         113\n 3 plob    north    sh    one             0       40      28      15          83\n 4 plob    north    sh    two             0       31      37      20          88\n 5 plob    se       dp    one             0        0      23      11          34\n 6 plob    se       dp    two             0        2       2       0          28\n 7 plob    se       sh    one             0        0      29       6          35\n 8 plob    se       sh    two             0        0       9       6          15\n 9 plob    west     dp    one             0       70      17       2          89\n10 plob    west     dp    two             0       55      16       2          73\n# ℹ 14 more rows\n# ℹ 4 more variables: bl &lt;int&gt;, pb &lt;int&gt;, p &lt;int&gt;, h &lt;int&gt;\n\n\n\nplob_bleach &lt;- rpn_bleach %&gt;%\n  filter(species == \"plob\")\n\n\nplob_bleach\n\n# A tibble: 12 × 13\n   species location depth transect bl_count pb_count p_count h_count coral_count\n   &lt;fct&gt;   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;       &lt;int&gt;    &lt;int&gt;   &lt;int&gt;   &lt;int&gt;       &lt;int&gt;\n 1 plob    north    dp    one             0        5      87      12         104\n 2 plob    north    dp    two             0       49      52      12         113\n 3 plob    north    sh    one             0       40      28      15          83\n 4 plob    north    sh    two             0       31      37      20          88\n 5 plob    se       dp    one             0        0      23      11          34\n 6 plob    se       dp    two             0        2       2       0          28\n 7 plob    se       sh    one             0        0      29       6          35\n 8 plob    se       sh    two             0        0       9       6          15\n 9 plob    west     dp    one             0       70      17       2          89\n10 plob    west     dp    two             0       55      16       2          73\n11 plob    west     sh    one             0       64       5       0          71\n12 plob    west     sh    two             0       46      55       5         101\n# ℹ 4 more variables: bl &lt;int&gt;, pb &lt;int&gt;, p &lt;int&gt;, h &lt;int&gt;\n\n\n\nplob_pb.glm &lt;- glm(cbind(pb_count, pb) ~ location * depth, \n                family = binomial(link = \"logit\"), \n                data = plob_bleach)\n\n\npar(mfrow = c(2, 2))\nplot(plob_pb.glm)\n\n\n\n\n\nsummary(plob_pb.glm)\n\n\nCall:\nglm(formula = cbind(pb_count, pb) ~ location * depth, family = binomial(link = \"logit\"), \n    data = plob_bleach)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -1.1048     0.1570  -7.036 1.98e-12 ***\nlocationse             -2.2964     0.7357  -3.121 0.001801 ** \nlocationwest            2.3222     0.2443   9.506  &lt; 2e-16 ***\ndepthsh                 0.7623     0.2208   3.453 0.000555 ***\nlocationse:depthsh    -17.2555  1792.1996  -0.010 0.992318    \nlocationwest:depthsh   -1.4063     0.3301  -4.260 2.04e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 344.520  on 11  degrees of freedom\nResidual deviance:  95.151  on  6  degrees of freedom\nAIC: 145.78\n\nNumber of Fisher Scoring iterations: 16\n\n\nAnova function from the car package\n\nAnova(plob_pb.glm, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(pb_count, pb)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        161.859  2  &lt; 2.2e-16 ***\ndepth            12.092  1  0.0005065 ***\nlocation:depth   21.115  2    2.6e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nplob_pb.aov &lt;- Anova(plob_pb.glm, type = \"III\") # Type III because...\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nplob_bleach$groups &lt;- interaction(plob_bleach$location, plob_bleach$depth)"
  },
  {
    "objectID": "content/bleaching.html#create-a-post-hoc-model-3",
    "href": "content/bleaching.html#create-a-post-hoc-model-3",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_plob_bleach &lt;- with(plob_bleach, glm(cbind(pb_count, pb) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-3",
    "href": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-3",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_plob_bleach, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(pb_count, pb) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0   -0.9158     0.2220  -4.125 0.000223 ***\n(north.sh) - (west.dp) == 0   -1.5599     0.2431  -6.416 1.40e-09 ***\n(north.sh) - (se.sh) == 0     19.5519  1792.1994   0.011 1.000000    \n(north.sh) - (se.dp) == 0      3.0587     0.7354   4.159 0.000223 ***\n(north.dp) - (west.sh) == 0   -1.6781     0.2233  -7.514 6.30e-13 ***\n(north.dp) - (west.dp) == 0   -2.3222     0.2443  -9.506  &lt; 2e-16 ***\n(north.dp) - (se.sh) == 0     18.7897  1792.1994   0.010 1.000000    \n(north.dp) - (se.dp) == 0      2.2964     0.7357   3.121 0.009005 ** \n(se.sh) - (west.sh) == 0     -20.4678  1792.1994  -0.011 1.000000    \n(se.sh) - (west.dp) == 0     -21.1118  1792.1994  -0.012 1.000000    \n(se.dp) - (west.sh) == 0      -3.9745     0.7361  -5.399 5.35e-07 ***\n(se.dp) - (west.dp) == 0      -4.6186     0.7428  -6.218 4.53e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\nPLOB pale\n\nplob_pale.glm &lt;- glm(cbind(p_count, p) ~ location * depth, \n                family = binomial(link = \"logit\"), \n                data = plob_bleach)\n\n\npar(mfrow = c(2, 2))\nplot(plob_pale.glm)\n\n\n\n\n\nsummary(plob_pale.glm)\n\n\nCall:\nglm(formula = cbind(p_count, p) ~ location * depth, family = binomial(link = \"logit\"), \n    data = plob_bleach)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            0.5778     0.1415   4.084 4.43e-05 ***\nlocationse            -0.9698     0.2950  -3.287  0.00101 ** \nlocationwest          -1.9411     0.2410  -8.055 7.95e-16 ***\ndepthsh               -1.0668     0.2117  -5.038 4.70e-07 ***\nlocationse:depthsh     2.6115     0.4706   5.549 2.88e-08 ***\nlocationwest:depthsh   1.8060     0.3294   5.483 4.18e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 217.65  on 11  degrees of freedom\nResidual deviance: 112.66  on  6  degrees of freedom\nAIC: 174.36\n\nNumber of Fisher Scoring iterations: 4\n\n\nAnova function from the car package\n\nAnova(plob_pale.glm, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(p_count, p)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation         75.499  2  &lt; 2.2e-16 ***\ndepth            26.276  1  2.959e-07 ***\nlocation:depth   49.739  2  1.583e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nplob_pale.aov &lt;- Anova(plob_pale.glm, type = \"III\") # Type III because...\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nplob_bleach$groups &lt;- interaction(plob_bleach$location, plob_bleach$depth)"
  },
  {
    "objectID": "content/bleaching.html#create-a-post-hoc-model-4",
    "href": "content/bleaching.html#create-a-post-hoc-model-4",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_plob_pale &lt;- with(plob_bleach, glm(cbind(p_count, p) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-4",
    "href": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-4",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_plob_pale, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(p_count, p) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  0.13510    0.22453   0.602  1.00000    \n(north.sh) - (west.dp) == 0  0.87425    0.25075   3.487  0.00342 ** \n(north.sh) - (se.sh) == 0   -1.64173    0.36670  -4.477 6.05e-05 ***\n(north.sh) - (se.dp) == 0   -0.09701    0.30306  -0.320  1.00000    \n(north.dp) - (west.sh) == 0  1.20192    0.21356   5.628 1.82e-07 ***\n(north.dp) - (west.dp) == 0  1.94107    0.24098   8.055 1.07e-14 ***\n(north.dp) - (se.sh) == 0   -0.57491    0.36009  -1.597  0.44143    \n(north.dp) - (se.dp) == 0    0.96981    0.29503   3.287  0.00607 ** \n(se.sh) - (west.sh) == 0     1.77683    0.36776   4.832 1.22e-05 ***\n(se.sh) - (west.dp) == 0     2.51598    0.38432   6.547 6.48e-10 ***\n(se.dp) - (west.sh) == 0     0.23211    0.30434   0.763  1.00000    \n(se.dp) - (west.dp) == 0     0.97126    0.32416   2.996  0.01367 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nPLOB healthy\nInteraction\n\nplob_h.glm &lt;- glm(cbind(h_count, h) ~ location * depth, \n                family = binomial(link = \"logit\"), \n                data = plob_bleach)\n\n\npar(mfrow = c(2, 2))\nplot(plob_h.glm)\n\n\n\n\n\nsummary(plob_h.glm)\n\n\nCall:\nglm(formula = cbind(h_count, h) ~ location * depth, family = binomial(link = \"logit\"), \n    data = plob_bleach)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -2.0846     0.2164  -9.631  &lt; 2e-16 ***\nlocationse             0.5507     0.3967   1.388  0.16506    \nlocationwest          -1.5917     0.5506  -2.891  0.00384 ** \ndepthsh                0.7273     0.2877   2.528  0.01147 *  \nlocationse:depthsh    -0.3461     0.5504  -0.629  0.52949    \nlocationwest:depthsh  -0.5596     0.7383  -0.758  0.44849    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 78.898  on 11  degrees of freedom\nResidual deviance: 24.092  on  6  degrees of freedom\nAIC: 72.567\n\nNumber of Fisher Scoring iterations: 5\n\n\nAnova function from the car package\n\nAnova(plob_h.glm, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(h_count, h)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        17.2263  2  0.0001817 ***\ndepth            6.5218  1  0.0106558 *  \nlocation:depth   0.8028  2  0.6693953    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nplob_pale.aov &lt;- Anova(plob_h.glm, type = \"III\") # Type III because...\n\nNo interaction\n\nplob_h.glm2 &lt;- glm(cbind(h_count, h) ~ location + depth, \n                family = binomial(link = \"logit\"), \n                data = plob_bleach)\n\n\npar(mfrow = c(2, 2))\nplot(plob_h.glm2)\n\n\n\n\n\nsummary(plob_h.glm2)\n\n\nCall:\nglm(formula = cbind(h_count, h) ~ location + depth, family = binomial(link = \"logit\"), \n    data = plob_bleach)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   -2.0042     0.1892 -10.592  &lt; 2e-16 ***\nlocationse     0.3666     0.2751   1.332   0.1827    \nlocationwest  -1.9215     0.3678  -5.225 1.74e-07 ***\ndepthsh        0.5819     0.2308   2.521   0.0117 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 78.898  on 11  degrees of freedom\nResidual deviance: 24.895  on  8  degrees of freedom\nAIC: 69.37\n\nNumber of Fisher Scoring iterations: 5\n\n\nAnova function from the car package\n\nAnova(plob_h.glm2, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(h_count, h)\n         LR Chisq Df Pr(&gt;Chisq)    \nlocation   49.890  2  1.467e-11 ***\ndepth       6.441  1    0.01115 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-5",
    "href": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-5",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(plob_h.glm2, linfct = mcp(location = \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: glm(formula = cbind(h_count, h) ~ location + depth, family = binomial(link = \"logit\"), \n    data = plob_bleach)\n\nLinear Hypotheses:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \nse - north == 0     0.3666     0.2751   1.332     0.37    \nwest - north == 0  -1.9215     0.3678  -5.225   &lt;1e-04 ***\nwest - se == 0     -2.2880     0.4131  -5.539   &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\nPocillopora\n\npoci_bleach &lt;- rpn_bleach %&gt;%\n  filter(species == \"poci\")\n\n\npoci_bleach\n\n# A tibble: 12 × 13\n   species location depth transect bl_count pb_count p_count h_count coral_count\n   &lt;fct&gt;   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;       &lt;int&gt;    &lt;int&gt;   &lt;int&gt;   &lt;int&gt;       &lt;int&gt;\n 1 poci    north    dp    one             1        2       3       1           7\n 2 poci    north    dp    two             0        1       1       0           2\n 3 poci    north    sh    one             0        0       0       0           0\n 4 poci    north    sh    two             0        0       0       1           1\n 5 poci    se       dp    one             1       27      19      10          57\n 6 poci    se       dp    two             2        9      16       0          58\n 7 poci    se       sh    one             0        2      59      14          75\n 8 poci    se       sh    two             1        5      45       9          60\n 9 poci    west     dp    one             4        0       7       2          13\n10 poci    west     dp    two             0        2       8       4          14\n11 poci    west     sh    one             0        1      13       1          15\n12 poci    west     sh    two             2        0       9       7          18\n# ℹ 4 more variables: bl &lt;int&gt;, pb &lt;int&gt;, p &lt;int&gt;, h &lt;int&gt;\n\n\n\nPOCI Partially Bleached\nInteraction\n\npoci_pb.glm &lt;- glm(cbind(pb_count, pb) ~ location * depth, \n                family = binomial(link = \"logit\"), \n                data = poci_bleach)\n\n\npar(mfrow = c(2, 2))\nplot(poci_pb.glm)\n\nWarning: not plotting observations with leverage one:\n  3\n\n\n\n\n\n\nsummary(poci_pb.glm)\n\n\nCall:\nglm(formula = cbind(pb_count, pb) ~ location * depth, family = binomial(link = \"logit\"), \n    data = poci_bleach)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)            -0.69315    0.70711  -0.980   0.3270  \nlocationse             -0.09278    0.73514  -0.126   0.8996  \nlocationwest           -1.83258    1.01980  -1.797   0.0723 .\ndepthsh               -16.87292 3956.18038  -0.004   0.9966  \nlocationse:depthsh     14.75273 3956.18040   0.004   0.9970  \nlocationwest:depthsh   15.93291 3956.18058   0.004   0.9968  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.211  on 10  degrees of freedom\nResidual deviance: 20.921  on  5  degrees of freedom\nAIC: 55.354\n\nNumber of Fisher Scoring iterations: 16\n\n\nAnova function from the car package\n\nAnova(poci_pb.glm, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(pb_count, pb)\n               LR Chisq Df Pr(&gt;Chisq)  \nlocation         7.9356  2    0.01892 *\ndepth            0.7600  1    0.38332  \nlocation:depth   0.8257  2    0.66178  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNo interaction\n\npoci_pb.glm &lt;- glm(cbind(pb_count, pb) ~ location + depth, \n                family = binomial(link = \"logit\"), \n                data = poci_bleach)\n\n\npar(mfrow = c(2, 2))\nplot(poci_pb.glm)\n\n\n\n\n\nsummary(poci_pb.glm)\n\n\nCall:\nglm(formula = cbind(pb_count, pb) ~ location + depth, family = binomial(link = \"logit\"), \n    data = poci_bleach)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.72330    0.70092  -1.032   0.3021    \nlocationse   -0.08263    0.72752  -0.114   0.9096    \nlocationwest -1.53602    0.92597  -1.659   0.0972 .  \ndepthsh      -2.02830    0.41105  -4.934 8.04e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.211  on 10  degrees of freedom\nResidual deviance: 21.747  on  7  degrees of freedom\nAIC: 52.18\n\nNumber of Fisher Scoring iterations: 5\n\n\nAnova function from the car package\n\nAnova(poci_pb.glm, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(pb_count, pb)\n         LR Chisq Df Pr(&gt;Chisq)    \nlocation    7.508  2    0.02342 *  \ndepth      32.047  1  1.505e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-6",
    "href": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-6",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(poci_pb.glm, linfct = mcp(location = \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: glm(formula = cbind(pb_count, pb) ~ location + depth, family = binomial(link = \"logit\"), \n    data = poci_bleach)\n\nLinear Hypotheses:\n                  Estimate Std. Error z value Pr(&gt;|z|)  \nse - north == 0   -0.08263    0.72752  -0.114   0.9926  \nwest - north == 0 -1.53602    0.92597  -1.659   0.2126  \nwest - se == 0    -1.45339    0.62897  -2.311   0.0515 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\nsummary(glht(poci_pb.glm, linfct = mcp(depth = \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: glm(formula = cbind(pb_count, pb) ~ location + depth, family = binomial(link = \"logit\"), \n    data = poci_bleach)\n\nLinear Hypotheses:\n             Estimate Std. Error z value Pr(&gt;|z|)    \nsh - dp == 0  -2.0283     0.4111  -4.934 8.04e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\nPOCI Pale\n\npoci_pale.glm &lt;- glm(cbind(p_count, p) ~ location * depth, \n                family = binomial(link = \"logit\"), \n                data = poci_bleach)\n\n\npar(mfrow = c(2, 2))\nplot(poci_pale.glm)\n\nWarning: not plotting observations with leverage one:\n  3\n\n\n\n\n\n\nsummary(poci_pale.glm)\n\n\nCall:\nglm(formula = cbind(p_count, p) ~ location * depth, family = binomial(link = \"logit\"), \n    data = poci_bleach)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)            -0.2231     0.6708  -0.333    0.739\nlocationse             -0.6035     0.7008  -0.861    0.389\nlocationwest            0.4463     0.7746   0.576    0.565\ndepthsh               -18.3429  6522.6386  -0.003    0.998\nlocationse:depthsh     20.3800  6522.6386   0.003    0.998\nlocationwest:depthsh   18.8129  6522.6386   0.003    0.998\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 66.3499  on 10  degrees of freedom\nResidual deviance:  6.0394  on  5  degrees of freedom\nAIC: 51.212\n\nNumber of Fisher Scoring iterations: 17\n\n\nAnova function from the car package\n\nAnova(poci_pale.glm, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(p_count, p)\n               LR Chisq Df Pr(&gt;Chisq)   \nlocation         6.1173  2   0.046951 * \ndepth            1.0949  1   0.295383   \nlocation:depth   9.5663  2   0.008369 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\npoci_pale.aov &lt;- Anova(poci_pale.glm, type = \"III\") # Type III because...\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\npoci_bleach$groups &lt;- interaction(poci_bleach$location, poci_bleach$depth)"
  },
  {
    "objectID": "content/bleaching.html#create-a-post-hoc-model-5",
    "href": "content/bleaching.html#create-a-post-hoc-model-5",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_poci_pale &lt;- with(poci_bleach, glm(cbind(p_count, p) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-7",
    "href": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-7",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_poci_pale, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(p_count, p) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)   \n(north.sh) - (west.sh) == 0  -19.2592  6522.6386  -0.003   1.0000   \n(north.sh) - (west.dp) == 0  -18.7892  6522.6386  -0.003   1.0000   \n(north.sh) - (se.sh) == 0    -19.7765  6522.6386  -0.003   1.0000   \n(north.sh) - (se.dp) == 0    -17.7394  6522.6386  -0.003   1.0000   \n(north.dp) - (west.sh) == 0   -0.9163     0.7657  -1.197   1.0000   \n(north.dp) - (west.dp) == 0   -0.4463     0.7746  -0.576   1.0000   \n(north.dp) - (se.sh) == 0     -1.4335     0.7013  -2.044   0.3686   \n(north.dp) - (se.dp) == 0      0.6035     0.7008   0.861   1.0000   \n(se.sh) - (west.sh) == 0       0.5173     0.4222   1.225   1.0000   \n(se.sh) - (west.dp) == 0       0.9873     0.4380   2.254   0.2421   \n(se.dp) - (west.sh) == 0      -1.5198     0.4212  -3.608   0.0037 **\n(se.dp) - (west.dp) == 0      -1.0498     0.4371  -2.402   0.1795   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nPOCI Healthy\nInteraction\n\npoci_h.glm &lt;- glm(cbind(h_count, h) ~ location * depth, \n                family = binomial(link = \"logit\"), \n                data = poci_bleach)\n\n\npar(mfrow = c(2, 2))\nplot(poci_h.glm)\n\nWarning: not plotting observations with leverage one:\n  3\n\n\n\n\n\n\nsummary(poci_h.glm)\n\n\nCall:\nglm(formula = cbind(h_count, h) ~ location * depth, family = binomial(link = \"logit\"), \n    data = poci_bleach)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)            -2.0794     1.0607  -1.961   0.0499 *\nlocationse             -0.2719     1.1111  -0.245   0.8067  \nlocationwest            0.8267     1.1573   0.714   0.4750  \ndepthsh                19.6455  3956.1805   0.005   0.9960  \nlocationse:depthsh    -18.8771  3956.1805  -0.005   0.9962  \nlocationwest:depthsh  -19.5322  3956.1805  -0.005   0.9961  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 33.048  on 10  degrees of freedom\nResidual deviance: 21.706  on  5  degrees of freedom\nAIC: 58.33\n\nNumber of Fisher Scoring iterations: 16\n\n\nAnova function from the car package\n\nAnova(poci_h.glm, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(h_count, h)\n               LR Chisq Df Pr(&gt;Chisq)  \nlocation         3.4341  2    0.17960  \ndepth            3.7291  1    0.05347 .\nlocation:depth   3.5875  2    0.16634  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\npoci_pale.aov &lt;- Anova(poci_h.glm, type = \"III\") # Type III because...\n\nNo interaction\n\npoci_h.glm2 &lt;- glm(cbind(h_count, h) ~ location + depth, \n                family = binomial(link = \"logit\"), \n                data = poci_bleach)\n\n\npar(mfrow = c(2, 2))\nplot(poci_h.glm2)\n\n\n\n\n\nsummary(poci_h.glm2)\n\n\nCall:\nglm(formula = cbind(h_count, h) ~ location + depth, family = binomial(link = \"logit\"), \n    data = poci_bleach)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)   -1.4636     0.7951  -1.841   0.0657 .\nlocationse    -0.8138     0.8342  -0.976   0.3293  \nlocationwest  -0.1162     0.8678  -0.134   0.8935  \ndepthsh        0.6574     0.3333   1.972   0.0486 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 33.048  on 10  degrees of freedom\nResidual deviance: 25.293  on  7  degrees of freedom\nAIC: 57.918\n\nNumber of Fisher Scoring iterations: 5\n\n\nAnova function from the car package\n\nAnova(poci_h.glm2, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(h_count, h)\n         LR Chisq Df Pr(&gt;Chisq)  \nlocation   4.0681  2    0.13080  \ndepth      4.0623  1    0.04385 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-8",
    "href": "content/bleaching.html#determine-the-post-hoc-comparisons-of-interest-8",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(poci_h.glm2, linfct = mcp(location = \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: glm(formula = cbind(h_count, h) ~ location + depth, family = binomial(link = \"logit\"), \n    data = poci_bleach)\n\nLinear Hypotheses:\n                  Estimate Std. Error z value Pr(&gt;|z|)\nse - north == 0    -0.8138     0.8342  -0.976    0.576\nwest - north == 0  -0.1162     0.8678  -0.134    0.990\nwest - se == 0      0.6976     0.3609   1.933    0.119\n(Adjusted p values reported -- single-step method)\n\n\n\nsummary(glht(poci_h.glm2, linfct = mcp(depth = \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: glm(formula = cbind(h_count, h) ~ location + depth, family = binomial(link = \"logit\"), \n    data = poci_bleach)\n\nLinear Hypotheses:\n             Estimate Std. Error z value Pr(&gt;|z|)  \nsh - dp == 0   0.6574     0.3333   1.972   0.0486 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)"
  },
  {
    "objectID": "content/coral_size.html",
    "href": "content/coral_size.html",
    "title": "Coral Size",
    "section": "",
    "text": "poci_size &lt;- read.csv('coral_size.csv')\n\n\npoci_size.gg &lt;- read_csv(\"poci_size_main.csv\")\n\nRows: 3639 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): level, Site, cover\ndbl (7): layer, class, id, area, enn, para, size_cm\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nggplot(poci_size.gg, aes(x = size_cm)) +\n  geom_histogram(fill = \"#333399\") + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(NULL) +\n  ggtitle(expression(\"Coral size \" (cm**2))) +\n  theme_bw() +\n  facet_wrap(~ Site, ncol = 1) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(size = 14), \n        axis.title.y = element_text(size = 14), \n        axis.text.y  = element_text(size= 10),\n        axis.text.x  = element_text(size = 12), \n        legend.text = element_text(size = 12),\n        legend.title = element_text(size = 12),\n        plot.title = element_text(hjust = 0.5, size = 14),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill = \"white\"),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major = element_blank(),\n        plot.background = element_rect(fill = \"white\"),\n        legend.background = element_rect(fill = \"white\"),\n        strip.text.x = element_text(size = 12, colour = \"#FFFFFF\"),\n        strip.background = element_rect(fill = '#000066')\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\npoci_size2 &lt;-\npoci_size %&gt;%\n  as_tibble() %&gt;%\n  mutate(size_cm = area*10000) %&gt;%\n  group_by(Site) %&gt;%\n  dplyr::summarize(mean = mean(size_cm), \n                   sd = sd(size_cm), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %&gt;%\n  mutate_at(vars(Site), factor) %&gt;%\n  add_column(\n          location = c('Anakena', 'Manavai', 'Southeast')\n          ) %&gt;%\n  mutate_at(vars(location), factor)\n\n\npoci_size2\n\n# A tibble: 3 × 8\n  Site   mean    sd     n    se lower.ci upper.ci location \n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    \n1 ana    111.  73.8   136  6.33     98.2     123. Anakena  \n2 man    151.  82.7   372  4.29    142.      159. Manavai  \n3 vhu    231. 137.   3131  2.44    227.      236. Southeast\n\n\n\npoci_size.gg &lt;-\n  poci_size %&gt;%\n  mutate(size_cm = area*10000) %&gt;%\n  as_tibble() %&gt;%\n  mutate_at(vars(Site), factor)\n\n\npoci_size.gg\n\n# A tibble: 3,639 × 10\n   layer level class    id Site  cover    area    enn  para size_cm\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     1 patch     1     2 ana   coral 0.0165  0.111   42.0   165. \n 2     1 patch     1     3 ana   coral 0.0261  0.111   32.1   261. \n 3     1 patch     1     4 ana   coral 0.0162  0.0598  44.3   162. \n 4     1 patch     1     5 ana   coral 0.0149  0.230   38.6   149. \n 5     1 patch     1     6 ana   coral 0.00788 0.535   61.5    78.8\n 6     1 patch     1     7 ana   coral 0.0148  0.532   41.1   148. \n 7     1 patch     1     8 ana   coral 0.0109  0.0598  50.6   109. \n 8     1 patch     1     9 ana   coral 0.0101  0.346   52.6   101. \n 9     1 patch     1    10 ana   coral 0.0262  0.192   38.4   262. \n10     1 patch     1    11 ana   coral 0.00620 0.137   71.6    62.0\n# ℹ 3,629 more rows\n\n\n\nmodel_1.lm &lt;- lm(size_cm ~ Site, data = poci_size.gg)\n\n\nmodel_1.lm\n\n\nCall:\nlm(formula = size_cm ~ Site, data = poci_size.gg)\n\nCoefficients:\n(Intercept)      Siteman      Sitevhu  \n     110.67        40.18       120.81  \n\n\n\nsummary(model_1.lm)\n\n\nCall:\nlm(formula = size_cm ~ Site, data = poci_size.gg)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-231.46  -91.09  -16.44   70.33 1160.47 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   110.67      11.18   9.896  &lt; 2e-16 ***\nSiteman        40.18      13.07   3.074  0.00212 ** \nSitevhu       120.81      11.42  10.575  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 130.4 on 3636 degrees of freedom\nMultiple R-squared:  0.05804,   Adjusted R-squared:  0.05752 \nF-statistic:   112 on 2 and 3636 DF,  p-value: &lt; 2.2e-16\n\n\n\npar(mfrow = c(2, 2))\nplot(model_1.lm)\n\n\n\n\n\nAnova(model_1.lm, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: size_cm\n              Sum Sq   Df F value    Pr(&gt;F)    \n(Intercept)  1665764    1  97.933 &lt; 2.2e-16 ***\nSite         3810826    2 112.022 &lt; 2.2e-16 ***\nResiduals   61845547 3636                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nconfint(model_1.lm)\n\n               2.5 %   97.5 %\n(Intercept) 88.74557 132.5982\nSiteman     14.55638  65.8019\nSitevhu     98.40842 143.2033\n\n\n\n89+14\n\n[1] 103\n\n89+98\n\n[1] 187\n\n132+66\n\n[1] 198\n\n132+143\n\n[1] 275\n\n\n\naggregate(size_cm ~ Site, data = poci_size.gg, mean)\n\n  Site  size_cm\n1  ana 110.6719\n2  man 150.8510\n3  vhu 231.4777\n\n\n\nmodel_1.aov &lt;- Anova(model_1.lm, type = \"III\")\n\n\nas.data.frame(model_1.aov)\n\n              Sum Sq   Df   F value       Pr(&gt;F)\n(Intercept)  1665764    1  97.93297 8.382392e-23\nSite         3810826    2 112.02231 6.156818e-48\nResiduals   61845547 3636        NA           NA\n\n\n\nflextable(model_1.aov)\n\n\nSum SqDfF valuePr(&gt;F)1,665,764197.932970.0000000000000000000000838239209769198883906904039666703,810,8262112.022310.00000000000000000000000000000000000000000000000615681861,845,5473,636\n\n\n\npost_hoc.model_1.lm &lt;- glht(model_1.lm, linfct = mcp(Site = 'Tukey'))\n\n\nmodel_1.aov &lt;- aov(size_cm ~ Site, data = poci_size.gg)\n\n\n# Tukey's test\ntukey &lt;- TukeyHSD(model_1.aov)\n\n\n# compact letter display\ncld &lt;- multcompLetters4(model_1.aov, tukey)\n\n\ncld\n\n$Site\nvhu man ana \n\"a\" \"b\" \"c\" \n\n\n\npoci_size3 &lt;- \npoci_size2 %&gt;%\n  add_column(\n          cld = c('a', 'b', 'c')\n          ) %&gt;%\nmutate_at(vars(cld), factor)\n\n\npoci_size3\n\n# A tibble: 3 × 9\n  Site   mean    sd     n    se lower.ci upper.ci location  cld  \n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;\n1 ana    111.  73.8   136  6.33     98.2     123. Anakena   a    \n2 man    151.  82.7   372  4.29    142.      159. Manavai   b    \n3 vhu    231. 137.   3131  2.44    227.      236. Southeast c    \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n# label_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\", \"25 m\" = \"25 m\")\n\n\npoci_size.gg.barplot &lt;- ggplot(poci_size3, aes(x = location, y = mean, fill = x_labels)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", size = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = lower.ci, ymax = upper.ci), size = 0.75) +\n  scale_y_continuous(expression(paste(\"Mean Colony Size (\",\" \", cm^2, \")\")), limits = c(0, 300)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) +\n# facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n# ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  geom_text(aes(label = cld, y = upper.ci), vjust = -0.5) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = \"none\",\n        plot.title = element_text(size = 11),\n        axis.title.y = element_text(size = 11),\n        legend.title = element_blank())\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\npoci_size.gg.barplot"
  },
  {
    "objectID": "content/rpn_sppa2.html#density-plots",
    "href": "content/rpn_sppa2.html#density-plots",
    "title": "SPPA",
    "section": "Density Plots",
    "text": "Density Plots\n\nplot(\n  density(se_corals)\n)\n\n\n\n\n\nplot(\n  density(west_corals)\n)\n\n\n\n\n\nplot(\n  density(north_corals)\n)\n\n\n\n\nAlter smoothing parameter\n\nplot(\n  density(se_corals, 1)\n)  \n\n\n\n\n\nplot(\n  density(west_corals, 1)\n)  \n\n\n\n\n\nplot(\n  density(north_corals, 1)\n)  \n\n\n\n\nContour plot\n\ncontour(\n  density(se_corals, 1)\n)\n\n\n\n\n\ncontour(\n  density(west_corals, 1)\n)\n\n\n\n\n\ncontour(\n  density(north_corals, 1)\n)\n\n\n\n\nWe can also make tallies of counts of point locations based on quadrats overlaid on the plot. To determine whether these quadrat counts conform to CSR (i.e., a homogeneous Poisson process), use a simple Chi-Square test statistic.\nQuadrat counts\nCounts in 10 x 25 m quadrats\n\nse_Q &lt;- quadratcount(se_corals, nx = 10, ny = 25)\n\nPlot\n\nplot(se_corals, cex = 1)\nplot(se_Q, add = TRUE, cex = 1)\n\n\n\n\nChi-sq test for complete spatial randomness, CSR\n\nquadrat.test(se_corals, nx = 10, ny = 25, method = \"Chisq\")\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  se_corals\nX2 = 308.08, df = 249, p-value = 0.0127\nalternative hypothesis: two.sided\n\nQuadrats: 10 by 25 grid of tiles\n\n\nQuadrat counts\nCounts in 10 x 25 m quadrats\n\nwest_Q &lt;- quadratcount(west_corals, nx = 10, ny = 25)\n\nPlot\n\nplot(west_corals, cex = 1)\nplot(west_Q, add = TRUE, cex = 1)\n\n\n\n\nChi-sq test for complete spatial randomness, CSR\n\nquadrat.test(west_corals, nx = 10, ny = 25, method = \"Chisq\")\n\nWarning: Some expected counts are small; chi^2 approximation may be inaccurate\n\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  west_corals\nX2 = 1394.1, df = 249, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nQuadrats: 10 by 25 grid of tiles\n\n\nThe test statistic suggests highly a non-random point pattern at the scale of the quadrat defined. Note that this test is more akin to a first-order point pattern analysis because it is based on the dispersion of points among sampling quadrats.\nQuadrat counts\nCounts in 10 x 25 m quadrats\n\nnorth_Q &lt;- quadratcount(north_corals, nx = 10, ny = 25)\n\nPlot\n\nplot(north_corals, cex = 1)\nplot(north_Q, add = TRUE, cex = 1)\n\n\n\n\nChi-sq test for complete spatial randomness, CSR\n\nquadrat.test(north_corals, nx = 10, ny = 25, method = \"Chisq\")\n\nWarning: Some expected counts are small; chi^2 approximation may be inaccurate\n\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  north_corals\nX2 = 397.09, df = 249, p-value = 1.389e-08\nalternative hypothesis: two.sided\n\nQuadrats: 10 by 25 grid of tiles\n\n\nThe test statistic suggests highly a non-random point pattern at the scale of the quadrat defined. Note that this test is more akin to a first-order point pattern analysis because it is based on the dispersion of points among sampling quadrats."
  },
  {
    "objectID": "content/rpn_sppa2.html#ripleys-k-function",
    "href": "content/rpn_sppa2.html#ripleys-k-function",
    "title": "SPPA",
    "section": "Ripley’s K function:",
    "text": "Ripley’s K function:\n\nSecond-order point pattern analyses can readily be implemented in ‘spatstat’.\nRipley’s K and the standard L functions\nIgnore edge effects with ‘(correction = “none”)’\n\n\nSoutheast - Vaihu\n\nK_none_se &lt;- Kest(se_corals, rmax = 5.0, correction = \"none\")\n\n\nPlot K\n\n\nplot(K_none_se, legend = F, main = \"Southeast: Ripley's K\")\n\n\n\n\n\nPlot L with 1:1 expectation\n\n\nL_none_se &lt;- Lest(se_corals, rmax = 5.0, correction = \"none\")\n\n\nplot(L_none_se, legend = F, main = \"Southeast: standardized L function (standardized 1:1)\")\n\n\n\n\n\nPlot L with 0 expectation\n\n\nplot(L_none_se, . - r ~ r, legend = F, main = \"Southeast: standardized L function (standardized 0)\")\n\n\n\n\n\n\nWest - Manavai\n\nK_none_west &lt;- Kest(west_corals, rmax = 5.0, correction = \"none\")\n\n\nPlot K\n\n\nplot(K_none_west, legend = F, main = \"West: Ripley's K\")\n\n\n\n\n\nPlot L with 1:1 expectation\n\n\nL_none_west &lt;- Lest(west_corals, rmax = 5.0, correction = \"none\")\n\n\nplot(L_none_west, legend = F, main = \"West: standardized L function (standardized 1:1)\")\n\n\n\n\n\nPlot L with 0 expectation\n\n\nplot(L_none_west, . - r ~ r, legend = F, main = \"West: standardized L function (standardized 0)\")\n\n\n\n\n\n\nNorth - Anakena\n\nK_none_north &lt;- Kest(north_corals, rmax = 5.0, correction = \"none\")\n\n\nPlot K\n\n\nplot(K_none_north, legend = F, main = \"North: Ripley's K\")\n\n\n\n\n\nPlot L with 1:1 expectation\n\n\nL_none_north &lt;- Lest(north_corals, rmax = 5.0, correction = \"none\")\n\n\nplot(L_none_north, legend = F, main = \"North: standardized L function (standardized 1:1)\")\n\n\n\n\n\nPlot L with 0 expectation\n\n\nplot(L_none_north, . - r ~ r, legend = F, main = \"North: standardized L function (standardized 0)\")\n\n\n\n\nThe above analysis ignores the problem of edge effects. spatstat provides a variety of edge corrections. Contrast an (1) isotropic and (2) translate correction for adjusting for boundary effects. The isotropic correction uses a simple weighting for the area sampled near the plot boundary (Ripley 1988), the translate correction uses a toroidal shift. We adjust for potential boundary effects by typing:\n\n\nSoutheast – Vaihu\n\nIsotropic edge correction\n\n\nL_iso_se &lt;- Lest(se_corals, rmax = 5.0, correction = \"isotropic\")\n\n\nplot(L_iso_se, . - r ~ r, legend = F, main = \"Southeast: standardzied L (isotropic correction)\")\n\n\n\n\n\nTranslate (toroidal) edge correction\n\n\nL_trans_se &lt;- Lest(se_corals, rmax = 5.0, correction = \"trans\")\n\n\nplot(L_trans_se, . - r ~ r, legend = F, main = \"Southeast: standardzied L (translate correction)\")"
  },
  {
    "objectID": "content/rpn_sppa2.html#monte-carlo-simulations-to-calculate-a-global-and-pointwise-confidence-envelope-under-csr",
    "href": "content/rpn_sppa2.html#monte-carlo-simulations-to-calculate-a-global-and-pointwise-confidence-envelope-under-csr",
    "title": "SPPA",
    "section": "Monte Carlo simulations to calculate a global and pointwise confidence envelope under CSR",
    "text": "Monte Carlo simulations to calculate a global and pointwise confidence envelope under CSR\n\nL_csr_se &lt;- envelope(se_corals, rmax = 5.0, Lest, nsim = 99, rank = 1, correction = \"trans\", global = F)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nL_csr.g_se &lt;- envelope(se_corals, rmax = 5.0, Lest, nsim = 99, rank = 1, correction = \"trans\", global = T)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nPlot point-wise envelope\n\n\nplot(L_csr_se, . - r ~ r, shade = c(\"hi\", \"lo\"), legend = F, main = \"Southeast: stand. L (Monte Carlo, CSR env)\")\n\n\n\n\n\nPlot global envelope\n\n\nplot(L_csr.g_se, . - r ~ r, shade = c(\"hi\", \"lo\"), legend = F, main = \"Southeast: stand. L (Monte Carlo, CSR env)\")\n\n\n\n\n\nWest - Manavai\n\nIsotropic edge correction\n\n\nL_iso_west &lt;- Lest(west_corals, rmax = 5.0, correction = \"isotropic\")\n\n\nplot(L_iso_west, . - r ~ r, legend = F, main = \"West: standardzied L (isotropic correction)\")\n\n\n\n\n\nTranslate (toroidal) edge correction\n\n\nL_trans_west &lt;- Lest(west_corals, rmax = 5.0, correction = \"trans\")\n\n\nplot(L_trans_west, . - r ~ r, legend = F, main = \"West: standardzied L (translate correction)\")"
  },
  {
    "objectID": "content/rpn_sppa2.html#monte-carlo-simulations-to-calculate-a-global-and-pointwise-confidence-envelope-under-csr-1",
    "href": "content/rpn_sppa2.html#monte-carlo-simulations-to-calculate-a-global-and-pointwise-confidence-envelope-under-csr-1",
    "title": "SPPA",
    "section": "Monte Carlo simulations to calculate a global and pointwise confidence envelope under CSR",
    "text": "Monte Carlo simulations to calculate a global and pointwise confidence envelope under CSR\n\nL_csr_se &lt;- envelope(se_corals, rmax = 5.0, Lest, nsim = 99, rank = 1, correction = \"trans\", global = F)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nL_csr.g_se &lt;- envelope(se_corals, rmax = 5.0, Lest, nsim = 99, rank = 1, correction = \"trans\", global = T)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nPlot point-wise envelope\n\n\nplot(L_csr_se, . - r ~ r, shade = c(\"hi\", \"lo\"), legend = F, main = \"Southeast: stand. L (Monte Carlo, CSR env)\")\n\n\n\n\n\nPlot global envelope\n\n\nplot(L_csr.g_se, . - r ~ r, shade = c(\"hi\", \"lo\"), legend = F, main = \"Southeast: stand. L (Monte Carlo, CSR env)\")\n\n\n\n\n\nNorth - Anakena\n\nIsotropic edge correction\n\n\nL_iso_north &lt;- Lest(north_corals, rmax = 5.0, correction = \"isotropic\")\n\n\nplot(L_iso_north, . - r ~ r, legend = F, main = \"North: standardzied L (isotropic correction)\")\n\n\n\n\n\nTranslate (toroidal) edge correction\n\n\nL_trans_north &lt;- Lest(north_corals, rmax = 5.0, correction = \"trans\")\n\n\nplot(L_trans_north, . - r ~ r, legend = F, main = \"North: standardzied L (translate correction)\")"
  },
  {
    "objectID": "content/rpn_sppa2.html#monte-carlo-simulations-to-calculate-a-global-and-pointwise-confidence-envelope-under-csr-2",
    "href": "content/rpn_sppa2.html#monte-carlo-simulations-to-calculate-a-global-and-pointwise-confidence-envelope-under-csr-2",
    "title": "SPPA",
    "section": "Monte Carlo simulations to calculate a global and pointwise confidence envelope under CSR",
    "text": "Monte Carlo simulations to calculate a global and pointwise confidence envelope under CSR\n\nL_csr_north &lt;- envelope(north_corals, rmax = 5.0, Lest, nsim = 99, rank = 1, correction = \"trans\", global = F)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nL_csr.g_north &lt;- envelope(north_corals, rmax = 5.0, Lest, nsim = 99, rank = 1, correction = \"trans\", global = T)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nPlot point-wise envelope\n\n\nplot(L_csr_north, . - r ~ r, shade = c(\"hi\", \"lo\"), legend = F, main = \"North: stand. L (Monte Carlo, CSR env)\")\n\n\n\n\n\nPlot global envelope\n\n\nplot(L_csr.g_north, . - r ~ r, shade = c(\"hi\", \"lo\"), legend = F, main = \"North: stand. L (Monte Carlo, CSR env)\")\n\n\n\n\nFor the functions above, two lines are drawn. The \\(L_{pois}\\) line is a dashed line that represents the expected (theoretical) value based on a Poisson process (CSR). The way that spatstat calculates \\(L\\) is to linearize \\(K\\) such that the expected value is \\(r\\) (or the radius). The other solid line represents the estimated \\(L\\) (linearized \\(K\\)), when the edges are ignored.\nWhen comparing the \\(L\\) function that ignores boundaries to those above that account for boundaries, notice that patterns change at larger distances - we expect that the \\(L\\) function at larger distances should potentially be more biased than at smaller distances because larger radii will naturally overlap more with the boundary of the study area.\nWhen edge effects are ignored, the effect in the of counting fewer points within the radius \\(r\\) near the boundary, so the observed value for \\(L\\) or \\(K\\) should have an artifact of decreasing as \\(r\\) increases.\nThe analyses so far are exploratory. While the observed statistics (\\(K\\), \\(L\\)) appear different than the expectation, it is unclear if these are substantially (or significantly) different.\nTo conduct formal inference regarding if the point pattern follows CSR, we can use Monte Carlo simulations ro calculate a confidence envelope under CSR with the envelope function.\nIn the envelope function, rank specifies the alpha for the simulations. For a rank = 1, the max an min are used as the envelopes, such that for 99 simulations, alpha = 0.01 while for 19 simulations, alpha = 0.05.\nAlso not that we used global = FALSE. This means that these are pointwise envelopes.\nThese envelopes work better for \\(L\\) than \\(K\\) because of variance stabilizing properties.\nPlots of pointwise envelopes show the stated upper and lower quantiles of simulated patterns for any distance r. Because such analyses are calculating envelopes for vhuy distances, pointwise envelopes with a specified alpha should not be used to reject a null model at that level (because of the multiple tests). Consequently, there are alternative global tests that can be used in this way. While global tests are under active development (Baddeley et al. 2014; Wiegand et al. 2016), spatstat does provide one option for a global test (using global = T).\nThis approach estimates the maximum deviation from the Poisson point process across all r (i.e., \\(D = max|K_{(r)} - K_{pois(r)}|)\\). This approach is referred to as a simultaneous envelope (or critical band) rather than a pointwise envelope.\nIf the observed line falls outside the simultaneous envelope at any point on \\(r\\), we would reject the null hypothesis.\n\nSoutheast – Vaihu\n\nPtrans_se &lt;- pcf(se_corals, r = NULL, correction = \"translate\")\n\n\nplot(Ptrans_se)\n\n\n\n\n\nplot(Ptrans_se$r, Ptrans_se$pcf, type = \"l\", xlab = \"r\", ylab = \"g(r)\", main = \"pair correlation\")\nabline(h=1, lty=1)\n\n\n\n\n\nPenv_se &lt;- envelope(se_corals, r = NULL, pcf, nsim = 99, rank = 1, correction =\n                       \"translate\", global = FALSE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(Penv_se, shade = c(\"hi\", \"lo\"), legend = FALSE, main = \"Southeast: pair correlation function, g\")\n\n\n\n\n\n\nWest - Manavai\n\nPtrans_west &lt;- pcf(west_corals, r = NULL, correction = \"translate\")\n\n\nplot(Ptrans_west)\n\n\n\n\n\nplot(Ptrans_west$r, Ptrans_west$pcf, type = \"l\", xlab = \"r\", ylab = \"g(r)\", main = \"pair correlation\")\nabline(h=1, lty=1)\n\n\n\n\n\nPenv_west &lt;- envelope(west_corals, r = NULL, pcf, nsim = 99, rank = 1, correction =\n                       \"translate\", global = FALSE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(Penv_west, shade = c(\"hi\", \"lo\"), legend = FALSE, main = \"Southeast: pair correlation function, g\")\n\n\n\n\n\n\nNorth - Anakena\n\nPtrans_north &lt;- pcf(north_corals, r = NULL, correction = \"translate\")\n\n\nplot(Ptrans_north)\n\n\n\n\n\nplot(Ptrans_north$r, Ptrans_north$pcf, type = \"l\", xlab = \"r\", ylab = \"g(r)\", main = \"pair correlation\")\nabline(h = 1, lty = 1)\n\n\n\n\n\nPenv_north &lt;- envelope(north_corals, r = NULL, pcf, nsim = 99, rank = 1, correction =\n                       \"translate\", global = FALSE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(Penv_north, shade = c(\"hi\", \"lo\"), legend = FALSE, main = \"North: pair correlation function, g\")\n\n\n\n\nThe pcf function uses a smoothing kernel such that distance bins are not needed.\nThe default bandwidth coefficient (related to sigma in a Gaussian kernel) for the smoothing kernel is set to 0.15 (Stoyan and Stoyan 1994).\nWe can adjust the smoothing on the pair correlation function using the stoyan comvhud in the pcf function.\nIncreasing the value of the bandwidth coefficient (e.g., stoyan = 0.4) results in a less wiggly g function.\nFinally, we can use similar arguments for the G-function to estimate the probability of finding a nearest neighbor as a function of distance.\nspatstat uses a similar approach as above with the Gest function.\nNote that for Gest, there are subtly different ways to account for edge effects relative to above. Below we use rs, the reduced sample correction.\nWe can check the observed G-function calculated by spatstat to the cumulative distribution function of the empirical data (with the ecdf function):\n\n\nSoutheast – Vaihu\n\nGtrans_se &lt;- Gest(se_corals, r = NULL, correction = \"rs\")\n\n\nplot(Gtrans_se, legend = F)\n\n\n\n\n\nGenv_se &lt;- envelope(se_corals, r = NULL, Gest, nsim = 99, rank = 1, correction = \"rs\", global = FALSE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(Genv_se, shade = c(\"hi\", \"lo\"), legend = FALSE, main = \"Southeast: G-function\")\n\n\n\n\n\n\nWest - Manavai\n\nGtrans_west &lt;- Gest(west_corals, r = NULL, correction = \"rs\")\n\n\nplot(Gtrans_west, legend = F)\n\n\n\n\n\nGenv_west &lt;- envelope(west_corals, r = NULL, Gest, nsim = 99, rank = 1, correction = \"rs\", global = FALSE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(Genv_west, shade = c(\"hi\", \"lo\"), legend = FALSE, main = \"West: G-function\")\n\n\n\n\n\n\nNorth - Anakena\n\nGtrans_north &lt;- Gest(north_corals, r = NULL, correction = \"rs\")\n\n\nplot(Gtrans_north, legend = F)\n\n\n\n\n\nGenv_north &lt;- envelope(north_corals, r = NULL, Gest, nsim = 99, rank = 1, correction = \"rs\", global = FALSE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(Genv_north, shade = c(\"hi\", \"lo\"), legend = FALSE, main = \"North: G-function\")\n\n\n\n\n\n\nAlternative Null Models\nWhile CSR is a useful starting point as a null model, in some situations we may be interested in using alternative null models. Some null models can be derived from a Poisson cluster process. Two common Poisson cluster processes considered in ecology are Matern cluster processes and Thomas cluster processes (Velazquez et al. 2016). In a Matérn cluster process, there are two types of points. The first are parent points, which have a Poisson distribution. Second, for each parent point, there are offspring points, which are independently and uniformly distributed around the parent points within a radius r. Consequently, these offspring points generate an underlying aggregated pattern. Similarly, with a Thomas process, offspring points are generated with parents but with an isotropic Gaussian distribution (similar to a Gaussian kernel). Such a process could reflect biological phenomena such as seed dispersal from parent plants. We can use these alternative null models in spatstat, with the above functions (\\(K\\), \\(L\\), pair correlation g, etc.). For example, a K function with a Thomas process as a null model can be quantified as:\n\n\nSoutheast – Vaihu\n\nKthomas_se &lt;- kppm(se_corals, ~ 1, \"Thomas\")\n\n\nKthomas_se\n\nStationary cluster point process model\nFitted to point pattern dataset 'se_corals'\nFitted by minimum contrast\n    Summary statistic: K-function\n\nUniform intensity:  12.524\n\nCluster model: Thomas process\nFitted cluster parameters:\n     kappa      scale \n0.09841425 9.29489907 \nMean cluster size:  127.258 points\n\nCluster strength: phi =  0.009359\nSibling probability: psib =  0.009273\n\n\n\nsummary(Kthomas_se)\n\nStationary cluster point process model\nFitted to point pattern dataset 'se_corals'\nFitted by minimum contrast\n    Summary statistic: K-function\nMinimum contrast fit (object of class \"minconfit\")\nModel: Thomas process\nFitted by matching theoretical K function to se_corals\n\nInternal parameters fitted by minimum contrast ($par):\n      kappa      sigma2 \n 0.09841425 86.39514879 \n\nFitted cluster parameters:\n     kappa      scale \n0.09841425 9.29489907 \nMean cluster size:  127.258 points\n\nConverged successfully after 271 function evaluations\n\nStarting values of parameters:\n     kappa     sigma2 \n12.5240000  0.1273346 \nDomain of integration: [ 0 , 2.5 ]\nExponents: p= 2, q= 0.25\n\n----------- TREND  -----\nPoint process model\nFitted to data: X\nFitting method: maximum likelihood (Berman-Turner approximation)\nModel was fitted using glm()\nAlgorithm converged\nCall:\nppm.ppp(Q = X, trend = trend, rename.intercept = FALSE, covariates = covariates, \n    covfunargs = covfunargs, use.gam = use.gam, forcefit = TRUE, \n    improve.type = ppm.improve.type, improve.args = ppm.improve.args, \n    nd = nd, eps = eps)\nEdge correction: \"border\"\n    [border correction distance r = 0 ]\n--------------------------------------------------------------------------------\nQuadrature scheme (Berman-Turner) = data + dummy + weights\n\nData pattern:\nPlanar point pattern:  3131 points\nAverage intensity 12.5 points per square unit\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\n\nDummy quadrature points:\n     120 x 120 grid of dummy points, plus 4 corner points\n     dummy spacing: 0.08333333 x 0.20833333 units\n\nOriginal dummy parameters: =\nPlanar point pattern:  14404 points\nAverage intensity 57.6 points per square unit\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\nQuadrature weights:\n     (counting weights based on 120 x 120 array of rectangular tiles)\nAll weights:\n    range: [0.00434, 0.0174]    total: 250\nWeights on data points:\n    range: [0.00434, 0.00868]   total: 26.5\nWeights on dummy points:\n    range: [0.00434, 0.0174]    total: 223\n--------------------------------------------------------------------------------\nFITTED :\n\nStationary Poisson process\n\n---- Intensity: ----\n\n\nUniform intensity:\n[1] 12.524\n\n            Estimate      S.E. CI95.lo  CI95.hi Ztest     Zval\n(Intercept) 2.527647 0.0178714 2.49262 2.562674   *** 141.4353\n\n----------- gory details -----\n\nFitted regular parameters (theta):\n(Intercept) \n   2.527647 \n\nFitted exp(theta):\n(Intercept) \n     12.524 \n\n----------- CLUSTER  -----------\nModel: Thomas process\n\nFitted cluster parameters:\n     kappa      scale \n0.09841425 9.29489907 \nMean cluster size:  127.258 points\n\nFinal standard error and CI\n(allowing for correlation of cluster process):\n            Estimate       S.E.  CI95.lo  CI95.hi Ztest     Zval\n(Intercept) 2.527647 0.08537972 2.360306 2.694988   *** 29.60477\n\n----------- cluster strength indices ----------\nSibling probability 0.009272504\nCount overdispersion index (on original window): 22.87956\nCluster strength: 0.009359288\n\nSpatial persistence index (over window): 0.1227116\n\nBound on distance from Poisson process (over window): 1\n     = min (1, 6262, 490195.4, 93874.58, 302.9036)\n\nBound on distance from MIXED Poisson process (over window): 1\n\nIntensity of parents of nonempty clusters: 0.09841425\nMean number of offspring in a nonempty cluster: 127.258\nIntensity of parents of clusters of more than one offspring point: 0.09841425\nRatio of parents to parents-plus-offspring: 0.007796785 (where 1 = Poisson \nprocess)\nProbability that a typical point belongs to a nontrivial cluster: 1\n\n\n\nKthomas.env_se &lt;- envelope(Kthomas_se, rmax = 5, Lest, nsim = 99, rank = 1, global = F)\n\nGenerating 99 simulated realisations of fitted cluster model  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(Kthomas.env_se, . - r ~ r, shade = c(\"hi\", \"lo\"), legend = F, main = \"Southeast: Thomas Model\")\n\n\n\n\n\n\nWest - Manavai\n\nKthomas_west &lt;- kppm(west_corals, ~ 1, \"Thomas\")\n\n\nKthomas_west\n\nStationary cluster point process model\nFitted to point pattern dataset 'west_corals'\nFitted by minimum contrast\n    Summary statistic: K-function\n\nUniform intensity:  1.488\n\nCluster model: Thomas process\nFitted cluster parameters:\n     kappa      scale \n0.03807945 0.82357753 \nMean cluster size:  39.07619 points\n\nCluster strength: phi =  3.081\nSibling probability: psib =  0.755\n\n\n\nsummary(Kthomas_west)\n\nStationary cluster point process model\nFitted to point pattern dataset 'west_corals'\nFitted by minimum contrast\n    Summary statistic: K-function\nMinimum contrast fit (object of class \"minconfit\")\nModel: Thomas process\nFitted by matching theoretical K function to west_corals\n\nInternal parameters fitted by minimum contrast ($par):\n     kappa     sigma2 \n0.03807945 0.67827996 \n\nFitted cluster parameters:\n     kappa      scale \n0.03807945 0.82357753 \nMean cluster size:  39.07619 points\n\nConverged successfully after 107 function evaluations\n\nStarting values of parameters:\n    kappa    sigma2 \n1.4880000 0.2521775 \nDomain of integration: [ 0 , 2.5 ]\nExponents: p= 2, q= 0.25\n\n----------- TREND  -----\nPoint process model\nFitted to data: X\nFitting method: maximum likelihood (Berman-Turner approximation)\nModel was fitted using glm()\nAlgorithm converged\nCall:\nppm.ppp(Q = X, trend = trend, rename.intercept = FALSE, covariates = covariates, \n    covfunargs = covfunargs, use.gam = use.gam, forcefit = TRUE, \n    improve.type = ppm.improve.type, improve.args = ppm.improve.args, \n    nd = nd, eps = eps)\nEdge correction: \"border\"\n    [border correction distance r = 0 ]\n--------------------------------------------------------------------------------\nQuadrature scheme (Berman-Turner) = data + dummy + weights\n\nData pattern:\nPlanar point pattern:  372 points\nAverage intensity 1.49 points per square unit\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\n\nDummy quadrature points:\n     40 x 40 grid of dummy points, plus 4 corner points\n     dummy spacing: 0.250 x 0.625 units\n\nOriginal dummy parameters: =\nPlanar point pattern:  1604 points\nAverage intensity 6.42 points per square unit\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\nQuadrature weights:\n     (counting weights based on 40 x 40 array of rectangular tiles)\nAll weights:\n    range: [0.0223, 0.156]  total: 250\nWeights on data points:\n    range: [0.0223, 0.0781] total: 21.7\nWeights on dummy points:\n    range: [0.0223, 0.156]  total: 228\n--------------------------------------------------------------------------------\nFITTED :\n\nStationary Poisson process\n\n---- Intensity: ----\n\n\nUniform intensity:\n[1] 1.488\n\n             Estimate       S.E.   CI95.lo   CI95.hi Ztest     Zval\n(Intercept) 0.3974329 0.05184758 0.2958135 0.4990523   *** 7.665409\n\n----------- gory details -----\n\nFitted regular parameters (theta):\n(Intercept) \n  0.3974329 \n\nFitted exp(theta):\n(Intercept) \n      1.488 \n\n----------- CLUSTER  -----------\nModel: Thomas process\n\nFitted cluster parameters:\n     kappa      scale \n0.03807945 0.82357753 \nMean cluster size:  39.07619 points\n\nFinal standard error and CI\n(allowing for correlation of cluster process):\n             Estimate    S.E.    CI95.lo  CI95.hi Ztest     Zval\n(Intercept) 0.3974329 0.30742 -0.2050991 0.999965       1.292801\n\n----------- cluster strength indices ----------\nSibling probability 0.7549615\nCount overdispersion index (on original window): 35.83397\nCluster strength: 3.080991\n\nSpatial persistence index (over window): 0\n\nBound on distance from Poisson process (over window): 1\n     = min (1, 744, 440896.2, 1683540, 652.9624)\n\nBound on distance from MIXED Poisson process (over window): 1\n\nIntensity of parents of nonempty clusters: 0.03807945\nMean number of offspring in a nonempty cluster: 39.07619\nIntensity of parents of clusters of more than one offspring point: 0.03807945\nRatio of parents to parents-plus-offspring: 0.02495247 (where 1 = Poisson \nprocess)\nProbability that a typical point belongs to a nontrivial cluster: 1\n\n\n\nKthomas.env_west &lt;- envelope(Kthomas_west, rmax = 5, Lest, nsim = 99, rank = 1, global = F)\n\nGenerating 99 simulated realisations of fitted cluster model  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(Kthomas.env_west, . - r ~ r, shade = c(\"hi\", \"lo\"), legend = F, main = \"West: Thomas Model\")\n\n\n\n\n\n\nNorth - Anakena\n\nKthomas_north &lt;- kppm(north_corals, ~ 1, \"Thomas\")\n\n\nKthomas_north\n\nStationary cluster point process model\nFitted to point pattern dataset 'north_corals'\nFitted by minimum contrast\n    Summary statistic: K-function\n\nUniform intensity:  0.544\n\nCluster model: Thomas process\nFitted cluster parameters:\n    kappa     scale \n0.2166116 0.5233174 \nMean cluster size:  2.511408 points\n\nCluster strength: phi =  1.341\nSibling probability: psib =  0.5729\n\n\n\nsummary(Kthomas_north)\n\nStationary cluster point process model\nFitted to point pattern dataset 'north_corals'\nFitted by minimum contrast\n    Summary statistic: K-function\nMinimum contrast fit (object of class \"minconfit\")\nModel: Thomas process\nFitted by matching theoretical K function to north_corals\n\nInternal parameters fitted by minimum contrast ($par):\n    kappa    sigma2 \n0.2166116 0.2738611 \n\nFitted cluster parameters:\n    kappa     scale \n0.2166116 0.5233174 \nMean cluster size:  2.511408 points\n\nConverged successfully after 89 function evaluations\n\nStarting values of parameters:\n   kappa   sigma2 \n0.544000 1.095114 \nDomain of integration: [ 0 , 2.5 ]\nExponents: p= 2, q= 0.25\n\n----------- TREND  -----\nPoint process model\nFitted to data: X\nFitting method: maximum likelihood (Berman-Turner approximation)\nModel was fitted using glm()\nAlgorithm converged\nCall:\nppm.ppp(Q = X, trend = trend, rename.intercept = FALSE, covariates = covariates, \n    covfunargs = covfunargs, use.gam = use.gam, forcefit = TRUE, \n    improve.type = ppm.improve.type, improve.args = ppm.improve.args, \n    nd = nd, eps = eps)\nEdge correction: \"border\"\n    [border correction distance r = 0 ]\n--------------------------------------------------------------------------------\nQuadrature scheme (Berman-Turner) = data + dummy + weights\n\nData pattern:\nPlanar point pattern:  136 points\nAverage intensity 0.544 points per square unit\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\n\nDummy quadrature points:\n     32 x 32 grid of dummy points, plus 4 corner points\n     dummy spacing: 0.31250 x 0.78125 units\n\nOriginal dummy parameters: =\nPlanar point pattern:  1028 points\nAverage intensity 4.11 points per square unit\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\nQuadrature weights:\n     (counting weights based on 32 x 32 array of rectangular tiles)\nAll weights:\n    range: [0.0488, 0.244]  total: 250\nWeights on data points:\n    range: [0.0488, 0.122]  total: 14.9\nWeights on dummy points:\n    range: [0.0488, 0.244]  total: 235\n--------------------------------------------------------------------------------\nFITTED :\n\nStationary Poisson process\n\n---- Intensity: ----\n\n\nUniform intensity:\n[1] 0.544\n\n             Estimate       S.E.    CI95.lo    CI95.hi Ztest      Zval\n(Intercept) -0.608806 0.08574929 -0.7768716 -0.4407405   *** -7.099837\n\n----------- gory details -----\n\nFitted regular parameters (theta):\n(Intercept) \n  -0.608806 \n\nFitted exp(theta):\n(Intercept) \n      0.544 \n\n----------- CLUSTER  -----------\nModel: Thomas process\n\nFitted cluster parameters:\n    kappa     scale \n0.2166116 0.5233174 \nMean cluster size:  2.511408 points\n\nFinal standard error and CI\n(allowing for correlation of cluster process):\n             Estimate      S.E.    CI95.lo    CI95.hi Ztest      Zval\n(Intercept) -0.608806 0.1560742 -0.9147059 -0.3029062   *** -3.900747\n\n----------- cluster strength indices ----------\nSibling probability 0.5729162\nCount overdispersion index (on original window): 3.372763\nCluster strength: 1.341461\n\nSpatial persistence index (over window): 0\n\nBound on distance from Poisson process (over window): 1\n     = min (1, 249.9261, 25153.21, 206010.5, 157.5172)\n\nBound on distance from MIXED Poisson process (over window): 1\n\nIntensity of parents of nonempty clusters: 0.1990327\nMean number of offspring in a nonempty cluster: 2.733219\nIntensity of parents of clusters of more than one offspring point: 0.154885\nRatio of parents to parents-plus-offspring: 0.2847861 (where 1 = Poisson \nprocess)\nProbability that a typical point belongs to a nontrivial cluster: 0.9188461\n\n\n\nKthomas.env_north &lt;- envelope(Kthomas_north, rmax = 5, Lest, nsim = 99, rank = 1, global = F)\n\nGenerating 99 simulated realisations of fitted cluster model  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(Kthomas.env_north, . - r ~ r, shade = c(\"hi\", \"lo\"), legend = F, main = \"North: Thomas Model\")"
  },
  {
    "objectID": "content/soil2.html",
    "href": "content/soil2.html",
    "title": "Soil",
    "section": "",
    "text": "soil &lt;- read.csv('soil_main.csv') %&gt;%\n  as_tibble() %&gt;%\n    mutate_at(vars(material, depth_mean, depth_cat), factor)\n\n\nsoil\n\n# A tibble: 70 × 4\n   material depth_cat depth_mean   mbc\n   &lt;fct&gt;    &lt;fct&gt;     &lt;fct&gt;      &lt;dbl&gt;\n 1 HAHTM    1         6.5         896.\n 2 HAHTM    2         20.5        262.\n 3 HAHTM    3         35.5        231.\n 4 HAHTM    4         53          121.\n 5 HAHTM    5         70          146.\n 6 HAHTM    6         80.5        212.\n 7 HAHTM    7         94          153.\n 8 HAHTM    1         3          3274.\n 9 HAHTM    2         11          197.\n10 HAHTM    3         22          144.\n# ℹ 60 more rows"
  },
  {
    "objectID": "content/soil2.html#april-4-2023",
    "href": "content/soil2.html#april-4-2023",
    "title": "Soil",
    "section": "",
    "text": "soil &lt;- read.csv('soil_main.csv') %&gt;%\n  as_tibble() %&gt;%\n    mutate_at(vars(material, depth_mean, depth_cat), factor)\n\n\nsoil\n\n# A tibble: 70 × 4\n   material depth_cat depth_mean   mbc\n   &lt;fct&gt;    &lt;fct&gt;     &lt;fct&gt;      &lt;dbl&gt;\n 1 HAHTM    1         6.5         896.\n 2 HAHTM    2         20.5        262.\n 3 HAHTM    3         35.5        231.\n 4 HAHTM    4         53          121.\n 5 HAHTM    5         70          146.\n 6 HAHTM    6         80.5        212.\n 7 HAHTM    7         94          153.\n 8 HAHTM    1         3          3274.\n 9 HAHTM    2         11          197.\n10 HAHTM    3         22          144.\n# ℹ 60 more rows"
  },
  {
    "objectID": "content/app2.html",
    "href": "content/app2.html",
    "title": "Supplementary Material II",
    "section": "",
    "text": "poci_size &lt;- read.csv('coral_size.csv')\n\n\npoci_size.gg &lt;- read_csv(\"poci_size_main.csv\")\n\nRows: 3639 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): level, Site, cover\ndbl (7): layer, class, id, area, enn, para, size_cm\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nggplot(poci_size.gg, aes(x = size_cm)) +\n  geom_histogram(fill = \"#333399\") + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(NULL) +\n  ggtitle(expression(\"Coral size \" (cm**2))) +\n  theme_bw() +\n  facet_wrap(~ Site, ncol = 1) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(size = 14), \n        axis.title.y = element_text(size = 14), \n        axis.text.y  = element_text(size= 10),\n        axis.text.x  = element_text(size = 12), \n        legend.text = element_text(size = 12),\n        legend.title = element_text(size = 12),\n        plot.title = element_text(hjust = 0.5, size = 14),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill = \"white\"),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major = element_blank(),\n        plot.background = element_rect(fill = \"white\"),\n        legend.background = element_rect(fill = \"white\"),\n        strip.text.x = element_text(size = 12, colour = \"#FFFFFF\"),\n        strip.background = element_rect(fill = '#000066')\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\npoci_size2 &lt;-\npoci_size %&gt;%\n  as_tibble() %&gt;%\n  mutate(size_cm = area*10000) %&gt;%\n  group_by(Site) %&gt;%\n  dplyr::summarize(mean = mean(size_cm), \n                   sd = sd(size_cm), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %&gt;%\n  mutate_at(vars(Site), factor) %&gt;%\n  add_column(\n          location = c('Anakena', 'Manavai', 'Southeast')\n          ) %&gt;%\n  mutate_at(vars(location), factor)\n\n\npoci_size2\n\n# A tibble: 3 × 8\n  Site   mean    sd     n    se lower.ci upper.ci location \n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    \n1 ana    111.  73.8   136  6.33     98.2     123. Anakena  \n2 man    151.  82.7   372  4.29    142.      159. Manavai  \n3 vhu    231. 137.   3131  2.44    227.      236. Southeast\n\n\n\npoci_size.gg &lt;-\n  poci_size %&gt;%\n  mutate(size_cm = area*10000) %&gt;%\n  as_tibble() %&gt;%\n  mutate_at(vars(Site), factor)\n\n\npoci_size.gg\n\n# A tibble: 3,639 × 10\n   layer level class    id Site  cover    area    enn  para size_cm\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     1 patch     1     2 ana   coral 0.0165  0.111   42.0   165. \n 2     1 patch     1     3 ana   coral 0.0261  0.111   32.1   261. \n 3     1 patch     1     4 ana   coral 0.0162  0.0598  44.3   162. \n 4     1 patch     1     5 ana   coral 0.0149  0.230   38.6   149. \n 5     1 patch     1     6 ana   coral 0.00788 0.535   61.5    78.8\n 6     1 patch     1     7 ana   coral 0.0148  0.532   41.1   148. \n 7     1 patch     1     8 ana   coral 0.0109  0.0598  50.6   109. \n 8     1 patch     1     9 ana   coral 0.0101  0.346   52.6   101. \n 9     1 patch     1    10 ana   coral 0.0262  0.192   38.4   262. \n10     1 patch     1    11 ana   coral 0.00620 0.137   71.6    62.0\n# ℹ 3,629 more rows\n\n\n\nmodel_1.lm &lt;- lm(size_cm ~ Site, data = poci_size.gg)\n\n\nmodel_1.lm\n\n\nCall:\nlm(formula = size_cm ~ Site, data = poci_size.gg)\n\nCoefficients:\n(Intercept)      Siteman      Sitevhu  \n     110.67        40.18       120.81  \n\n\n\nsummary(model_1.lm)\n\n\nCall:\nlm(formula = size_cm ~ Site, data = poci_size.gg)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-231.46  -91.09  -16.44   70.33 1160.47 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   110.67      11.18   9.896  &lt; 2e-16 ***\nSiteman        40.18      13.07   3.074  0.00212 ** \nSitevhu       120.81      11.42  10.575  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 130.4 on 3636 degrees of freedom\nMultiple R-squared:  0.05804,   Adjusted R-squared:  0.05752 \nF-statistic:   112 on 2 and 3636 DF,  p-value: &lt; 2.2e-16\n\n\n\npar(mfrow = c(2, 2))\nplot(model_1.lm)\n\n\n\n\n\nAnova(model_1.lm, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: size_cm\n              Sum Sq   Df F value    Pr(&gt;F)    \n(Intercept)  1665764    1  97.933 &lt; 2.2e-16 ***\nSite         3810826    2 112.022 &lt; 2.2e-16 ***\nResiduals   61845547 3636                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nmodel_1.aov &lt;- Anova(model_1.lm, type = \"III\")\n\n\nas.data.frame(model_1.aov)\n\n              Sum Sq   Df   F value       Pr(&gt;F)\n(Intercept)  1665764    1  97.93297 8.382392e-23\nSite         3810826    2 112.02231 6.156818e-48\nResiduals   61845547 3636        NA           NA\n\n\n\nflextable(model_1.aov)\n\n\nSum SqDfF valuePr(&gt;F)1,665,764197.932970.0000000000000000000000838239209769198883906904039666703,810,8262112.022310.00000000000000000000000000000000000000000000000615681861,845,5473,636\n\n\n\npost_hoc.model_1.lm &lt;- glht(model_1.lm, linfct = mcp(Site = 'Tukey'))\n\n\nmodel_1.aov &lt;- aov(size_cm ~ Site, data = poci_size.gg)\n\n\n# Tukey's test\ntukey &lt;- TukeyHSD(model_1.aov)\n\n\n# compact letter display\ncld &lt;- multcompLetters4(model_1.aov, tukey)\n\n\ncld\n\n$Site\nvhu man ana \n\"a\" \"b\" \"c\" \n\n\n\npoci_size3 &lt;- \npoci_size2 %&gt;%\n  add_column(\n          cld = c('a', 'b', 'c')\n          ) %&gt;%\nmutate_at(vars(cld), factor)\n\n\npoci_size3\n\n# A tibble: 3 × 9\n  Site   mean    sd     n    se lower.ci upper.ci location  cld  \n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;\n1 ana    111.  73.8   136  6.33     98.2     123. Anakena   a    \n2 man    151.  82.7   372  4.29    142.      159. Manavai   b    \n3 vhu    231. 137.   3131  2.44    227.      236. Southeast c"
  },
  {
    "objectID": "content/app2.html#methods-for-analyzing-percent-cover-of-pocilloporid-coral",
    "href": "content/app2.html#methods-for-analyzing-percent-cover-of-pocilloporid-coral",
    "title": "Supplementary Material II",
    "section": "Methods for analyzing percent cover of pocilloporid coral",
    "text": "Methods for analyzing percent cover of pocilloporid coral\nOne option for dealing with the 0 and 1 values is to transform them to be slightly less than one or more than zero. This approach assumes that the data are consistent with a common beta distribution. We fit five models to the data: three variations on the beta model and two linear model approaches.\nA beta regression assuming a common spatial aggregation \\(\\delta\\) or precision parameter (\\(\\phi\\)) (object named: mod.beta1). Notice that \\(\\delta= \\frac{1}{1+\\phi}\\) and \\(\\phi=\\frac{(1-\\delta)}{\\delta}\\). A beta regression assuming each reef location had a different \\(\\phi\\) parameter.\nOther options based on assuming that the residuals are normally distributed is to use a linear model with a logit-transformed response or a linear model with response untransformed proportions.\nFor comparison this applies a logit-transformation to the empirical proportions and then uses a standard linear regression model.\nRaw data - no transformation\n\np_cover_mod.aov1 &lt;- aov(pland_decimal ~ Site, data = p_cover)\nsummary(p_cover_mod.aov1)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nSite          2 12.699   6.350    2203 &lt;2e-16 ***\nResiduals   747  2.153   0.003                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\np_cover_mod.lm1 &lt;- lm(pland_decimal ~ Site, data = p_cover)\nsummary(p_cover_mod.lm1)\n\n\nCall:\nlm(formula = pland_decimal ~ Site, data = p_cover)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.267087 -0.022444 -0.006021  0.015304  0.242376 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.006021   0.003395   1.773  0.07656 .  \nSiteman     0.016423   0.004802   3.420  0.00066 ***\nSitevhu     0.283878   0.004802  59.122  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05368 on 747 degrees of freedom\nMultiple R-squared:  0.8551,    Adjusted R-squared:  0.8547 \nF-statistic:  2203 on 2 and 747 DF,  p-value: &lt; 2.2e-16\n\n\n\npar(mfrow = c(2, 2))\nplot(p_cover_mod.lm1)\n\n\n\n\n\nAnova(p_cover_mod.lm1, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: pland_decimal\n             Sum Sq  Df   F value  Pr(&gt;F)    \n(Intercept)  0.0091   1    3.1451 0.07656 .  \nSite        12.6991   2 2203.2548 &lt; 2e-16 ***\nResiduals    2.1528 747                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOne option to deal with 0 and 100 percent cover is to add and subtract a small amount to those values\n\ntransform01 &lt;- function(x) {\n  (x * (length(x) - 1) + 0.5) / (length(x))\n}\n\n\np_cover$pland_decimal_scaled &lt;- transform01(p_cover$pland_decimal)\n\nLogit-transformation\n\np_cover_mod.lm2 &lt;- lm(logit(pland_decimal_scaled) ~ Site, data = p_cover) \n\n\nsummary(p_cover_mod.lm2)\n\n\nCall:\nlm(formula = logit(pland_decimal_scaled) ~ Site, data = p_cover)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7875 -1.0925 -0.1617  0.7543  4.5854 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -6.22005    0.09621 -64.654  &lt; 2e-16 ***\nSiteman      0.61521    0.13606   4.522 7.13e-06 ***\nSitevhu      5.27828    0.13606  38.795  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.521 on 747 degrees of freedom\nMultiple R-squared:  0.7067,    Adjusted R-squared:  0.7059 \nF-statistic: 900.1 on 2 and 747 DF,  p-value: &lt; 2.2e-16\n\n\n\npar(mfrow = c(2, 2))\nplot(p_cover_mod.lm2)\n\n\n\n\n\nAnova(p_cover_mod.lm2, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: logit(pland_decimal_scaled)\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 9672.3   1 4180.11 &lt; 2.2e-16 ***\nSite        4165.2   2  900.06 &lt; 2.2e-16 ***\nResiduals   1728.5 747                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nGeneralized-linear model\n\np_cover_mod.glm1 &lt;- glm(pland_decimal ~ Site, family = binomial, data = p_cover)\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\nsummary(p_cover_mod.glm1)\n\n\nCall:\nglm(formula = pland_decimal ~ Site, family = binomial, data = p_cover)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -5.1064     0.8175  -6.246 4.21e-10 ***\nSiteman       1.3324     0.9223   1.445    0.149    \nSitevhu       4.2106     0.8293   5.077 3.83e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 161.289  on 749  degrees of freedom\nResidual deviance:  26.922  on 747  degrees of freedom\nAIC: 191.54\n\nNumber of Fisher Scoring iterations: 8\n\n\n\npar(mfrow = c(2, 2))\nplot(p_cover_mod.glm1)\n\n\n\n\n\nAnova(p_cover_mod.glm1, type = \"III\")\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: pland_decimal\n     LR Chisq Df Pr(&gt;Chisq)    \nSite   134.37  2  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBeta Regression I: \\(\\phi\\) does not vary\n\np_cover_mod.beta1 &lt;- betareg(pland_decimal_scaled ~ Site, data = p_cover, link = c(\"logit\"), link.phi = NULL, type = c(\"ML\"))\n\n\nsummary(p_cover_mod.beta1)\n\n\nCall:\nbetareg(formula = pland_decimal_scaled ~ Site, data = p_cover, link = c(\"logit\"), \n    link.phi = NULL, type = c(\"ML\"))\n\nStandardized weighted residuals 2:\n    Min      1Q  Median      3Q     Max \n-6.1915 -0.6623 -0.3219  0.6315  1.8412 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.28350    0.07391 -57.953   &lt;2e-16 ***\nSiteman      0.20537    0.08442   2.433    0.015 *  \nSitevhu      3.38355    0.07733  43.754   &lt;2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)   25.321      1.561   16.22   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  2094 on 4 Df\nPseudo R-squared: 0.7048\nNumber of iterations: 19 (BFGS) + 2 (Fisher scoring) \n\n\nBeta Regression II: \\(\\phi\\) does vary (by Site)\n\np_cover_mod.beta2 &lt;- betareg(pland_decimal_scaled ~ Site | Site, data = p_cover, link = c(\"logit\"), link.phi = NULL, type = c(\"ML\"))\n\nExtract AIC from beta regression models\n\np_cover_mod.beta1_aic &lt;- AIC(p_cover_mod.beta1)\np_cover_mod.beta2_aic &lt;- AIC(p_cover_mod.beta2)\n\n\np_cover_mod.beta1_aic\n\n[1] -4179.365\n\np_cover_mod.beta2_aic\n\n[1] -4259.399"
  },
  {
    "objectID": "content/code.html",
    "href": "content/code.html",
    "title": "Rendering with Code",
    "section": "",
    "text": "You can have code (R, Python or Julia) in your qmd file. You will need to have these installed on your local computer, but presumably you do already if you are adding code to your qmd files.\nx &lt;- c(5, 15, 25, 35, 45, 55)\ny &lt;- c(5, 20, 14, 32, 22, 38)\nlm(x ~ y)\n\n\nCall:\nlm(formula = x ~ y)\n\nCoefficients:\n(Intercept)            y  \n      1.056        1.326"
  },
  {
    "objectID": "content/code.html#modify-the-github-action",
    "href": "content/code.html#modify-the-github-action",
    "title": "Rendering with Code",
    "section": "Modify the GitHub Action",
    "text": "Modify the GitHub Action\nYou will need to change the GitHub Action in .github/workflows to install these and any needed packages in order for GitHub to be able to render your webpage. The GitHub Action install R since I used that in code.qmd. If you use Python or Julia instead, then you will need to update the GitHub Action to install those.\nIf getting the GitHub Action to work is too much hassle (and that definitely happens), you can alway render locally and publish to the gh-pages branch. If you do this, make sure to delete or rename the GitHub Action to something like\nrender-and-publish.old_yml\nso GitHub does not keep trying to run it. Nothing bad will happen if you don’t do this, but if you are not using the action (because it keeps failing), then you don’t need GitHub to run it."
  },
  {
    "objectID": "content/code.html#render-locally-and-publish-to-gh-pages-branch",
    "href": "content/code.html#render-locally-and-publish-to-gh-pages-branch",
    "title": "Rendering with Code",
    "section": "Render locally and publish to gh-pages branch",
    "text": "Render locally and publish to gh-pages branch\nTo render locally and push up to the gh-pages branch, open a terminal window and then cd to the directory with the Quarto project. Type this in the terminal:\nquarto render gh-pages"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html",
    "href": "content/bleaching_results_supp_material2.html",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "",
    "text": "rpn_plob\n\n# A tibble: 12 × 8\n   location depth transect group total_count total_points cover failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;       &lt;int&gt;        &lt;int&gt; &lt;dbl&gt;    &lt;int&gt;\n 1 north    dp    one      PLOB          104          126 0.825       22\n 2 north    dp    two      PLOB          113          126 0.897       13\n 3 north    sh    one      PLOB           83          126 0.659       43\n 4 north    sh    two      PLOB           88          126 0.698       38\n 5 se       dp    one      PLOB           34          124 0.274       90\n 6 se       dp    two      PLOB           28          105 0.267       77\n 7 se       sh    one      PLOB           35          126 0.278       91\n 8 se       sh    two      PLOB           15          126 0.119      111\n 9 west     dp    one      PLOB           89          126 0.706       37\n10 west     dp    two      PLOB           73          126 0.579       53\n11 west     sh    one      PLOB           74          126 0.587       52\n12 west     sh    two      PLOB          101          126 0.802       25"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#porites",
    "href": "content/bleaching_results_supp_material2.html#porites",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Porites",
    "text": "Porites\n\nGeneralized linear model\n\nplob.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_plob)\n\n\npar(mfrow = c(2, 2))\nplot(plob.glm)\n\n\n\n\n\nsummary(plob.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_plob)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            1.8245     0.1822  10.017  &lt; 2e-16 ***\nlocationse            -2.8154     0.2352 -11.973  &lt; 2e-16 ***\nlocationwest          -1.2368     0.2246  -5.506 3.68e-08 ***\ndepthsh               -1.0773     0.2267  -4.753 2.00e-06 ***\nlocationse:depthsh     0.6719     0.3138   2.142   0.0322 *  \nlocationwest:depthsh   1.3105     0.2956   4.434 9.25e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 396.020  on 11  degrees of freedom\nResidual deviance:  31.694  on  6  degrees of freedom\nAIC: 102.95\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nanova(plob.glm, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: cbind(total_count, failures)\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                              11     396.02              \nlocation        2   335.08         9      60.94 &lt; 2.2e-16 ***\ndepth           1     8.86         8      52.08  0.002922 ** \nlocation:depth  2    20.39         6      31.69 3.735e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nAnova(plob.glm, type = 'III')\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(total_count, failures)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        186.616  2  &lt; 2.2e-16 ***\ndepth            24.219  1  8.599e-07 ***\nlocation:depth   20.391  2  3.735e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ncoef(plob.glm)\n\n         (Intercept)           locationse         locationwest \n           1.8245493           -2.8154087           -1.2367626 \n             depthsh   locationse:depthsh locationwest:depthsh \n          -1.0773349            0.6719496            1.3105288 \n\n\n\nexp(coef(plob.glm))\n\n         (Intercept)           locationse         locationwest \n          6.20000000           0.05988024           0.29032258 \n             depthsh   locationse:depthsh locationwest:depthsh \n          0.34050179           1.95805107           3.70813397 \n\n\n\nexp(confint(plob.glm))\n\nWaiting for profiling to be done...\n\n\n                          2.5 %     97.5 %\n(Intercept)          4.40093397 9.00759101\nlocationse           0.03729519 0.09389047\nlocationwest         0.18504789 0.44730372\ndepthsh              0.21629108 0.52701265\nlocationse:depthsh   1.06152479 3.63669707\nlocationwest:depthsh 2.08752124 6.65798553\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_plob$groups &lt;- interaction(rpn_plob$location, rpn_plob$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model",
    "href": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_plob &lt;- with(rpn_plob, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest",
    "href": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_plob, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0 -0.07377    0.19208  -0.384    0.795    \n(north.sh) - (west.dp) == 0  0.15943    0.18835   0.846    0.795    \n(north.sh) - (se.sh) == 0    2.14346    0.20771  10.319  &lt; 2e-16 ***\n(north.sh) - (se.dp) == 0    1.73807    0.20078   8.657  &lt; 2e-16 ***\n(north.dp) - (west.sh) == 0  1.00357    0.22777   4.406 3.16e-05 ***\n(north.dp) - (west.dp) == 0  1.23676    0.22464   5.506 1.47e-07 ***\n(north.dp) - (se.sh) == 0    3.22079    0.24110  13.359  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0    2.81541    0.23515  11.973  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0    -2.21723    0.20893 -10.612  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0    -1.98403    0.20551  -9.654  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0    -1.81184    0.20204  -8.968  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0    -1.57865    0.19850  -7.953 8.88e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_plob2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"PLOB\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_plob2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth  mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.861 0.0505      2 0.0357     0.407    1.31 \n2 north    sh    0.679 0.0281      2 0.0198     0.426    0.931\n3 se       dp    0.270 0.00532     2 0.00376    0.223    0.318\n4 se       sh    0.198 0.112       2 0.0794    -0.810    1.21 \n5 west     dp    0.643 0.0898      2 0.0635    -0.164    1.45 \n6 west     sh    0.694 0.152       2 0.107     -0.667    2.06 \n\n\n\nbroom::tidy(plob.glm, conf.int = TRUE, exponentiate = TRUE)\n\n# A tibble: 6 × 7\n  term                 estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)            6.20       0.182     10.0  1.29e-23   4.40      9.01  \n2 locationse             0.0599     0.235    -12.0  4.94e-33   0.0373    0.0939\n3 locationwest           0.290      0.225     -5.51 3.68e- 8   0.185     0.447 \n4 depthsh                0.341      0.227     -4.75 2.00e- 6   0.216     0.527 \n5 locationse:depthsh     1.96       0.314      2.14 3.22e- 2   1.06      3.64  \n6 locationwest:depthsh   3.71       0.296      4.43 9.25e- 6   2.09      6.66  \n\n\n\nplob_regression_1 &lt;- tbl_regression(plob.glm, exponentiate = TRUE)\n\n\nplob_regression_1\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    location\n\n\n\n        north\n—\n—\n\n        se\n0.06\n0.04, 0.09\n&lt;0.001\n        west\n0.29\n0.19, 0.45\n&lt;0.001\n    depth\n\n\n\n        dp\n—\n—\n\n        sh\n0.34\n0.22, 0.53\n&lt;0.001\n    location * depth\n\n\n\n        se * sh\n1.96\n1.06, 3.64\n0.032\n        west * sh\n3.71\n2.09, 6.66\n&lt;0.001\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\n plob_regression_2 &lt;- plob.glm %&gt;%\n   tbl_regression(\n     exponentiate = TRUE) %&gt;%\n   add_global_p()\n\n\nplob_regression_2\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    location\n\n\n&lt;0.001\n        north\n—\n—\n\n        se\n0.06\n0.04, 0.09\n\n        west\n0.29\n0.19, 0.45\n\n    depth\n\n\n&lt;0.001\n        dp\n—\n—\n\n        sh\n0.34\n0.22, 0.53\n\n    location * depth\n\n\n&lt;0.001\n        se * sh\n1.96\n1.06, 3.64\n\n        west * sh\n3.71\n2.09, 6.66\n\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\nrpn_plob3 &lt;-\n  as_tibble(rpn_plob2)\n\n\nrpn_plob_summ &lt;-\n    rpn_plob3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_plob_summ\n\n# A tibble: 6 × 10\n  location depth  mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.861 0.0505      2 0.0357     0.407    1.31  North     15 m  \n2 north    sh    0.679 0.0281      2 0.0198     0.426    0.931 North     8 m   \n3 se       dp    0.270 0.00532     2 0.00376    0.223    0.318 Southeast 15 m  \n4 se       sh    0.198 0.112       2 0.0794    -0.810    1.21  Southeast 8 m   \n5 west     dp    0.643 0.0898      2 0.0635    -0.164    1.45  West      15 m  \n6 west     sh    0.694 0.152       2 0.107     -0.667    2.06  West      8 m   \n\n\n\nrpn_plob_summ.gg &lt;- rpn_plob_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_plob_summ.gg &lt;- rpn_plob_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_plob_summ.gg\n\n# A tibble: 6 × 10\n  location depth  mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.861 0.0505      2 0.0357     0.407    1.31  North     15 m  \n2 north    sh    0.679 0.0281      2 0.0198     0.426    0.931 North     8 m   \n3 se       dp    0.270 0.00532     2 0.00376    0.223    0.318 Southeast 15 m  \n4 se       sh    0.198 0.112       2 0.0794    -0.810    1.21  Southeast 8 m   \n5 west     dp    0.643 0.0898      2 0.0635    -0.164    1.45  West      15 m  \n6 west     sh    0.694 0.152       2 0.107     -0.667    2.06  West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_plob_2015.ggbarplot &lt;- ggplot(rpn_plob_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_plob_2015.ggbarplot &lt;- ggplot(rpn_plob_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_plob_2015.ggbarplot\n\n\n\n\n\nrpn_plob_bleach &lt;- rpn_bleach %&gt;%  \n  filter(group == 'PLOB' & status == 'BL') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_pb &lt;- rpn_bleach %&gt;% \n  filter(group == 'PLOB' & status == 'PB') %&gt;% \n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_pb\n\n# A tibble: 9 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                5\n2 north    dp    two               49\n3 north    sh    one               40\n4 north    sh    two               31\n5 se       dp    two                2\n6 west     dp    one               70\n7 west     dp    two               55\n8 west     sh    one               64\n9 west     sh    two               46\n\n\n\nrpn_plob_pb2 &lt;-\nas.data.frame(rpn_plob_pb) %&gt;%\n  add_row(location = 'se', depth = 'dp', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'se', depth = 'sh', transect = 'one', total_count = 0) %&gt;%\n  add_row(location = 'se', depth = 'sh', transect = 'two', total_count = 0)\n\n\nrpn_plob_pb.main &lt;- rpn_plob_pb2 %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_plob_pb.main\n\n   location depth transect total_count      cover failures\n1     north    dp      one           5 0.03968254      121\n2     north    dp      two          49 0.38888889       77\n3     north    sh      one          40 0.31746032       86\n4     north    sh      two          31 0.24603175       95\n5        se    dp      two           2 0.01587302      124\n6      west    dp      one          70 0.55555556       56\n7      west    dp      two          55 0.43650794       71\n8      west    sh      one          64 0.50793651       62\n9      west    sh      two          46 0.36507937       80\n10       se    dp      two           0 0.00000000      126\n11       se    sh      one           0 0.00000000      126\n12       se    sh      two           0 0.00000000      126\n\n\n\nplob_pb.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_plob_pb.main)\n\n\nanova(plob_pb.glm, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: cbind(total_count, failures)\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)    \nNULL                              11     449.57             \nlocation        2   377.30         9      72.27  &lt; 2e-16 ***\ndepth           1     0.00         8      72.27  1.00000    \nlocation:depth  2     7.66         6      64.61  0.02174 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_plob_pale &lt;- rpn_bleach %&gt;%  \n  filter(group == 'PLOB' & status == 'P') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_pale\n\n# A tibble: 12 × 4\n# Groups:   location, depth [6]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one               87\n 2 north    dp    two               52\n 3 north    sh    one               28\n 4 north    sh    two               37\n 5 se       dp    one               23\n 6 se       dp    two                2\n 7 se       sh    one               29\n 8 se       sh    two                9\n 9 west     dp    one               17\n10 west     dp    two               16\n11 west     sh    one                5\n12 west     sh    two               55\n\n\n\nrpn_plob_pale.main &lt;- rpn_plob_pale %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_plob_pale.main\n\n# A tibble: 12 × 6\n# Groups:   location, depth [6]\n   location depth transect total_count  cover failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 north    dp    one               87 0.690        39\n 2 north    dp    two               52 0.413        74\n 3 north    sh    one               28 0.222        98\n 4 north    sh    two               37 0.294        89\n 5 se       dp    one               23 0.183       103\n 6 se       dp    two                2 0.0159      124\n 7 se       sh    one               29 0.230        97\n 8 se       sh    two                9 0.0714      117\n 9 west     dp    one               17 0.135       109\n10 west     dp    two               16 0.127       110\n11 west     sh    one                5 0.0397      121\n12 west     sh    two               55 0.437        71\n\n\n\nplob_p.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_plob_pale.main)\n\n\nanova(plob_p.glm, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: cbind(total_count, failures)\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                              11     295.62              \nlocation        2  117.708         9     177.91 &lt; 2.2e-16 ***\ndepth           1    4.586         8     173.32   0.03223 *  \nlocation:depth  2   54.135         6     119.19 1.757e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_plob_healthy &lt;- rpn_bleach %&gt;%  \n  filter(group == 'PLOB' & status == 'H') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_healthy\n\n# A tibble: 10 × 4\n# Groups:   location, depth [6]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one               12\n 2 north    dp    two               12\n 3 north    sh    one               15\n 4 north    sh    two               20\n 5 se       dp    one               11\n 6 se       sh    one                6\n 7 se       sh    two                6\n 8 west     dp    one                2\n 9 west     dp    two                2\n10 west     sh    one                5\n\n\n\nrpn_plob_healthy2 &lt;-\nas.data.frame(rpn_plob_healthy) %&gt;%\n  add_row(location = 'se', depth = 'dp', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'west', depth = 'sh', transect = 'two', total_count = 0)\n\n\nrpn_plob_healthy2\n\n   location depth transect total_count\n1     north    dp      one          12\n2     north    dp      two          12\n3     north    sh      one          15\n4     north    sh      two          20\n5        se    dp      one          11\n6        se    sh      one           6\n7        se    sh      two           6\n8      west    dp      one           2\n9      west    dp      two           2\n10     west    sh      one           5\n11       se    dp      two           0\n12     west    sh      two           0\n\n\n\nrpn_plob_healthy.main &lt;- rpn_plob_healthy2 %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_plob_healthy.main \n\n   location depth transect total_count      cover failures\n1     north    dp      one          12 0.09523810      114\n2     north    dp      two          12 0.09523810      114\n3     north    sh      one          15 0.11904762      111\n4     north    sh      two          20 0.15873016      106\n5        se    dp      one          11 0.08730159      115\n6        se    sh      one           6 0.04761905      120\n7        se    sh      two           6 0.04761905      120\n8      west    dp      one           2 0.01587302      124\n9      west    dp      two           2 0.01587302      124\n10     west    sh      one           5 0.03968254      121\n11       se    dp      two           0 0.00000000      126\n12     west    sh      two           0 0.00000000      126\n\n\n\nplob_h.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_plob_healthy.main)\n\n\nanova(plob_h.glm, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: cbind(total_count, failures)\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)    \nNULL                              11     72.844             \nlocation        2   46.734         9     26.110 7.11e-11 ***\ndepth           1    2.045         8     24.064   0.1527    \nlocation:depth  2    0.448         6     23.616   0.7992    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#pocillopora",
    "href": "content/bleaching_results_supp_material2.html#pocillopora",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Pocillopora",
    "text": "Pocillopora\n\nrpn_bleach &lt;- read.csv('rpn_bleach_2015.csv') %&gt;%\n  as_tibble() %&gt;%\n  mutate_at(vars(location, depth, transect, group, status), factor)\n\n\nrpn_bleach\n\n# A tibble: 1,512 × 7\n   location depth transect point metric group status\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;int&gt;  &lt;int&gt; &lt;fct&gt; &lt;fct&gt; \n 1 north    sh    one          1      0 PLOB  PB    \n 2 north    sh    one          2     20 PLOB  PB    \n 3 north    sh    one          3     40 PLOB  PB    \n 4 north    sh    one          4     60 MA    HAL   \n 5 north    sh    one          5     80 TURF  na    \n 6 north    sh    one          6    100 TURF  na    \n 7 north    sh    one          7    120 TURF  na    \n 8 north    sh    one          8    140 PLOB  PB    \n 9 north    sh    one          9    160 PLOB  PB    \n10 north    sh    one         10    180 PLOB  PB    \n# ℹ 1,502 more rows\n\n\n\nrpn_summary &lt;- rpn_bleach %&gt;%  \n  group_by(location, depth, transect, group) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth', 'transect'. You can\noverride using the `.groups` argument.\n\n\n\nrpn_POCI &lt;- rpn_bleach %&gt;%  \n  filter(group == \"POCI\") %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_POCI\n\n# A tibble: 11 × 4\n# Groups:   location, depth [6]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one                7\n 2 north    dp    two                2\n 3 north    sh    two                1\n 4 se       dp    one               57\n 5 se       dp    two               58\n 6 se       sh    one               75\n 7 se       sh    two               60\n 8 west     dp    one               13\n 9 west     dp    two               14\n10 west     sh    one               15\n11 west     sh    two               18\n\n\n\nrpn_poci &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"POCI\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nrpn_poci\n\n# A tibble: 12 × 8\n   location depth transect group total_count total_points   cover failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;       &lt;int&gt;        &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;\n 1 north    dp    one      POCI            7          126 0.0556       119\n 2 north    dp    two      POCI            2          126 0.0159       124\n 3 north    sh    one      POCI            0          126 0            126\n 4 north    sh    two      POCI            1          126 0.00794      125\n 5 se       dp    one      POCI           57          124 0.460         67\n 6 se       dp    two      POCI           58          105 0.552         47\n 7 se       sh    one      POCI           75          126 0.595         51\n 8 se       sh    two      POCI           60          126 0.476         66\n 9 west     dp    one      POCI           13          126 0.103        113\n10 west     dp    two      POCI           14          126 0.111        112\n11 west     sh    one      POCI           15          126 0.119        111\n12 west     sh    two      POCI           18          126 0.143        108"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#pocillopora-1",
    "href": "content/bleaching_results_supp_material2.html#pocillopora-1",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Pocillopora",
    "text": "Pocillopora\n\nGeneralized linear model\n\npoci.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_poci)\n\n\npar(mfrow = c(2, 2))\nplot(poci.glm)\n\n\n\n\n\nsummary(poci.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_poci)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -3.2958     0.3395  -9.709  &lt; 2e-16 ***\nlocationse             3.3046     0.3643   9.072  &lt; 2e-16 ***\nlocationwest           1.1756     0.3959   2.970  0.00298 ** \ndepthsh               -2.2296     1.0579  -2.108  0.03507 *  \nlocationse:depthsh     2.3640     1.0736   2.202  0.02767 *  \nlocationwest:depthsh   2.4573     1.0934   2.247  0.02462 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 436.578  on 11  degrees of freedom\nResidual deviance:  10.347  on  6  degrees of freedom\nAIC: 69.293\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nAnova(poci.glm, type = 'III')\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(total_count, failures)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        178.902  2  &lt; 2.2e-16 ***\ndepth             7.491  1   0.006201 ** \nlocation:depth    8.513  2   0.014171 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_poci$groups &lt;- interaction(rpn_poci$location, rpn_poci$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-1",
    "href": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-1",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_poci &lt;- with(rpn_poci, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-1",
    "href": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-1",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_poci, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  -3.6329     1.0192  -3.564  0.00117 ** \n(north.sh) - (west.dp) == 0  -3.4052     1.0225  -3.330  0.00173 ** \n(north.sh) - (se.sh) == 0    -5.6686     1.0099  -5.613 1.19e-07 ***\n(north.sh) - (se.dp) == 0    -5.5342     1.0107  -5.476 2.18e-07 ***\n(north.dp) - (west.sh) == 0  -1.4033     0.3874  -3.622  0.00117 ** \n(north.dp) - (west.dp) == 0  -1.1756     0.3959  -2.970  0.00298 ** \n(north.dp) - (se.sh) == 0    -3.4389     0.3622  -9.495  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0    -3.3046     0.3643  -9.072  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0      2.0357     0.2254   9.030  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0      2.2634     0.2397   9.444  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0      1.9013     0.2288   8.311  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0      2.1290     0.2428   8.769  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nanova(poci.glm, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: cbind(total_count, failures)\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)    \nNULL                              11     436.58             \nlocation        2   417.52         9      19.06  &lt; 2e-16 ***\ndepth           1     0.20         8      18.86  0.65444    \nlocation:depth  2     8.51         6      10.35  0.01417 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_poci2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"POCI\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_poci2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth    mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288 \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544\n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29  \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158 \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282 \n\n\n\nrpn_poci3 &lt;-\n  as_tibble(rpn_poci2)\n\n\nrpn_poci_summ &lt;-\n    rpn_poci3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_poci_summ\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_poci_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-2",
    "href": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-2",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_poci &lt;- with(rpn_poci, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-2",
    "href": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-2",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_poci, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  -3.6329     1.0192  -3.564  0.00117 ** \n(north.sh) - (west.dp) == 0  -3.4052     1.0225  -3.330  0.00173 ** \n(north.sh) - (se.sh) == 0    -5.6686     1.0099  -5.613 1.19e-07 ***\n(north.sh) - (se.dp) == 0    -5.5342     1.0107  -5.476 2.18e-07 ***\n(north.dp) - (west.sh) == 0  -1.4033     0.3874  -3.622  0.00117 ** \n(north.dp) - (west.dp) == 0  -1.1756     0.3959  -2.970  0.00298 ** \n(north.dp) - (se.sh) == 0    -3.4389     0.3622  -9.495  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0    -3.3046     0.3643  -9.072  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0      2.0357     0.2254   9.030  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0      2.2634     0.2397   9.444  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0      1.9013     0.2288   8.311  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0      2.1290     0.2428   8.769  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_poci_bleach &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'BL') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_bleach\n\n# A tibble: 6 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                1\n2 se       dp    one                1\n3 se       dp    two                2\n4 se       sh    two                1\n5 west     dp    one                4\n6 west     sh    two                2\n\n\n\nrpn_poci_pb &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'PB') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_pb\n\n# A tibble: 8 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                2\n2 north    dp    two                1\n3 se       dp    one               27\n4 se       dp    two                9\n5 se       sh    one                2\n6 se       sh    two                5\n7 west     dp    two                2\n8 west     sh    one                1\n\n\n\nrpn_poci_pale &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'P') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_pale\n\n# A tibble: 10 × 4\n# Groups:   location, depth [5]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one                3\n 2 north    dp    two                1\n 3 se       dp    one               19\n 4 se       dp    two               16\n 5 se       sh    one               59\n 6 se       sh    two               45\n 7 west     dp    one                7\n 8 west     dp    two                8\n 9 west     sh    one               13\n10 west     sh    two                9\n\n\n\nrpn_poci_healthy &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'H') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_healthy\n\n# A tibble: 9 × 4\n# Groups:   location, depth [6]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                1\n2 north    sh    two                1\n3 se       dp    one               10\n4 se       sh    one               14\n5 se       sh    two                9\n6 west     dp    one                2\n7 west     dp    two                4\n8 west     sh    one                1\n9 west     sh    two                7"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#examine-bleaching-response-of-coral-groups",
    "href": "content/bleaching_results_supp_material2.html#examine-bleaching-response-of-coral-groups",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Examine bleaching response of coral groups",
    "text": "Examine bleaching response of coral groups\n\nrpn_plob_pb.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                family = binomial(link = \"logit\"), \n                data = rpn_plob_pb.main)\n\n\npar(mfrow = c(2, 2))\nplot(rpn_plob_pb.glm)\n\n\n\n\n\nsummary(rpn_plob_pb.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_plob_pb.main)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -1.2993     0.1535  -8.463  &lt; 2e-16 ***\nlocationse             -3.5290     0.7263  -4.859 1.18e-06 ***\nlocationwest            1.2834     0.1986   6.462 1.03e-10 ***\ndepthsh                 0.3635     0.2078   1.749   0.0803 .  \nlocationse:depthsh    -17.0748  1817.2897  -0.009   0.9925    \nlocationwest:depthsh   -0.6029     0.2742  -2.199   0.0279 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 449.568  on 11  degrees of freedom\nResidual deviance:  64.609  on  6  degrees of freedom\nAIC: 119.1\n\nNumber of Fisher Scoring iterations: 16\n\n\nAnova function from the car package\n\nAnova(rpn_plob_pb.glm, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(total_count, failures)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        197.689  2    &lt; 2e-16 ***\ndepth             3.082  1    0.07916 .  \nlocation:depth    7.657  2    0.02174 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_plob_pb.main\n\n   location depth transect total_count      cover failures\n1     north    dp      one           5 0.03968254      121\n2     north    dp      two          49 0.38888889       77\n3     north    sh      one          40 0.31746032       86\n4     north    sh      two          31 0.24603175       95\n5        se    dp      two           2 0.01587302      124\n6      west    dp      one          70 0.55555556       56\n7      west    dp      two          55 0.43650794       71\n8      west    sh      one          64 0.50793651       62\n9      west    sh      two          46 0.36507937       80\n10       se    dp      two           0 0.00000000      126\n11       se    sh      one           0 0.00000000      126\n12       se    sh      two           0 0.00000000      126\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_plob_pb.main$groups &lt;- interaction(rpn_plob_pb.main$location, rpn_plob_pb.main$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-3",
    "href": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-3",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nrpn_plob_pb.lm &lt;- with(rpn_plob_pb.main, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-3",
    "href": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-3",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(rpn_plob_pb.lm, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0   -0.6805     0.1891  -3.599   0.0016 ** \n(north.sh) - (west.dp) == 0   -0.9199     0.1884  -4.884 7.29e-06 ***\n(north.sh) - (se.sh) == 0     20.6038  1817.2895   0.011   1.0000    \n(north.sh) - (se.dp) == 0      3.8925     0.7236   5.379 6.73e-07 ***\n(north.dp) - (west.sh) == 0   -1.0439     0.1993  -5.239 1.29e-06 ***\n(north.dp) - (west.dp) == 0   -1.2834     0.1986  -6.462 1.14e-09 ***\n(north.dp) - (se.sh) == 0     20.2403  1817.2895   0.011   1.0000    \n(north.dp) - (se.dp) == 0      3.5290     0.7263   4.859 7.29e-06 ***\n(se.sh) - (west.sh) == 0     -21.2843  1817.2895  -0.012   1.0000    \n(se.sh) - (west.dp) == 0     -21.5238  1817.2895  -0.012   1.0000    \n(se.dp) - (west.sh) == 0      -4.5730     0.7212  -6.341 2.29e-09 ***\n(se.dp) - (west.dp) == 0      -4.8124     0.7210  -6.674 2.98e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#pocillopora-2",
    "href": "content/bleaching_results_supp_material2.html#pocillopora-2",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Pocillopora",
    "text": "Pocillopora\n\nGeneralized linear model\n\npoci.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_poci)\n\n\npar(mfrow = c(2, 2))\nplot(poci.glm)\n\n\n\n\n\nsummary(poci.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_poci)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -3.2958     0.3395  -9.709  &lt; 2e-16 ***\nlocationse             3.3046     0.3643   9.072  &lt; 2e-16 ***\nlocationwest           1.1756     0.3959   2.970  0.00298 ** \ndepthsh               -2.2296     1.0579  -2.108  0.03507 *  \nlocationse:depthsh     2.3640     1.0736   2.202  0.02767 *  \nlocationwest:depthsh   2.4573     1.0934   2.247  0.02462 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 436.578  on 11  degrees of freedom\nResidual deviance:  10.347  on  6  degrees of freedom\nAIC: 69.293\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_poci$groups &lt;- interaction(rpn_poci$location, rpn_poci$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-4",
    "href": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-4",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_poci &lt;- with(rpn_poci, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-4",
    "href": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-4",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_poci, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  -3.6329     1.0192  -3.564  0.00117 ** \n(north.sh) - (west.dp) == 0  -3.4052     1.0225  -3.330  0.00173 ** \n(north.sh) - (se.sh) == 0    -5.6686     1.0099  -5.613 1.19e-07 ***\n(north.sh) - (se.dp) == 0    -5.5342     1.0107  -5.476 2.18e-07 ***\n(north.dp) - (west.sh) == 0  -1.4033     0.3874  -3.622  0.00117 ** \n(north.dp) - (west.dp) == 0  -1.1756     0.3959  -2.970  0.00298 ** \n(north.dp) - (se.sh) == 0    -3.4389     0.3622  -9.495  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0    -3.3046     0.3643  -9.072  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0      2.0357     0.2254   9.030  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0      2.2634     0.2397   9.444  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0      1.9013     0.2288   8.311  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0      2.1290     0.2428   8.769  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_poci2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"POCI\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_poci2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth    mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288 \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544\n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29  \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158 \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282 \n\n\n\nrpn_poci3 &lt;-\n  as_tibble(rpn_poci2)\n\n\nrpn_poci_summ &lt;-\n    rpn_poci3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_poci_summ\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_poci_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#macroalgae",
    "href": "content/bleaching_results_supp_material2.html#macroalgae",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Macroalgae",
    "text": "Macroalgae\n\nGeneralized linear model\n\nrpn_ma &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"MA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nma.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_ma)\n\n\npar(mfrow = c(2, 2))\nplot(ma.glm)\n\n\n\n\n\nsummary(ma.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_ma)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -2.9957     0.2958 -10.127   &lt;2e-16 ***\nlocationse            -19.4459  2992.7957  -0.006    0.995    \nlocationwest           -0.1906     0.4378  -0.435    0.663    \ndepthsh                -0.3001     0.4503  -0.667    0.505    \nlocationse:depthsh     17.2163  2992.7959   0.006    0.995    \nlocationwest:depthsh   -0.2271     0.6911  -0.329    0.742    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 45.822  on 11  degrees of freedom\nResidual deviance: 20.051  on  6  degrees of freedom\nAIC: 57.317\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_ma$groups &lt;- interaction(rpn_ma$location, rpn_ma$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-5",
    "href": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-5",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_ma &lt;- with(rpn_ma, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-5",
    "href": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-5",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_ma, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)\n(north.sh) - (west.sh) == 0    0.4177     0.5348   0.781    1.000\n(north.sh) - (west.dp) == 0   -0.1095     0.4684  -0.234    1.000\n(north.sh) - (se.sh) == 0      2.2296     1.0579   2.108    0.351\n(north.sh) - (se.dp) == 0     19.1458  2992.7957   0.006    1.000\n(north.dp) - (west.sh) == 0    0.7178     0.5082   1.413    1.000\n(north.dp) - (west.dp) == 0    0.1906     0.4378   0.435    1.000\n(north.dp) - (se.sh) == 0      2.5297     1.0447   2.421    0.186\n(north.dp) - (se.dp) == 0     19.4459  2992.7957   0.006    1.000\n(se.sh) - (west.sh) == 0      -1.8119     1.0838  -1.672    0.851\n(se.sh) - (west.dp) == 0      -2.3391     1.0527  -2.222    0.289\n(se.dp) - (west.sh) == 0     -18.7281  2992.7957  -0.006    1.000\n(se.dp) - (west.dp) == 0     -19.2553  2992.7957  -0.006    1.000\n(Adjusted p values reported -- holm method)\n\n\n\nanova(ma.glm, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: cbind(total_count, failures)\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                              11     45.822              \nlocation        2   22.984         9     22.838 1.021e-05 ***\ndepth           1    1.003         8     21.835    0.3166    \nlocation:depth  2    1.784         6     20.051    0.4098    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_ma2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"MA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_ma2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth    mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0476  0.0112      2 0.00794  -0.0532   0.148 \n2 north    sh    0.0357  0.0168      2 0.0119   -0.116    0.187 \n3 se       dp    0       0           2 0         0        0     \n4 se       sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544\n5 west     dp    0.0397  0.0561      2 0.0397   -0.465    0.544 \n6 west     sh    0.0238  0.0224      2 0.0159   -0.178    0.225 \n\n\n\nrpn_ma3 &lt;-\n  as_tibble(rpn_ma2)\n\n\nrpn_ma_summ &lt;-\n    rpn_ma3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_ma_summ\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0476  0.0112      2 0.00794  -0.0532   0.148  North    15 m  \n2 north    sh    0.0357  0.0168      2 0.0119   -0.116    0.187  North    8 m   \n3 se       dp    0       0           2 0         0        0      Southea… 15 m  \n4 se       sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 Southea… 8 m   \n5 west     dp    0.0397  0.0561      2 0.0397   -0.465    0.544  West     15 m  \n6 west     sh    0.0238  0.0224      2 0.0159   -0.178    0.225  West     8 m   \n\n\n\nrpn_ma_summ.gg &lt;- rpn_ma_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_ma_summ.gg &lt;- rpn_ma_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_ma_summ.gg\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0476  0.0112      2 0.00794  -0.0532   0.148  North    15 m  \n2 north    sh    0.0357  0.0168      2 0.0119   -0.116    0.187  North    8 m   \n3 se       dp    0       0           2 0         0        0      Southea… 15 m  \n4 se       sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 Southea… 8 m   \n5 west     dp    0.0397  0.0561      2 0.0397   -0.465    0.544  West     15 m  \n6 west     sh    0.0238  0.0224      2 0.0159   -0.178    0.225  West     8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_ma_2015.ggbarplot &lt;- ggplot(rpn_ma_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_ma_2015.ggbarplot &lt;- ggplot(rpn_ma_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Macrolagae \")))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_ma_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#turf",
    "href": "content/bleaching_results_supp_material2.html#turf",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Turf",
    "text": "Turf\n\nGeneralized linear model\n\nrpn_turf &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"TURF\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) \n\n\nturf.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_turf)\n\n\npar(mfrow = c(2, 2))\nplot(turf.glm)\n\n\n\n\n\nsummary(turf.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_turf)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -4.4188     0.5808  -7.608 2.78e-14 ***\nlocationse            -18.0228  2992.7958  -0.006    0.995    \nlocationwest            0.8635     0.6959   1.241    0.215    \ndepthsh                 0.7053     0.7128   0.989    0.322    \nlocationse:depthsh     17.3175  2992.7958   0.006    0.995    \nlocationwest:depthsh   -0.2368     0.8661  -0.273    0.785    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 34.021  on 11  degrees of freedom\nResidual deviance: 16.535  on  6  degrees of freedom\nAIC: 52.682\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_turf$groups &lt;- interaction(rpn_turf$location, rpn_turf$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-6",
    "href": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-6",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_turf &lt;- with(rpn_turf, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-6",
    "href": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-6",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_turf, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                              Estimate Std. Error z value Pr(&gt;|z|)\n(north.sh) - (west.sh) == 0 -6.267e-01  5.155e-01  -1.216    1.000\n(north.sh) - (west.dp) == 0 -1.582e-01  5.636e-01  -0.281    1.000\n(north.sh) - (se.sh) == 0    7.053e-01  7.128e-01   0.989    1.000\n(north.sh) - (se.dp) == 0    1.873e+01  2.993e+03   0.006    1.000\n(north.dp) - (west.sh) == 0 -1.332e+00  6.576e-01  -2.026    0.514\n(north.dp) - (west.dp) == 0 -8.635e-01  6.959e-01  -1.241    1.000\n(north.dp) - (se.sh) == 0    1.567e-15  8.214e-01   0.000    1.000\n(north.dp) - (se.dp) == 0    1.802e+01  2.993e+03   0.006    1.000\n(se.sh) - (west.sh) == 0    -1.332e+00  6.576e-01  -2.026    0.514\n(se.sh) - (west.dp) == 0    -8.635e-01  6.959e-01  -1.241    1.000\n(se.dp) - (west.sh) == 0    -1.935e+01  2.993e+03  -0.006    1.000\n(se.dp) - (west.dp) == 0    -1.889e+01  2.993e+03  -0.006    1.000\n(Adjusted p values reported -- holm method)\n\n\n\nanova(turf.glm, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: cbind(total_count, failures)\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)   \nNULL                              11     34.021            \nlocation        2  11.6231         9     22.398 0.002993 **\ndepth           1   3.3953         8     19.002 0.065384 . \nlocation:depth  2   2.4673         6     16.535 0.291224   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_turf2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"TURF\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_turf2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0119 0.0168      2 0.0119   -0.139    0.163 \n2 north    sh    0.0238 0.0224      2 0.0159   -0.178    0.225 \n3 se       dp    0      0           2 0         0        0     \n4 se       sh    0.0119 0.0168      2 0.0119   -0.139    0.163 \n5 west     dp    0.0278 0.00561     2 0.00397  -0.0226   0.0782\n6 west     sh    0.0437 0.0393      2 0.0278   -0.309    0.397 \n\n\n\nrpn_turf3 &lt;-\n  as_tibble(rpn_turf2)\n\n\nrpn_turf_summ &lt;-\n    rpn_turf3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_turf_summ\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0119 0.0168      2 0.0119   -0.139    0.163  North     15 m  \n2 north    sh    0.0238 0.0224      2 0.0159   -0.178    0.225  North     8 m   \n3 se       dp    0      0           2 0         0        0      Southeast 15 m  \n4 se       sh    0.0119 0.0168      2 0.0119   -0.139    0.163  Southeast 8 m   \n5 west     dp    0.0278 0.00561     2 0.00397  -0.0226   0.0782 West      15 m  \n6 west     sh    0.0437 0.0393      2 0.0278   -0.309    0.397  West      8 m   \n\n\n\nrpn_turf_summ.gg &lt;- rpn_turf_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_turf_summ.gg &lt;- rpn_turf_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_turf_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0119 0.0168      2 0.0119   -0.139    0.163  North     15 m  \n2 north    sh    0.0238 0.0224      2 0.0159   -0.178    0.225  North     8 m   \n3 se       dp    0      0           2 0         0        0      Southeast 15 m  \n4 se       sh    0.0119 0.0168      2 0.0119   -0.139    0.163  Southeast 8 m   \n5 west     dp    0.0278 0.00561     2 0.00397  -0.0226   0.0782 West      15 m  \n6 west     sh    0.0437 0.0393      2 0.0278   -0.309    0.397  West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_turf_2015.ggbarplot &lt;- ggplot(rpn_turf_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_turf_2015.ggbarplot &lt;- ggplot(rpn_turf_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" turfllopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_turf_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#sand",
    "href": "content/bleaching_results_supp_material2.html#sand",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Sand",
    "text": "Sand\n\nGeneralized linear model\n\nrpn_sand &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"SAND\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nsand.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_sand)\n\n\npar(mfrow = c(2, 2))\nplot(sand.glm)\n\n\n\n\n\nsummary(sand.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_sand)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -3.0869     0.3083 -10.012  &lt; 2e-16 ***\nlocationse            -19.3547  2992.7957  -0.006    0.995    \nlocationwest            1.4486     0.3524   4.111 3.95e-05 ***\ndepthsh                 1.6140     0.3482   4.636 3.55e-06 ***\nlocationse:depthsh     -1.7120  4234.8629   0.000    1.000    \nlocationwest:depthsh   -2.5407     0.4584  -5.542 2.99e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 161.962  on 11  degrees of freedom\nResidual deviance:  28.599  on  6  degrees of freedom\nAIC: 72.931\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_sand$groups &lt;- interaction(rpn_sand$location, rpn_sand$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-7",
    "href": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-7",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_sand &lt;- with(rpn_sand, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-7",
    "href": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-7",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_sand, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0    1.0921     0.2932   3.724 0.002154 ** \n(north.sh) - (west.dp) == 0    0.1654     0.2351   0.704 1.000000    \n(north.sh) - (se.sh) == 0     21.0668  2996.2039   0.007 1.000000    \n(north.sh) - (se.dp) == 0     20.9688  2992.7957   0.007 1.000000    \n(north.dp) - (west.sh) == 0   -0.5220     0.3936  -1.326 1.000000    \n(north.dp) - (west.dp) == 0   -1.4486     0.3524  -4.111 0.000473 ***\n(north.dp) - (se.sh) == 0     19.4527  2996.2039   0.006 1.000000    \n(north.dp) - (se.dp) == 0     19.3547  2992.7957   0.006 1.000000    \n(se.sh) - (west.sh) == 0     -19.9747  2996.2039  -0.007 1.000000    \n(se.sh) - (west.dp) == 0     -20.9013  2996.2039  -0.007 1.000000    \n(se.dp) - (west.sh) == 0     -19.8767  2992.7957  -0.007 1.000000    \n(se.dp) - (west.dp) == 0     -20.8034  2992.7957  -0.007 1.000000    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nanova(sand.glm, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: cbind(total_count, failures)\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                              11    161.962              \nlocation        2   95.996         9     65.966 &lt; 2.2e-16 ***\ndepth           1    1.637         8     64.329    0.2007    \nlocation:depth  2   35.731         6     28.599 1.743e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_sand2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"SAND\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_sand2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0437 0.0505      2 0.0357    -0.410    0.497\n2 north    sh    0.187  0.00561     2 0.00397    0.136    0.237\n3 se       dp    0      0           2 0          0        0    \n4 se       sh    0      0           2 0          0        0    \n5 west     dp    0.163  0.118       2 0.0833    -0.896    1.22 \n6 west     sh    0.0714 0.0561      2 0.0397    -0.433    0.576\n\n\n\nrpn_sand3 &lt;-\n  as_tibble(rpn_sand2)\n\n\nrpn_sand_summ &lt;-\n    rpn_sand3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_sand_summ\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0437 0.0505      2 0.0357    -0.410    0.497 North     15 m  \n2 north    sh    0.187  0.00561     2 0.00397    0.136    0.237 North     8 m   \n3 se       dp    0      0           2 0          0        0     Southeast 15 m  \n4 se       sh    0      0           2 0          0        0     Southeast 8 m   \n5 west     dp    0.163  0.118       2 0.0833    -0.896    1.22  West      15 m  \n6 west     sh    0.0714 0.0561      2 0.0397    -0.433    0.576 West      8 m   \n\n\n\nrpn_sand_summ.gg &lt;- rpn_sand_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_sand_summ.gg &lt;- rpn_sand_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_sand_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0437 0.0505      2 0.0357    -0.410    0.497 North     15 m  \n2 north    sh    0.187  0.00561     2 0.00397    0.136    0.237 North     8 m   \n3 se       dp    0      0           2 0          0        0     Southeast 15 m  \n4 se       sh    0      0           2 0          0        0     Southeast 8 m   \n5 west     dp    0.163  0.118       2 0.0833    -0.896    1.22  West      15 m  \n6 west     sh    0.0714 0.0561      2 0.0397    -0.433    0.576 West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_sand_2015.ggbarplot &lt;- ggplot(rpn_sand_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_sand_2015.ggbarplot &lt;- ggplot(rpn_sand_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Sand \")))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_sand_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#bare-substrate",
    "href": "content/bleaching_results_supp_material2.html#bare-substrate",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Bare substrate",
    "text": "Bare substrate\n\nGeneralized linear model\n\nrpn_bare &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"BARE\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nbare.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_bare)\n\n\npar(mfrow = c(2, 2))\nplot(bare.glm)\n\n\n\n\n\nsummary(bare.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_bare)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)            -22.54    2996.20  -0.008    0.994\nlocationse              21.16    2996.20   0.007    0.994\nlocationwest            18.64    2996.20   0.006    0.995\ndepthsh                 19.97    2996.20   0.007    0.995\nlocationse:depthsh     -19.89    2996.20  -0.007    0.995\nlocationwest:depthsh   -38.61    4237.27  -0.009    0.993\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 221.002  on 11  degrees of freedom\nResidual deviance:  42.405  on  6  degrees of freedom\nAIC: 86.079\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_bare$groups &lt;- interaction(rpn_bare$location, rpn_bare$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-8",
    "href": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-8",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_bare &lt;- with(rpn_bare, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-8",
    "href": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-8",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_bare, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  1.997e+01  2.996e+03   0.007 1.000000    \n(north.sh) - (west.dp) == 0  1.335e+00  5.137e-01   2.599 0.074830 .  \n(north.sh) - (se.sh) == 0   -1.266e+00  2.888e-01  -4.383 0.000117 ***\n(north.sh) - (se.dp) == 0   -1.184e+00  2.950e-01  -4.014 0.000538 ***\n(north.dp) - (west.sh) == 0 -6.022e-11  4.237e+03   0.000 1.000000    \n(north.dp) - (west.dp) == 0 -1.864e+01  2.996e+03  -0.006 1.000000    \n(north.dp) - (se.sh) == 0   -2.124e+01  2.996e+03  -0.007 1.000000    \n(north.dp) - (se.dp) == 0   -2.116e+01  2.996e+03  -0.007 1.000000    \n(se.sh) - (west.sh) == 0     2.124e+01  2.996e+03   0.007 1.000000    \n(se.sh) - (west.dp) == 0     2.601e+00  4.771e-01   5.451 6.01e-07 ***\n(se.dp) - (west.sh) == 0     2.116e+01  2.996e+03   0.007 1.000000    \n(se.dp) - (west.dp) == 0     2.519e+00  4.809e-01   5.238 1.78e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nanova(bare.glm, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: cbind(total_count, failures)\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                              11    221.002              \nlocation        2  145.864         9     75.138 &lt; 2.2e-16 ***\ndepth           1    2.608         8     72.529    0.1063    \nlocation:depth  2   30.124         6     42.405 2.874e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_bare2 &lt;- read.csv('rpn_cover.csv')\n\n\nrpn_bare2\n\n   location depth transect  group total_count total_points\n1     north    dp      one   BARE           0          126\n2     north    dp      one    CCA           0          126\n3     north    dp      one     MA           5          126\n4     north    dp      one   PLOB         104          126\n5     north    dp      one   POCI           7          126\n6     north    dp      one   SAND          10          126\n7     north    dp      one SPONGE           0          126\n8     north    dp      one   TURF           0          126\n9     north    dp      two   BARE           0          126\n10    north    dp      two    CCA           0          126\n11    north    dp      two     MA           7          126\n12    north    dp      two   PLOB         113          126\n13    north    dp      two   POCI           2          126\n14    north    dp      two   SAND           1          126\n15    north    dp      two SPONGE           0          126\n16    north    dp      two   TURF           3          126\n17    north    sh      one   BARE           8          126\n18    north    sh      one    CCA           0          126\n19    north    sh      one     MA           6          126\n20    north    sh      one   PLOB          83          126\n21    north    sh      one   POCI           0          126\n22    north    sh      one   SAND          24          126\n23    north    sh      one SPONGE           0          126\n24    north    sh      one   TURF           5          126\n25    north    sh      two   BARE          10          126\n26    north    sh      two    CCA           0          126\n27    north    sh      two     MA           3          126\n28    north    sh      two   PLOB          88          126\n29    north    sh      two   POCI           1          126\n30    north    sh      two   SAND          23          126\n31    north    sh      two SPONGE           0          126\n32    north    sh      two   TURF           1          126\n33       se    dp      one   BARE          33          124\n34       se    dp      one    CCA           0          124\n35       se    dp      one     MA           0          124\n36       se    dp      one   PLOB          34          124\n37       se    dp      one   POCI          57          124\n38       se    dp      one   SAND           0          124\n39       se    dp      one SPONGE           0          124\n40       se    dp      one   TURF           0          124\n41       se    dp      two   BARE          13          105\n42       se    dp      two    CCA           6          105\n43       se    dp      two     MA           0          105\n44       se    dp      two   PLOB          28          105\n45       se    dp      two   POCI          58          105\n46       se    dp      two   SAND           0          105\n47       se    dp      two SPONGE           0          105\n48       se    dp      two   TURF           0          105\n49       se    sh      one   BARE           9          126\n50       se    sh      one    CCA           4          126\n51       se    sh      one     MA           0          126\n52       se    sh      one   PLOB          35          126\n53       se    sh      one   POCI          75          126\n54       se    sh      one   SAND           0          126\n55       se    sh      one SPONGE           0          126\n56       se    sh      one   TURF           3          126\n57       se    sh      two   BARE          45          126\n58       se    sh      two    CCA           5          126\n59       se    sh      two     MA           1          126\n60       se    sh      two   PLOB          15          126\n61       se    sh      two   POCI          60          126\n62       se    sh      two   SAND           0          126\n63       se    sh      two SPONGE           0          126\n64       se    sh      two   TURF           0          126\n65     west    dp      one   BARE           1          126\n66     west    dp      one    CCA           0          126\n67     west    dp      one     MA          10          126\n68     west    dp      one   PLOB          89          126\n69     west    dp      one   POCI          13          126\n70     west    dp      one   SAND          10          126\n71     west    dp      one SPONGE           0          126\n72     west    dp      one   TURF           3          126\n73     west    dp      two   BARE           4          126\n74     west    dp      two    CCA           0          126\n75     west    dp      two     MA           0          126\n76     west    dp      two   PLOB          73          126\n77     west    dp      two   POCI          14          126\n78     west    dp      two   SAND          31          126\n79     west    dp      two SPONGE           0          126\n80     west    dp      two   TURF           4          126\n81     west    sh      one   BARE           0          126\n82     west    sh      one    CCA           0          126\n83     west    sh      one     MA           5          126\n84     west    sh      one   PLOB          74          126\n85     west    sh      one   POCI          15          126\n86     west    sh      one   SAND          14          126\n87     west    sh      one SPONGE           9          126\n88     west    sh      one   TURF           9          126\n89     west    sh      two   BARE           0          126\n90     west    sh      two    CCA           0          126\n91     west    sh      two     MA           1          126\n92     west    sh      two   PLOB         101          126\n93     west    sh      two   POCI          18          126\n94     west    sh      two   SAND           4          126\n95     west    sh      two SPONGE           0          126\n96     west    sh      two   TURF           2          126\n\n\n\nrpn_bare2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"BARE\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_bare2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean     sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0      0          2 0         0         0    \n2 north    sh    0.0714 0.0112     2 0.00794  -0.0294    0.172\n3 se       dp    0.195  0.101      2 0.0712   -0.709     1.10 \n4 se       sh    0.214  0.202      2 0.143    -1.60      2.03 \n5 west     dp    0.0198 0.0168     2 0.0119   -0.131     0.171\n6 west     sh    0      0          2 0         0         0    \n\n\n\nrpn_bare3 &lt;-\n  as_tibble(rpn_bare2)\n\n\nrpn_bare_summ &lt;-\n    rpn_bare3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_bare_summ\n\n# A tibble: 6 × 10\n  location depth   mean     sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0          2 0         0         0     North     15 m  \n2 north    sh    0.0714 0.0112     2 0.00794  -0.0294    0.172 North     8 m   \n3 se       dp    0.195  0.101      2 0.0712   -0.709     1.10  Southeast 15 m  \n4 se       sh    0.214  0.202      2 0.143    -1.60      2.03  Southeast 8 m   \n5 west     dp    0.0198 0.0168     2 0.0119   -0.131     0.171 West      15 m  \n6 west     sh    0      0          2 0         0         0     West      8 m   \n\n\n\nrpn_bare_summ.gg &lt;- rpn_bare_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_bare_summ.gg &lt;- rpn_bare_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_bare_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean     sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0          2 0         0         0     North     15 m  \n2 north    sh    0.0714 0.0112     2 0.00794  -0.0294    0.172 North     8 m   \n3 se       dp    0.195  0.101      2 0.0712   -0.709     1.10  Southeast 15 m  \n4 se       sh    0.214  0.202      2 0.143    -1.60      2.03  Southeast 8 m   \n5 west     dp    0.0198 0.0168     2 0.0119   -0.131     0.171 West      15 m  \n6 west     sh    0      0          2 0         0         0     West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_bare_2015.ggbarplot &lt;- ggplot(rpn_bare_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_bare_2015.ggbarplot &lt;- ggplot(rpn_bare_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Bare \")))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_bare_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#cca-substrate",
    "href": "content/bleaching_results_supp_material2.html#cca-substrate",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "cca substrate",
    "text": "cca substrate\n\nGeneralized linear model\n\nrpn_cca &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"CCA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\ncca.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_cca)\n\n\npar(mfrow = c(2, 2))\nplot(cca.glm)\n\n\n\n\n\nsummary(cca.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_cca)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)          -2.454e+01  8.145e+03  -0.003    0.998\nlocationse            2.092e+01  8.145e+03   0.003    0.998\nlocationwest         -9.358e-09  1.152e+04   0.000    1.000\ndepthsh              -2.366e-08  1.152e+04   0.000    1.000\nlocationse:depthsh    3.196e-01  1.152e+04   0.000    1.000\nlocationwest:depthsh  2.365e-08  1.629e+04   0.000    1.000\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 44.2469  on 11  degrees of freedom\nResidual deviance:  9.6636  on  6  degrees of freedom\nAIC: 31.936\n\nNumber of Fisher Scoring iterations: 19\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_cca$groups &lt;- interaction(rpn_cca$location, rpn_cca$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-9",
    "href": "content/bleaching_results_supp_material2.html#create-a-post-hoc-model-9",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_cca &lt;- with(rpn_cca, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-9",
    "href": "content/bleaching_results_supp_material2.html#determine-the-post-hoc-comparisons-of-interest-9",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_cca, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                              Estimate Std. Error z value Pr(&gt;|z|)\n(north.sh) - (west.sh) == 0  3.412e-12  1.152e+04   0.000        1\n(north.sh) - (west.dp) == 0  3.501e-15  1.152e+04   0.000        1\n(north.sh) - (se.sh) == 0   -2.124e+01  8.145e+03  -0.003        1\n(north.sh) - (se.dp) == 0   -2.092e+01  8.145e+03  -0.003        1\n(north.dp) - (west.sh) == 0 -1.819e-08  1.152e+04   0.000        1\n(north.dp) - (west.dp) == 0 -1.819e-08  1.152e+04   0.000        1\n(north.dp) - (se.sh) == 0   -2.124e+01  8.145e+03  -0.003        1\n(north.dp) - (se.dp) == 0   -2.092e+01  8.145e+03  -0.003        1\n(se.sh) - (west.sh) == 0     2.124e+01  8.145e+03   0.003        1\n(se.sh) - (west.dp) == 0     2.124e+01  8.145e+03   0.003        1\n(se.dp) - (west.sh) == 0     2.092e+01  8.145e+03   0.003        1\n(se.dp) - (west.dp) == 0     2.092e+01  8.145e+03   0.003        1\n(Adjusted p values reported -- holm method)\n\n\n\nanova(cca.glm, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: cbind(total_count, failures)\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                              11     44.247              \nlocation        2   34.221         9     10.026 3.707e-08 ***\ndepth           1    0.362         8      9.664    0.5471    \nlocation:depth  2    0.000         6      9.664    1.0000    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_cca2 &lt;- read.csv('rpn_cover.csv')\n\n\nrpn_cca2\n\n   location depth transect  group total_count total_points\n1     north    dp      one   BARE           0          126\n2     north    dp      one    CCA           0          126\n3     north    dp      one     MA           5          126\n4     north    dp      one   PLOB         104          126\n5     north    dp      one   POCI           7          126\n6     north    dp      one   SAND          10          126\n7     north    dp      one SPONGE           0          126\n8     north    dp      one   TURF           0          126\n9     north    dp      two   BARE           0          126\n10    north    dp      two    CCA           0          126\n11    north    dp      two     MA           7          126\n12    north    dp      two   PLOB         113          126\n13    north    dp      two   POCI           2          126\n14    north    dp      two   SAND           1          126\n15    north    dp      two SPONGE           0          126\n16    north    dp      two   TURF           3          126\n17    north    sh      one   BARE           8          126\n18    north    sh      one    CCA           0          126\n19    north    sh      one     MA           6          126\n20    north    sh      one   PLOB          83          126\n21    north    sh      one   POCI           0          126\n22    north    sh      one   SAND          24          126\n23    north    sh      one SPONGE           0          126\n24    north    sh      one   TURF           5          126\n25    north    sh      two   BARE          10          126\n26    north    sh      two    CCA           0          126\n27    north    sh      two     MA           3          126\n28    north    sh      two   PLOB          88          126\n29    north    sh      two   POCI           1          126\n30    north    sh      two   SAND          23          126\n31    north    sh      two SPONGE           0          126\n32    north    sh      two   TURF           1          126\n33       se    dp      one   BARE          33          124\n34       se    dp      one    CCA           0          124\n35       se    dp      one     MA           0          124\n36       se    dp      one   PLOB          34          124\n37       se    dp      one   POCI          57          124\n38       se    dp      one   SAND           0          124\n39       se    dp      one SPONGE           0          124\n40       se    dp      one   TURF           0          124\n41       se    dp      two   BARE          13          105\n42       se    dp      two    CCA           6          105\n43       se    dp      two     MA           0          105\n44       se    dp      two   PLOB          28          105\n45       se    dp      two   POCI          58          105\n46       se    dp      two   SAND           0          105\n47       se    dp      two SPONGE           0          105\n48       se    dp      two   TURF           0          105\n49       se    sh      one   BARE           9          126\n50       se    sh      one    CCA           4          126\n51       se    sh      one     MA           0          126\n52       se    sh      one   PLOB          35          126\n53       se    sh      one   POCI          75          126\n54       se    sh      one   SAND           0          126\n55       se    sh      one SPONGE           0          126\n56       se    sh      one   TURF           3          126\n57       se    sh      two   BARE          45          126\n58       se    sh      two    CCA           5          126\n59       se    sh      two     MA           1          126\n60       se    sh      two   PLOB          15          126\n61       se    sh      two   POCI          60          126\n62       se    sh      two   SAND           0          126\n63       se    sh      two SPONGE           0          126\n64       se    sh      two   TURF           0          126\n65     west    dp      one   BARE           1          126\n66     west    dp      one    CCA           0          126\n67     west    dp      one     MA          10          126\n68     west    dp      one   PLOB          89          126\n69     west    dp      one   POCI          13          126\n70     west    dp      one   SAND          10          126\n71     west    dp      one SPONGE           0          126\n72     west    dp      one   TURF           3          126\n73     west    dp      two   BARE           4          126\n74     west    dp      two    CCA           0          126\n75     west    dp      two     MA           0          126\n76     west    dp      two   PLOB          73          126\n77     west    dp      two   POCI          14          126\n78     west    dp      two   SAND          31          126\n79     west    dp      two SPONGE           0          126\n80     west    dp      two   TURF           4          126\n81     west    sh      one   BARE           0          126\n82     west    sh      one    CCA           0          126\n83     west    sh      one     MA           5          126\n84     west    sh      one   PLOB          74          126\n85     west    sh      one   POCI          15          126\n86     west    sh      one   SAND          14          126\n87     west    sh      one SPONGE           9          126\n88     west    sh      one   TURF           9          126\n89     west    sh      two   BARE           0          126\n90     west    sh      two    CCA           0          126\n91     west    sh      two     MA           1          126\n92     west    sh      two   PLOB         101          126\n93     west    sh      two   POCI          18          126\n94     west    sh      two   SAND           4          126\n95     west    sh      two SPONGE           0          126\n96     west    sh      two   TURF           2          126\n\n\n\nrpn_cca2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"CCA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_cca2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0      0           2 0         0        0     \n2 north    sh    0      0           2 0         0        0     \n3 se       dp    0.0286 0.0404      2 0.0286   -0.334    0.392 \n4 se       sh    0.0357 0.00561     2 0.00397  -0.0147   0.0861\n5 west     dp    0      0           2 0         0        0     \n6 west     sh    0      0           2 0         0        0     \n\n\n\nrpn_cca3 &lt;-\n  as_tibble(rpn_cca2)\n\n\nrpn_cca_summ &lt;-\n    rpn_cca3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_cca_summ\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0           2 0         0        0      North     15 m  \n2 north    sh    0      0           2 0         0        0      North     8 m   \n3 se       dp    0.0286 0.0404      2 0.0286   -0.334    0.392  Southeast 15 m  \n4 se       sh    0.0357 0.00561     2 0.00397  -0.0147   0.0861 Southeast 8 m   \n5 west     dp    0      0           2 0         0        0      West      15 m  \n6 west     sh    0      0           2 0         0        0      West      8 m   \n\n\n\nrpn_cca_summ.gg &lt;- rpn_cca_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_cca_summ.gg &lt;- rpn_cca_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_cca_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0           2 0         0        0      North     15 m  \n2 north    sh    0      0           2 0         0        0      North     8 m   \n3 se       dp    0.0286 0.0404      2 0.0286   -0.334    0.392  Southeast 15 m  \n4 se       sh    0.0357 0.00561     2 0.00397  -0.0147   0.0861 Southeast 8 m   \n5 west     dp    0      0           2 0         0        0      West      15 m  \n6 west     sh    0      0           2 0         0        0      West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_cca_2015.ggbarplot &lt;- ggplot(rpn_cca_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_cca_2015.ggbarplot &lt;- ggplot(rpn_cca_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" ccallopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_cca_2015.ggbarplot\n\n\n\n\n\nrpn_crw &lt;- read_delim('rpn_crw.txt', delim = \" \")\n\nNew names:\n• `` -&gt; `...8`\n• `` -&gt; `...9`\n• `` -&gt; `...10`\n• `` -&gt; `...11`\n• `` -&gt; `...13`\n• `` -&gt; `...14`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 14005 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (3): MM, DD, BAA_7day_max\ndbl (6): YYYY, SST_MIN, SST_MAX, SST, ...11, 90th_HS\nlgl (8):        SSTA    , ...8, ...9, ...10, ...13, ...14, DHW,         \n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n#{r} #rpn_crw.main &lt;- write_csv(rpn_crw, 'rpn_crw.csv') #\n\nrpn_crw.main &lt;- read_csv('rpn_crw.csv')\n\nRows: 14005 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (7): year, month, day, sst_min, sst_max, sst, dhw\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nrpn_crw.main\n\n# A tibble: 14,005 × 7\n    year month   day sst_min sst_max   sst   dhw\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  1985     1     1    24.1    24.2  24.1     0\n 2  1985     1     2    24.2    24.3  24.2     0\n 3  1985     1     3    24.3    24.3  24.3     0\n 4  1985     1     4    24.4    24.4  24.4     0\n 5  1985     1     5    24.5    24.6  24.5     0\n 6  1985     1     6    25.2    25.3  25.3     0\n 7  1985     1     7    25.0    25.2  25.2     0\n 8  1985     1     8    25.7    25.9  25.9     0\n 9  1985     1     9    26      26.2  26.2     0\n10  1985     1    10    26.2    26.3  26.3     0\n# ℹ 13,995 more rows\n\n\n\nrpn_crw.main2 &lt;- \n  rpn_crw.main %&gt;%\n  mutate(date = make_date(year, month, day)) \n\n#%&gt;%\n#  filter(date &gt; 2015-01-01)\n\n\nrpn_crw.main2\n\n# A tibble: 14,005 × 8\n    year month   day sst_min sst_max   sst   dhw date      \n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;    \n 1  1985     1     1    24.1    24.2  24.1     0 1985-01-01\n 2  1985     1     2    24.2    24.3  24.2     0 1985-01-02\n 3  1985     1     3    24.3    24.3  24.3     0 1985-01-03\n 4  1985     1     4    24.4    24.4  24.4     0 1985-01-04\n 5  1985     1     5    24.5    24.6  24.5     0 1985-01-05\n 6  1985     1     6    25.2    25.3  25.3     0 1985-01-06\n 7  1985     1     7    25.0    25.2  25.2     0 1985-01-07\n 8  1985     1     8    25.7    25.9  25.9     0 1985-01-08\n 9  1985     1     9    26      26.2  26.2     0 1985-01-09\n10  1985     1    10    26.2    26.3  26.3     0 1985-01-10\n# ℹ 13,995 more rows\n\n\n\nrpn_crw.main3 &lt;- \n  rpn_crw.main2 %&gt;%\n  filter(date &gt;= '2014-01-01',\n         date &lt;= '2015-12-31') %&gt;% \n  dplyr::select(sst_max, dhw, date) %&gt;%\n  pivot_longer(!date, names_to = \"metric\", values_to = \"value\")\n\n\nrpn_crw.main3\n\n# A tibble: 1,460 × 3\n   date       metric  value\n   &lt;date&gt;     &lt;chr&gt;   &lt;dbl&gt;\n 1 2014-01-01 sst_max  24.3\n 2 2014-01-01 dhw       0  \n 3 2014-01-02 sst_max  23.9\n 4 2014-01-02 dhw       0  \n 5 2014-01-03 sst_max  23.8\n 6 2014-01-03 dhw       0  \n 7 2014-01-04 sst_max  23.7\n 8 2014-01-04 dhw       0  \n 9 2014-01-05 sst_max  23.8\n10 2014-01-05 dhw       0  \n# ℹ 1,450 more rows\n\n\n\nrpn_crw.main4 &lt;- \n  rpn_crw.main3 %&gt;%\n  pivot_wider(names_from = metric, values_from = value)\n\n\nrpn_crw.main4\n\n# A tibble: 730 × 3\n   date       sst_max   dhw\n   &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 2014-01-01    24.3     0\n 2 2014-01-02    23.9     0\n 3 2014-01-03    23.8     0\n 4 2014-01-04    23.7     0\n 5 2014-01-05    23.8     0\n 6 2014-01-06    24.0     0\n 7 2014-01-07    24.2     0\n 8 2014-01-08    24.4     0\n 9 2014-01-09    24.4     0\n10 2014-01-10    24.4     0\n# ℹ 720 more rows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrpn_crw.main.gg &lt;- ggplot(data = rpn_crw.main4, aes(x = date, y = sst_max)) +\n  geom_line(aes(color = \"SST Max (°C)\")) +\n#  ylim(0, 30) +\n#  scale_fill_discrete(name = \"Dose\", labels = c(\"A\", \"B\")) +\n  geom_line(aes(y = dhw, color = \"Degree Heating Week\")) +\n  scale_y_continuous(limits = c(0, 30), breaks = c(0, 5, 10, 15, 20, 25, 30)) +\n  #scale_x_continuous(breaks = seq(0, 336, 24)) +\n  scale_x_date(date_breaks = \"3 month\", date_labels = \"%b %y\") +\n  scale_color_manual(values = c(\"red2\", \"blue\"))+\n  labs(x = NULL) +\n  theme(#strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        #strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        #panel.spacing.x = unit(1, \"cm\"),\n        #panel.spacing.y = unit(0.5, \"cm\"),\n        #panel.spacing = unit(1, \"lines\"),\n        axis.ticks.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        legend.position = 'right',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        #axis.text.x = element_text(size = 12),\n        axis.text.x = element_text(angle = 60, hjust = 0.40, size = 8),\n        axis.title.y = element_blank(),\n        legend.title = element_blank())\n\n\nrpn_crw.main.gg\n\n\n\n\n\nscale = 0.25\n\n\npkpd &lt;- ggplot(data = rpn_crw.main4, aes(x = date, y = sst_max)) +\n#  scale_y_continuous(breaks = c(5, 5), limits = c(0, 50)) +\n#  ylim(0, 40) +\n  geom_line(aes(color = \"Maximum Sea Surface Temperature\")) +\n  geom_line(aes(y = dhw * scale, color = \"Degree Heating Week\"))+\n#  scale_x_continuous(breaks = seq(0, 336, 24)) +\n  scale_y_continuous(sec.axis = sec_axis(~.*scale, name = \"DHW\")) +\n  labs(x = \"Date\", y = \"SST Max (C)\", color = \"\") +\n  scale_color_manual(values = c(\"orange2\", \"gray50\"))\n\nprint(pkpd)\n\n\n\n\n\n#-----------------------------------------------------------------------------\n# Rescale the second y axis by \n#   - subtracting its minimum value (to set it to start at 0)\n#   - scaling so that it has the same range as the 'y1' variable\n#   - offsettting it by the minimum value of y1\n#-----------------------------------------------------------------------------\na            &lt;- range(rpn_crw.main4[['sst_max']])\n\n\na\n\n[1] 19.39 26.99\n\n\n\nb            &lt;- range(rpn_crw.main4[['dhw']])\n\n\nscale_factor &lt;- diff(a)/diff(b)\n\n\nrpn_crw.main4[['sst_max']]      &lt;- ((rpn_crw.main4[['sst_max']] - b[1]) * scale_factor) + a[1]\n\n\n#-----------------------------------------------------------------------------\n# Need to define the second axis transformation to be the inverse of the data\n# transformation to everything cancels out appropriately\n#-----------------------------------------------------------------------------\ntrans &lt;- ~ ((. - a[1]) / scale_factor) + b[1]\n\n\npkpd &lt;- ggplot(data = rpn_crw.main4, aes(x = date, y = sst_max)) +\n#  scale_y_continuous(breaks = c(5, 5), limits = c(0, 50)) +\n#  ylim(0, 40) +\n  geom_line(aes(color = \"Maximum Sea Surface Temperature\")) +\n  geom_line(aes(y = dhw * scale, color = \"Degree Heating Week\"))+\n#  scale_x_continuous(breaks = seq(0, 336, 24)) +\n  scale_y_continuous(sec.axis = sec_axis(trans = trans, name = 'dhw'), \n                     breaks = c(0, 500)) +\n  labs(x = \"Date\", y = \"SST Max (C)\", color = \"\") +\n  scale_color_manual(values = c(\"orange2\", \"gray50\"))\n\nprint(pkpd)\n\n\n\n\n\nmy_data &lt;- read_tsv(\"https://coralreefwatch.noaa.gov/product/vs/data/easter_island.txt\")\n\nRows: 14229 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): Name:\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhead(my_data)\n\n# A tibble: 6 × 1\n  `Name:`                       \n  &lt;chr&gt;                         \n1 Easter Island, Chile          \n2 Polygon Middle Longitude:     \n3 -109.3250                     \n4 Polygon Middle Latitude:      \n5 -27.1750                      \n6 Averaged Maximum Monthly Mean:\n\n\n\nwrite_csv(rpn_crw, \".csv\")"
  },
  {
    "objectID": "content/rpn_sppa.html",
    "href": "content/rpn_sppa.html",
    "title": "SPPA",
    "section": "",
    "text": "vhu_csv &lt;- read.csv(\"vhu_centroids.csv\")\n\n\nvhu_csv2 &lt;- as_tibble(vhu_csv)\n\n\nvhu_csv2 \n\n# A tibble: 3,131 × 6\n   layer level class    id       x     y\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1     1 patch     0     1 0.0775   24.7\n 2     1 patch     0     2 0.0588   24.0\n 3     1 patch     0     3 0.0368   23.7\n 4     1 patch     0     4 0.0318   23.4\n 5     1 patch     0     5 0.0501   23.1\n 6     1 patch     0     6 0.0125   22.8\n 7     1 patch     0     7 0.0794   21.7\n 8     1 patch     0     8 0.00269  21.0\n 9     1 patch     0     9 0.0485   20.8\n10     1 patch     0    10 0.0824   16.7\n# ℹ 3,121 more rows\n\n\nDefine window for spatial pattern analyses based on the extent defined above\n\nvhu_window &lt;- owin(c(0, 10), c(0, 25))\n\n\nattach(vhu_window)\n\n\nvhu_corals &lt;- ppp(vhu_csv2$x, vhu_csv2$y, window = vhu_window)\n\nSummary information\n\nsummary(vhu_corals)\n\nPlanar point pattern:  3131 points\nAverage intensity 12.524 points per square unit\n\nCoordinates are given to 7 decimal places\n\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\n\n\nThis summary shows there are 3131 points (pocilloporid coral colony) and provides the observed, lambda. The density plot can be a helpful visualization of intensity of points across the plot. By plotting the spatial intensity this way, spatial trends in the point occurrences that may violate the assumption of homogeneous point process.\nDensity plots\n\nplot(\n  density(vhu_corals)\n)\n\n\n\n\nAlter smoothing parameter\n\nplot(\n  density(vhu_corals, 1)\n)  \n\n\n\n\nContour plot\n\ncontour(\n  density(vhu_corals, 1)\n)\n\n\n\n\nWe can also make tallies of counts of point locations based on quadrats overlaid on the plot. To determine whether these quadrat counts conform to CSR (i.e., a homogeneous Poisson process), use a simple Chi-Square test statistic.\nQuadrat counts\nCounts in 10 x 25 m quadrats\n\nvhu_Q &lt;- quadratcount(vhu_corals, nx = 10, ny = 25)\n\nPlot\n\nplot(vhu_corals, cex = 1)\nplot(vhu_Q, add = TRUE, cex = 1)\n\n\n\n\nChi-sq test for complete spatial randomness, CSR\n\nquadrat.test(vhu_corals, nx = 10, ny = 25, method = \"Chisq\")\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  vhu_corals\nX2 = 308.08, df = 249, p-value = 0.0127\nalternative hypothesis: two.sided\n\nQuadrats: 10 by 25 grid of tiles\n\n\nThe test statistic suggests highly a non-random point pattern at the scale of the quadrat defined. Note that this test is more akin to a first-order point pattern analysis because it is based on the dispersion of points among sampling quadrats.\n\n\n\n\nman_csv &lt;- read.csv(\"man_centroids.csv\")\n\n\nman_csv2 &lt;- as_tibble(man_csv)\n\n\nman_csv2 \n\n# A tibble: 372 × 6\n   layer level class    id       x     y\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1     1 patch     0     1 0.0579  20.6 \n 2     1 patch     0     2 0.0812  20.5 \n 3     1 patch     0     3 0.00173 19.4 \n 4     1 patch     0     4 0.0281  12.7 \n 5     1 patch     0     5 0.0164  12.6 \n 6     1 patch     0     6 0.0550  10.8 \n 7     1 patch     0     7 0.0111   8.88\n 8     1 patch     0     8 0.0366   8.51\n 9     1 patch     0     9 0.0589  13.3 \n10     1 patch     0    10 0.0825  13.0 \n# ℹ 362 more rows\n\n\nDefine window for spatial pattern analyses based on the extent defined above\n\nman_window &lt;- owin(c(0, 10), c(0, 25))\n\n\nattach(man_window)\n\nThe following objects are masked from vhu_window:\n\n    type, units, xrange, yrange\n\n\n\nman_corals &lt;- ppp(man_csv2$x, man_csv2$y, window = man_window)\n\nSummary information\n\nsummary(man_corals)\n\nPlanar point pattern:  372 points\nAverage intensity 1.488 points per square unit\n\nCoordinates are given to 7 decimal places\n\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\n\n\nThis summary shows there are 3131 points (pocilloporid coral colony) and provides the observed, lambda. The density plot can be a helpful visualization of intensity of points across the plot. By plotting the spatial intensity this way, spatial trends in the point occurrences that may violate the assumption of homogeneous point process.\nDensity plots\n\nplot(\n  density(man_corals)\n)\n\n\n\n\nAlter smoothing parameter\n\nplot(\n  density(man_corals, 1)\n)  \n\n\n\n\nContour plot\n\ncontour(\n  density(man_corals, 1)\n)\n\n\n\n\nWe can also make tallies of counts of point locations based on quadrats overlaid on the plot. To determine whether these quadrat counts conform to CSR (i.e., a homogeneous Poisson process), use a simple Chi-Square test statistic.\nQuadrat counts\nCounts in 10 x 25 m quadrats\n\nman_Q &lt;- quadratcount(man_corals, nx = 10, ny = 25)\n\nPlot\n\nplot(man_corals, cex = 1)\nplot(man_Q, add = TRUE, cex = 1)\n\n\n\n\nChi-sq test for complete spatial randomness, CSR\n\nquadrat.test(man_corals, nx = 10, ny = 25, method = \"Chisq\")\n\nWarning: Some expected counts are small; chi^2 approximation may be inaccurate\n\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  man_corals\nX2 = 1394.1, df = 249, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nQuadrats: 10 by 25 grid of tiles\n\n\n\n\n\n\nana_csv &lt;- read.csv(\"ana_centroids.csv\")\n\n\nana_csv2 &lt;- as_tibble(ana_csv)\n\n\nana_csv2 \n\n# A tibble: 136 × 6\n   layer level class    id     x      y\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1 patch     1     1 0.330 23.4  \n 2     1 patch     1     2 0.343 23.7  \n 3     1 patch     1     3 0.360  1.54 \n 4     1 patch     1     4 0.477 11.2  \n 5     1 patch     1     5 0.494 12.6  \n 6     1 patch     1     6 0.547 17.4  \n 7     1 patch     1     7 0.557  1.52 \n 8     1 patch     1     8 0.587 16.3  \n 9     1 patch     1     9 0.779  1.81 \n10     1 patch     1    10 0.749  0.270\n# ℹ 126 more rows\n\n\nDefine window for spatial pattern analyses based on the extent defined above\n\nana_window &lt;- owin(c(0, 10), c(0, 25))\n\n\nattach(ana_window)\n\nThe following objects are masked from man_window:\n\n    type, units, xrange, yrange\n\n\nThe following objects are masked from vhu_window:\n\n    type, units, xrange, yrange\n\n\n\nana_corals &lt;- ppp(ana_csv2$x, ana_csv2$y, window = ana_window)\n\nSummary information\n\nsummary(ana_corals)\n\nPlanar point pattern:  136 points\nAverage intensity 0.544 points per square unit\n\nCoordinates are given to 7 decimal places\n\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\n\n\nThis summary shows there are 3131 points (pocilloporid coral colony) and provides the observed, lambda. The density plot can be a helpful visualization of intensity of points across the plot. By plotting the spatial intensity this way, spatial trends in the point occurrences that may violate the assumption of homogeneous point process.\nDensity plots\n\nplot(\n  density(ana_corals)\n)\n\n\n\n\nAlter smoothing parameter\n\nplot(\n  density(ana_corals, 1)\n)  \n\n\n\n\nContour plot\n\ncontour(\n  density(ana_corals, 1)\n)\n\n\n\n\nWe can also make tallies of counts of point locations based on quadrats overlaid on the plot. To determine whether these quadrat counts conform to CSR (i.e., a homogeneous Poisson process), use a simple Chi-Square test statistic.\nQuadrat counts\nCounts in 10 x 25 m quadrats\n\nana_Q &lt;- quadratcount(ana_corals, nx = 10, ny = 25)\n\nPlot\n\nplot(ana_corals, cex = 1)\nplot(ana_Q, add = TRUE, cex = 1)\n\n\n\n\nChi-sq test for complete spatial randomness, CSR\n\nquadrat.test(ana_corals, nx = 10, ny = 25, method = \"Chisq\")\n\nWarning: Some expected counts are small; chi^2 approximation may be inaccurate\n\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  ana_corals\nX2 = 397.09, df = 249, p-value = 1.389e-08\nalternative hypothesis: two.sided\n\nQuadrats: 10 by 25 grid of tiles\n\n\nThe test statistic suggests highly a non-random point pattern at the scale of the quadrat defined. Note that this test is more akin to a first-order point pattern analysis because it is based on the dispersion of points among sampling quadrats."
  },
  {
    "objectID": "content/rpn_sppa.html#quadrat-count",
    "href": "content/rpn_sppa.html#quadrat-count",
    "title": "SPPA",
    "section": "",
    "text": "vhu_csv &lt;- read.csv(\"vhu_centroids.csv\")\n\n\nvhu_csv2 &lt;- as_tibble(vhu_csv)\n\n\nvhu_csv2 \n\n# A tibble: 3,131 × 6\n   layer level class    id       x     y\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1     1 patch     0     1 0.0775   24.7\n 2     1 patch     0     2 0.0588   24.0\n 3     1 patch     0     3 0.0368   23.7\n 4     1 patch     0     4 0.0318   23.4\n 5     1 patch     0     5 0.0501   23.1\n 6     1 patch     0     6 0.0125   22.8\n 7     1 patch     0     7 0.0794   21.7\n 8     1 patch     0     8 0.00269  21.0\n 9     1 patch     0     9 0.0485   20.8\n10     1 patch     0    10 0.0824   16.7\n# ℹ 3,121 more rows\n\n\nDefine window for spatial pattern analyses based on the extent defined above\n\nvhu_window &lt;- owin(c(0, 10), c(0, 25))\n\n\nattach(vhu_window)\n\n\nvhu_corals &lt;- ppp(vhu_csv2$x, vhu_csv2$y, window = vhu_window)\n\nSummary information\n\nsummary(vhu_corals)\n\nPlanar point pattern:  3131 points\nAverage intensity 12.524 points per square unit\n\nCoordinates are given to 7 decimal places\n\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\n\n\nThis summary shows there are 3131 points (pocilloporid coral colony) and provides the observed, lambda. The density plot can be a helpful visualization of intensity of points across the plot. By plotting the spatial intensity this way, spatial trends in the point occurrences that may violate the assumption of homogeneous point process.\nDensity plots\n\nplot(\n  density(vhu_corals)\n)\n\n\n\n\nAlter smoothing parameter\n\nplot(\n  density(vhu_corals, 1)\n)  \n\n\n\n\nContour plot\n\ncontour(\n  density(vhu_corals, 1)\n)\n\n\n\n\nWe can also make tallies of counts of point locations based on quadrats overlaid on the plot. To determine whether these quadrat counts conform to CSR (i.e., a homogeneous Poisson process), use a simple Chi-Square test statistic.\nQuadrat counts\nCounts in 10 x 25 m quadrats\n\nvhu_Q &lt;- quadratcount(vhu_corals, nx = 10, ny = 25)\n\nPlot\n\nplot(vhu_corals, cex = 1)\nplot(vhu_Q, add = TRUE, cex = 1)\n\n\n\n\nChi-sq test for complete spatial randomness, CSR\n\nquadrat.test(vhu_corals, nx = 10, ny = 25, method = \"Chisq\")\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  vhu_corals\nX2 = 308.08, df = 249, p-value = 0.0127\nalternative hypothesis: two.sided\n\nQuadrats: 10 by 25 grid of tiles\n\n\nThe test statistic suggests highly a non-random point pattern at the scale of the quadrat defined. Note that this test is more akin to a first-order point pattern analysis because it is based on the dispersion of points among sampling quadrats.\n\n\n\n\nman_csv &lt;- read.csv(\"man_centroids.csv\")\n\n\nman_csv2 &lt;- as_tibble(man_csv)\n\n\nman_csv2 \n\n# A tibble: 372 × 6\n   layer level class    id       x     y\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1     1 patch     0     1 0.0579  20.6 \n 2     1 patch     0     2 0.0812  20.5 \n 3     1 patch     0     3 0.00173 19.4 \n 4     1 patch     0     4 0.0281  12.7 \n 5     1 patch     0     5 0.0164  12.6 \n 6     1 patch     0     6 0.0550  10.8 \n 7     1 patch     0     7 0.0111   8.88\n 8     1 patch     0     8 0.0366   8.51\n 9     1 patch     0     9 0.0589  13.3 \n10     1 patch     0    10 0.0825  13.0 \n# ℹ 362 more rows\n\n\nDefine window for spatial pattern analyses based on the extent defined above\n\nman_window &lt;- owin(c(0, 10), c(0, 25))\n\n\nattach(man_window)\n\nThe following objects are masked from vhu_window:\n\n    type, units, xrange, yrange\n\n\n\nman_corals &lt;- ppp(man_csv2$x, man_csv2$y, window = man_window)\n\nSummary information\n\nsummary(man_corals)\n\nPlanar point pattern:  372 points\nAverage intensity 1.488 points per square unit\n\nCoordinates are given to 7 decimal places\n\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\n\n\nThis summary shows there are 3131 points (pocilloporid coral colony) and provides the observed, lambda. The density plot can be a helpful visualization of intensity of points across the plot. By plotting the spatial intensity this way, spatial trends in the point occurrences that may violate the assumption of homogeneous point process.\nDensity plots\n\nplot(\n  density(man_corals)\n)\n\n\n\n\nAlter smoothing parameter\n\nplot(\n  density(man_corals, 1)\n)  \n\n\n\n\nContour plot\n\ncontour(\n  density(man_corals, 1)\n)\n\n\n\n\nWe can also make tallies of counts of point locations based on quadrats overlaid on the plot. To determine whether these quadrat counts conform to CSR (i.e., a homogeneous Poisson process), use a simple Chi-Square test statistic.\nQuadrat counts\nCounts in 10 x 25 m quadrats\n\nman_Q &lt;- quadratcount(man_corals, nx = 10, ny = 25)\n\nPlot\n\nplot(man_corals, cex = 1)\nplot(man_Q, add = TRUE, cex = 1)\n\n\n\n\nChi-sq test for complete spatial randomness, CSR\n\nquadrat.test(man_corals, nx = 10, ny = 25, method = \"Chisq\")\n\nWarning: Some expected counts are small; chi^2 approximation may be inaccurate\n\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  man_corals\nX2 = 1394.1, df = 249, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nQuadrats: 10 by 25 grid of tiles\n\n\n\n\n\n\nana_csv &lt;- read.csv(\"ana_centroids.csv\")\n\n\nana_csv2 &lt;- as_tibble(ana_csv)\n\n\nana_csv2 \n\n# A tibble: 136 × 6\n   layer level class    id     x      y\n   &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1 patch     1     1 0.330 23.4  \n 2     1 patch     1     2 0.343 23.7  \n 3     1 patch     1     3 0.360  1.54 \n 4     1 patch     1     4 0.477 11.2  \n 5     1 patch     1     5 0.494 12.6  \n 6     1 patch     1     6 0.547 17.4  \n 7     1 patch     1     7 0.557  1.52 \n 8     1 patch     1     8 0.587 16.3  \n 9     1 patch     1     9 0.779  1.81 \n10     1 patch     1    10 0.749  0.270\n# ℹ 126 more rows\n\n\nDefine window for spatial pattern analyses based on the extent defined above\n\nana_window &lt;- owin(c(0, 10), c(0, 25))\n\n\nattach(ana_window)\n\nThe following objects are masked from man_window:\n\n    type, units, xrange, yrange\n\n\nThe following objects are masked from vhu_window:\n\n    type, units, xrange, yrange\n\n\n\nana_corals &lt;- ppp(ana_csv2$x, ana_csv2$y, window = ana_window)\n\nSummary information\n\nsummary(ana_corals)\n\nPlanar point pattern:  136 points\nAverage intensity 0.544 points per square unit\n\nCoordinates are given to 7 decimal places\n\nWindow: rectangle = [0, 10] x [0, 25] units\nWindow area = 250 square units\n\n\nThis summary shows there are 3131 points (pocilloporid coral colony) and provides the observed, lambda. The density plot can be a helpful visualization of intensity of points across the plot. By plotting the spatial intensity this way, spatial trends in the point occurrences that may violate the assumption of homogeneous point process.\nDensity plots\n\nplot(\n  density(ana_corals)\n)\n\n\n\n\nAlter smoothing parameter\n\nplot(\n  density(ana_corals, 1)\n)  \n\n\n\n\nContour plot\n\ncontour(\n  density(ana_corals, 1)\n)\n\n\n\n\nWe can also make tallies of counts of point locations based on quadrats overlaid on the plot. To determine whether these quadrat counts conform to CSR (i.e., a homogeneous Poisson process), use a simple Chi-Square test statistic.\nQuadrat counts\nCounts in 10 x 25 m quadrats\n\nana_Q &lt;- quadratcount(ana_corals, nx = 10, ny = 25)\n\nPlot\n\nplot(ana_corals, cex = 1)\nplot(ana_Q, add = TRUE, cex = 1)\n\n\n\n\nChi-sq test for complete spatial randomness, CSR\n\nquadrat.test(ana_corals, nx = 10, ny = 25, method = \"Chisq\")\n\nWarning: Some expected counts are small; chi^2 approximation may be inaccurate\n\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  ana_corals\nX2 = 397.09, df = 249, p-value = 1.389e-08\nalternative hypothesis: two.sided\n\nQuadrats: 10 by 25 grid of tiles\n\n\nThe test statistic suggests highly a non-random point pattern at the scale of the quadrat defined. Note that this test is more akin to a first-order point pattern analysis because it is based on the dispersion of points among sampling quadrats."
  },
  {
    "objectID": "content/rpn_sppa.html#ripleys-k-function",
    "href": "content/rpn_sppa.html#ripleys-k-function",
    "title": "SPPA",
    "section": "Ripley’s K function:",
    "text": "Ripley’s K function:\n\nSecond-order point pattern analyses can readily be implemented in ‘spatstat’.\nRipley’s K and the standard L functions\nIgnore edge effects with ‘(correction = “none”)’\n\n\nSoutheast - Vaihu\n\nK_none_vhu &lt;- Kest(vhu_corals, rmax = 5.0, correction = \"none\")\n\n\nPlot K\n\n\nplot(K_none_vhu, legend = F, main = \"Southeast: Ripley's K\")\n\n\n\n\n\nPlot L with 1:1 expectation\n\n\nL_none_vhu &lt;- Lest(vhu_corals, rmax = 5.0, correction = \"none\")\n\n\nplot(L_none_vhu, legend = F, main = \"Southeast: standardized L function (standardized 1:1)\")\n\n\n\n\n\nPlot L with 0 expectation\n\n\nplot(L_none_vhu, . - r ~ r, legend = F, main = \"Southeast: standardized L function (standardized 0)\")\n\n\n\n\nThe above analysis ignores the problem of edge effects. spatstat provides a variety of edge corrections. Contrast an (1) isotropic and (2) translate correction for adjusting for boundary effects. The isotropic correction uses a simple weighting for the area sampled near the plot boundary (Ripley 1988), the translate correction uses a toroidal shift. We adjust for potential boundary effects by typing:\n\nIsotropic edge correction\n\n\nL_iso_vhu &lt;- Lest(vhu_corals, rmax = 5.0, correction = \"isotropic\")\n\n\nplot(L_iso_vhu, . - r ~ r, legend = F, main = \"Southeast: standardzied L (isotropic correction)\")\n\n\n\n\n\nTranslate (toroidal) edge correction\n\n\nL_trans_vhu &lt;- Lest(vhu_corals, rmax = 5.0, correction = \"trans\")\n\n\nplot(L_trans_vhu, . - r ~ r, legend = F, main = \"Southeast: standardzied L (translate correction)\")"
  },
  {
    "objectID": "content/rpn_sppa.html#monte-carlo-simulations-to-calculate-a-global-and-pointwise-confidence-envelope-under-csr",
    "href": "content/rpn_sppa.html#monte-carlo-simulations-to-calculate-a-global-and-pointwise-confidence-envelope-under-csr",
    "title": "SPPA",
    "section": "Monte Carlo simulations to calculate a global and pointwise confidence envelope under CSR",
    "text": "Monte Carlo simulations to calculate a global and pointwise confidence envelope under CSR\n\nL_csr_vhu &lt;- envelope(vhu_corals, rmax = 5.0, Lest, nsim = 99, rank = 1, correction = \"trans\", global = F)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nL_csr.g_vhu &lt;- envelope(vhu_corals, rmax = 5.0, Lest, nsim = 99, rank = 1, correction = \"trans\", global = T)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nPlot point-wise envelope\n\n\nplot(L_csr_vhu, . - r ~ r, shade = c(\"hi\", \"lo\"), legend = F, main = \"Southeast: stand. L (Monte Carlo, CSR env)\")\n\n\n\n\n\nPlot global envelope\n\n\nplot(L_csr.g_vhu, . - r ~ r, shade = c(\"hi\", \"lo\"), legend = F, main = \"Southeast: stand. L (Monte Carlo, CSR env)\")\n\n\n\n\n\nWest - Manavai\n\nK_none_man &lt;- Kest(man_corals, rmax = 5.0, correction = \"none\")\n\n\nPlot K\n\n\nplot(K_none_man, legend = F, main = \"West: Ripley's K\")\n\n\n\n\n\nPlot L with 1:1 expectation\n\n\nL_none_man &lt;- Lest(man_corals, rmax = 5.0, correction = \"none\")\n\n\nplot(L_none_man, legend = F, main = \"West: standardized L function (standardized 1:1)\")\n\n\n\n\n\nPlot L with 0 expectation\n\n\nplot(L_none_man, . - r ~ r, legend = F, main = \"West: standardized L function (standardized 0)\")\n\n\n\n\nThe above analysis ignores the problem of edge effects. spatstat provides a variety of edge corrections. Contrast an (1) isotropic and (2) translate correction for adjusting for boundary effects. The isotropic correction uses a simple weighting for the area sampled near the plot boundary (Ripley 1988), the translate correction uses a toroidal shift. We adjust for potential boundary effects by typing:\n\nIsotropic edge correction\n\n\nL_iso_man &lt;- Lest(man_corals, rmax = 5.0, correction = \"isotropic\")\n\n\nplot(L_iso_man, . - r ~ r, legend = F, main = \"West: standardzied L (isotropic correction)\")\n\n\n\n\n\nTranslate (toroidal) edge correction\n\n\nL_trans_man &lt;- Lest(man_corals, rmax = 5.0, correction = \"trans\")\n\n\nplot(L_trans_man, . - r ~ r, legend = F, main = \"West: standardzied L (translate correction)\")\n\n\n\n\n\n\nNorth - Anakena\n\nK_none_ana &lt;- Kest(ana_corals, rmax = 5.0, correction = \"none\")\n\n\nPlot K\n\n\nplot(K_none_ana, legend = F, main = \"North: Ripley's K\")\n\n\n\n\n\nPlot L with 1:1 expectation\n\n\nL_none_ana &lt;- Lest(ana_corals, rmax = 5.0, correction = \"none\")\n\n\nplot(L_none_ana, legend = F, main = \"North: standardized L function (standardized 1:1)\")\n\n\n\n\n\nPlot L with 0 expectation\n\n\nplot(L_none_ana, . - r ~ r, legend = F, main = \"North: standardized L function (standardized 0)\")\n\n\n\n\nThe above analysis ignores the problem of edge effects. spatstat provides a variety of edge corrections. Contrast an (1) isotropic and (2) translate correction for adjusting for boundary effects. The isotropic correction uses a simple weighting for the area sampled near the plot boundary (Ripley 1988), the translate correction uses a toroidal shift. We adjust for potential boundary effects by typing:\n\nIsotropic edge correction\n\n\nL_iso_ana &lt;- Lest(ana_corals, rmax = 5.0, correction = \"isotropic\")\n\n\nplot(L_iso_ana, . - r ~ r, legend = F, main = \"North: standardzied L (isotropic correction)\")\n\n\n\n\n\nTranslate (toroidal) edge correction\n\n\nL_trans_ana &lt;- Lest(ana_corals, rmax = 5.0, correction = \"trans\")\n\n\nplot(L_trans_ana, . - r ~ r, legend = F, main = \"North: standardzied L (translate correction)\")\n\n\n\n\nFor the functions above, two lines are drawn. The \\(L_{pois}\\) line is a dashed line that represents the expected (theoretical) value based on a Poisson process (CSR). The way that spatstat calculates \\(L\\) is to linearize \\(K\\) such that the expected value is \\(r\\) (or the radius). The other solid line represents the estimated \\(L\\) (linearized \\(K\\)), when the edges are ignored.\nWhen comparing the \\(L\\) function that ignores boundaries to those above that account for boundaries, notice that patterns change at larger distances - we expect that the \\(L\\) function at larger distances should potentially be more biased than at smaller distances because larger radii will naturally overlap more with the boundary of the study area.\nWhen edge effects are ignored, the effect in the of counting fewer points within the radius \\(r\\) near the boundary, so the observed value for \\(L\\) or \\(K\\) should have an artifact of decreasing as \\(r\\) increases.\nThe analyses so far are exploratory. While the observed statistics (\\(K\\), \\(L\\)) appear different than the expectation, it is unclear if these are substantially (or significantly) different.\nTo conduct formal inference regarding if the point pattern follows CSR, we can use Monte Carlo simulations ro calculate a confidence envelope under CSR with the envelope function.\nIn the envelope function, rank specifies the alpha for the simulations. For a rank = 1, the max an min are used as the envelopes, such that for 99 simulations, alpha = 0.01 while for 19 simulations, alpha = 0.05.\nAlso not that we used global = FALSE. This means that these are pointwise envelopes.\nThese envelopes work better for \\(L\\) than \\(K\\) because of variance stabilizing properties.\nPlots of pointwise envelopes show the stated upper and lower quantiles of simulated patterns for any distance r. Because such analyses are calculating envelopes for vhuy distances, pointwise envelopes with a specified alpha should not be used to reject a null model at that level (because of the multiple tests). Consequently, there are alternative global tests that can be used in this way. While global tests are under active development (Baddeley et al. 2014; Wiegand et al. 2016), spatstat does provide one option for a global test (using global = T).\nThis approach estimates the maximum deviation from the Poisson point process across all r (i.e., \\(D = max|K_{(r)} - K_{pois(r)}|)\\). This approach is referred to as a simultaneous envelope (or critical band) rather than a pointwise envelope.\nIf the observed line falls outside the simultaneous envelope at any point on \\(r\\), we would reject the null hypothesis."
  },
  {
    "objectID": "content/percent_cover.html",
    "href": "content/percent_cover.html",
    "title": "Percent Cover",
    "section": "",
    "text": "From Damgaard & Irvine (2019) Using the beta distribution to analyse plant cover data Journal of Ecology. 107:2747-2759\nWrote a function to create a table from betreg object that can be used in xtable()\nFcn.CreateSummary.betareg &lt;- function(object.betareg){\n  OUT &lt;- summary(object.betareg)\n tab &lt;- rbind(OUT$coefficients$mean,OUT$coefficients$precision)\n      return(tab)\n   }\np_cover = read_csv('rpn_percent_cover.csv') %&gt;% \n  group_by(Site) %&gt;%\n  mutate(\n    pland_decimal = pland*0.01\n  ) %&gt;%\n  mutate_at(vars(Site, cover, plot_id), factor)\n\nRows: 750 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Site, cover, level\ndbl (7): plot_id, class, layer, percentage_inside, clumpy, pd, pland\nlgl (2): id, NA\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\np_cover\n\n# A tibble: 750 × 13\n# Groups:   Site [3]\n   plot_id class Site  cover level layer id    percentage_inside clumpy    pd\n   &lt;fct&gt;   &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;             &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 1           1 ana   coral class     1 NA                100.   0.992  2.00\n 2 1           0 man   coral class    NA NA                 NA   NA     NA   \n 3 1           0 vhu   coral class     1 NA                100.   0.987 19.0 \n 4 2           1 ana   coral class     1 NA                 99.9  0.990  8.01\n 5 2           0 man   coral class    NA NA                 NA   NA     NA   \n 6 2           0 vhu   coral class     1 NA                 99.9  0.987 20.0 \n 7 3           1 ana   coral class     1 NA                100.   0.995  4.00\n 8 3           0 man   coral class    NA NA                 NA   NA     NA   \n 9 3           0 vhu   coral class     1 NA                100.   0.989 16.0 \n10 4           1 ana   coral class     1 NA                100.   0.995  3.00\n# ℹ 740 more rows\n# ℹ 3 more variables: pland &lt;dbl&gt;, `NA` &lt;lgl&gt;, pland_decimal &lt;dbl&gt;\nhead(p_cover)\n\n# A tibble: 6 × 13\n# Groups:   Site [3]\n  plot_id class Site  cover level layer id    percentage_inside clumpy    pd\n  &lt;fct&gt;   &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;             &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 1           1 ana   coral class     1 NA                100.   0.992  2.00\n2 1           0 man   coral class    NA NA                 NA   NA     NA   \n3 1           0 vhu   coral class     1 NA                100.   0.987 19.0 \n4 2           1 ana   coral class     1 NA                 99.9  0.990  8.01\n5 2           0 man   coral class    NA NA                 NA   NA     NA   \n6 2           0 vhu   coral class     1 NA                 99.9  0.987 20.0 \n# ℹ 3 more variables: pland &lt;dbl&gt;, `NA` &lt;lgl&gt;, pland_decimal &lt;dbl&gt;\nggplot(p_cover, aes(x = pland_decimal)) +\n  geom_histogram(fill = \"#333399\") + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(NULL) +\n  ggtitle(expression(\"Coral Cover (%)\")) +\n  theme_bw() +\n  facet_wrap(~ Site, ncol = 1) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(size = 14), \n        axis.title.y = element_text(size = 14), \n        axis.text.y  = element_text(size= 10),\n        axis.text.x  = element_text(size = 12), \n        legend.text = element_text(size = 12),\n        legend.title = element_text(size = 12),\n        plot.title = element_text(hjust = 0.5, size = 14),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill = \"white\"),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major = element_blank(),\n        plot.background = element_rect(fill = \"white\"),\n        legend.background = element_rect(fill = \"white\"),\n        strip.text.x = element_text(size = 12, colour = \"#FFFFFF\"),\n        strip.background = element_rect(fill = '#000066')\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\np_cover.mean &lt;-\n  p_cover %&gt;%\n  group_by(Site) %&gt;%\n  dplyr::summarise(mean = mean(pland_decimal))\np_cover.mean\n\n# A tibble: 3 × 2\n  Site     mean\n  &lt;fct&gt;   &lt;dbl&gt;\n1 ana   0.00602\n2 man   0.0224 \n3 vhu   0.290"
  },
  {
    "objectID": "content/percent_cover.html#methods-for-analyzing-percent-cover-of-pocilloporid-coral",
    "href": "content/percent_cover.html#methods-for-analyzing-percent-cover-of-pocilloporid-coral",
    "title": "Percent Cover",
    "section": "Methods for analyzing percent cover of pocilloporid coral",
    "text": "Methods for analyzing percent cover of pocilloporid coral\nOne option for dealing with the 0 and 1 values is to transform them to be slightly less than one or more than zero. This approach assumes that the data are consistent with a common beta distribution. We fit five models to the data: three variations on the beta model and two linear model approaches.\nA beta regression assuming a common spatial aggregation \\(\\delta\\) or precision parameter (\\(\\phi\\)) (object named: mod.beta1). Notice that \\(\\delta= \\frac{1}{1+\\phi}\\) and \\(\\phi=\\frac{(1-\\delta)}{\\delta}\\). A beta regression assuming each year had a different \\(\\phi\\) parameter (object named: mod.beta2).\nAnother option for modeling the data is to use a zero-one augmented beta model. Currently, the betareg package does not implement this model directly. Therefore, we follow the theoretical results shown in Ospina and Ferrari (2010) that suggest a three-part model can be fit to the data. Basically, we use logistic regression with response an indicator variable for whether or not the plot had zero recorded cover, another logistic regression with response an indicator for whether or not the plot had 100\\(\\%\\) recorded percent cover, and then the beta regression is used to model the continuous percent cover observations ranging from greater than 0 and less than 1.\nOther options based on assuming that the residuals are normally distributed is to use a linear model with a logit-transformed response (object named: mod.lmlogit) or a linear model with response untransformed proportions (object named: mod.lmraw).\nFor comparison this applies a logit-transformation to the empirical proportions and then uses a standard linear regression model.\nRaw data - no transformation\n\np_cover_mod.aov1 &lt;- aov(pland_decimal ~ Site, data = p_cover)\nsummary(p_cover_mod.aov1)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nSite          2 12.699   6.350    2203 &lt;2e-16 ***\nResiduals   747  2.153   0.003                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\np_cover_mod.lm1 &lt;- lm(pland_decimal ~ Site, data = p_cover)\nsummary(p_cover_mod.lm1)\n\n\nCall:\nlm(formula = pland_decimal ~ Site, data = p_cover)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.267087 -0.022444 -0.006021  0.015304  0.242376 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.006021   0.003395   1.773  0.07656 .  \nSiteman     0.016423   0.004802   3.420  0.00066 ***\nSitevhu     0.283878   0.004802  59.122  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05368 on 747 degrees of freedom\nMultiple R-squared:  0.8551,    Adjusted R-squared:  0.8547 \nF-statistic:  2203 on 2 and 747 DF,  p-value: &lt; 2.2e-16\n\n\n\npar(mfrow = c(2, 2))\nplot(p_cover_mod.lm1)\n\n\n\n\n\nAnova(p_cover_mod.lm1, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: pland_decimal\n             Sum Sq  Df   F value  Pr(&gt;F)    \n(Intercept)  0.0091   1    3.1451 0.07656 .  \nSite        12.6991   2 2203.2548 &lt; 2e-16 ***\nResiduals    2.1528 747                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOne option to deal with 0 and 100 percent cover is to add and subtract a small amount to those values\n\ntransform01 &lt;- function(x) {\n  (x * (length(x) - 1) + 0.5) / (length(x))\n}\n\n\np_cover$pland_decimal_scaled &lt;- transform01(p_cover$pland_decimal)\n\nLogit-transformation\n\np_cover_mod.lm2 &lt;- lm(logit(pland_decimal_scaled) ~ Site, data = p_cover) \n\n\nsummary(p_cover_mod.lm2)\n\n\nCall:\nlm(formula = logit(pland_decimal_scaled) ~ Site, data = p_cover)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7875 -1.0925 -0.1617  0.7543  4.5854 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -6.22005    0.09621 -64.654  &lt; 2e-16 ***\nSiteman      0.61521    0.13606   4.522 7.13e-06 ***\nSitevhu      5.27828    0.13606  38.795  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.521 on 747 degrees of freedom\nMultiple R-squared:  0.7067,    Adjusted R-squared:  0.7059 \nF-statistic: 900.1 on 2 and 747 DF,  p-value: &lt; 2.2e-16\n\n\n\npar(mfrow = c(2, 2))\nplot(p_cover_mod.lm2)\n\n\n\n\n\nAnova(p_cover_mod.lm2, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: logit(pland_decimal_scaled)\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 9672.3   1 4180.11 &lt; 2.2e-16 ***\nSite        4165.2   2  900.06 &lt; 2.2e-16 ***\nResiduals   1728.5 747                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nGeneralized-linear model\n\np_cover_mod.glm1 &lt;- glm(pland_decimal ~ Site, family = binomial, data = p_cover)\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\nsummary(p_cover_mod.glm1)\n\n\nCall:\nglm(formula = pland_decimal ~ Site, family = binomial, data = p_cover)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -5.1064     0.8175  -6.246 4.21e-10 ***\nSiteman       1.3324     0.9223   1.445    0.149    \nSitevhu       4.2106     0.8293   5.077 3.83e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 161.289  on 749  degrees of freedom\nResidual deviance:  26.922  on 747  degrees of freedom\nAIC: 191.54\n\nNumber of Fisher Scoring iterations: 8\n\n\n\npar(mfrow = c(2, 2))\nplot(p_cover_mod.glm1)\n\n\n\n\n\nAnova(p_cover_mod.glm1, type = \"III\")\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: pland_decimal\n     LR Chisq Df Pr(&gt;Chisq)    \nSite   134.37  2  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBeta Regression I: \\(\\phi\\) does not vary\n\np_cover_mod.beta1 &lt;- betareg(pland_decimal_scaled ~ Site, data = p_cover, link = c(\"logit\"), link.phi = NULL, type = c(\"ML\"))\n\n\nsummary(p_cover_mod.beta1)\n\n\nCall:\nbetareg(formula = pland_decimal_scaled ~ Site, data = p_cover, link = c(\"logit\"), \n    link.phi = NULL, type = c(\"ML\"))\n\nStandardized weighted residuals 2:\n    Min      1Q  Median      3Q     Max \n-6.1915 -0.6623 -0.3219  0.6315  1.8412 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.28350    0.07391 -57.953   &lt;2e-16 ***\nSiteman      0.20537    0.08442   2.433    0.015 *  \nSitevhu      3.38355    0.07733  43.754   &lt;2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)   25.321      1.561   16.22   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  2094 on 4 Df\nPseudo R-squared: 0.7048\nNumber of iterations: 19 (BFGS) + 2 (Fisher scoring) \n\n\nBeta Regression II: \\(\\phi\\) does vary (by Site)\n\np_cover_mod.beta2 &lt;- betareg(pland_decimal_scaled ~ Site | Site, data = p_cover, link = c(\"logit\"), link.phi = NULL, type = c(\"ML\"))\n\n#{r} #test(pairs(emmeans(p_cover.bm2, ~ Site, mode = \"link\"))) #\n\np_cover_mod.beta1.aov &lt;- Anova(p_cover_mod.beta1, type = 'III')\n\n\np_cover_mod.beta2.aov &lt;- Anova(p_cover_mod.beta2, type = 'III')\n\n\np_cover_mod.beta2.aov\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: pland_decimal_scaled\n            Df  Chisq Pr(&gt;Chisq)    \n(Intercept)  1 3239.1  &lt; 2.2e-16 ***\nSite         2 2520.1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nmodels &lt;- list(\n  \n  'p_cover_mod.beta1' = betareg(pland_decimal_scaled ~ Site, \n                                data = p_cover, \n                                link = c(\"logit\"), \n                                link.phi = NULL, \n                                type = c(\"ML\")\n                                ),\n  \n  'p_cover_mod.beta2' = betareg(pland_decimal_scaled ~ Site | Site, \n                      data = p_cover,\n                      link = c(\"logit\"), \n                      link.phi = NULL, \n                      type = c(\"ML\")\n                      )\n)\n\n\nmodelsummary(models)\n\n\n\n\n\np_cover_mod.beta1\n p_cover_mod.beta2\n\n\n\n\n(Intercept)\n−4.283\n−4.999\n\n\n\n(0.074)\n(0.088)\n\n\nSiteman\n0.205\n1.263\n\n\n\n(0.084)\n(0.136)\n\n\nSitevhu\n3.384\n4.099\n\n\n\n(0.077)\n(0.092)\n\n\nNum.Obs.\n750\n750\n\n\nR2\n0.705\n0.679\n\n\nAIC\n−4179.4\n−4259.4\n\n\nBIC\n−4160.9\n−4231.7\n\n\nRMSE\n0.05\n0.05\n\n\n\n\n\n\n\nExtract AIC from beta regression models\n\np_cover_mod.beta1_aic &lt;- AIC(p_cover_mod.beta1)\np_cover_mod.beta2_aic &lt;- AIC(p_cover_mod.beta2)\n\n\np_cover_mod.beta1_aic\n\n[1] -4179.365\n\np_cover_mod.beta2_aic\n\n[1] -4259.399"
  },
  {
    "objectID": "content/percent_cover.html#interpreting-results-for-pocilloporid-corals",
    "href": "content/percent_cover.html#interpreting-results-for-pocilloporid-corals",
    "title": "Percent Cover",
    "section": "Interpreting results for pocilloporid corals",
    "text": "Interpreting results for pocilloporid corals\nIn order to choose between the beta regression model with a common \\(\\phi\\) versus different \\(\\phi\\), I used AIC but a likelihood ratio or wald test could be used. Using AIC, the model with varying \\(\\phi\\) values had a lower AIC (-1518.568 compared to -1494.524) and therefore more support. We interpret the output from beta regression with the following:\nThe model we fit assumes \\[logit(\\mu_j)=\\beta_0+\\beta_1 Ind_{grp2},\\] where \\(Ind_{grp2}\\) is an indicator for group 2 and \\(j\\) denotes the group membership so \\(j=1\\) or \\(j=2\\). We have \\(logit(\\mu_2)-logit(\\mu_1)=\\beta_1\\), which is equivalent to \\[log(\\frac{\\mu_2}{1-\\mu_2})-log(\\frac{\\mu_1}{1-\\mu_1})= \\beta_1.\\]\nThe \\(\\frac{\\mu_j}{1-\\mu_j}\\) is interpreted as the odds of proportion cover in group \\(j\\). Therefore,\n\\[log(\\frac{\\mu_2}{1-\\mu_2}/\\frac{\\mu_1}{1-\\mu_1})=\\beta_1\\] is the log- odds ratio of cover in group 2 compared to group 1, \\[(\\frac{\\mu_2}{1-\\mu_2}/\\frac{\\mu_1}{1-\\mu_1})=exp(\\beta_1).\\]\nThen \\(exp(\\beta_1)\\) is the factor increase/decrease in odds of proportion cover for group 2 compared to group 1, where \\(exp(\\beta_1)&gt;1\\) is an increase and \\(exp(\\beta_1)&lt;1\\) is a decrease, and \\(exp(\\beta_1) \\approx 1\\) means essentially no change.\nBeta Regression I: \\(\\phi\\) does not vary\n\n\n\n\n\n\nResults from using betareg package in R by transforming the 0 and 1’s. These are on the logit-scale for \\(\\mu\\) with a common \\(\\phi\\) parameter\n\n\n\n\n\nEstimate\n\n\nStd. Error\n\n\nz value\n\n\nPr(&gt;|z|)\n\n\n\n\n(Intercept)\n\n\n-4.283\n\n\n0.074\n\n\n-57.953\n\n\n0.000\n\n\n\n\nSiteman\n\n\n0.205\n\n\n0.084\n\n\n2.433\n\n\n0.015\n\n\n\n\nSitevhu\n\n\n3.384\n\n\n0.077\n\n\n43.754\n\n\n0.000\n\n\n\n\n(phi)\n\n\n25.321\n\n\n1.561\n\n\n16.221\n\n\n0.000\n\n\n\n\nBeta Regression II: \\(\\phi\\) does vary (by Site)\n\np_cover_mod.beta2 &lt;- betareg(pland_decimal_scaled ~ Site | Site, data = p_cover, link = c(\"logit\"), link.phi = NULL, type = c(\"ML\"))\n\n\nsummary(p_cover_mod.beta2)\n\n\nCall:\nbetareg(formula = pland_decimal_scaled ~ Site | Site, data = p_cover, \n    link = c(\"logit\"), link.phi = NULL, type = c(\"ML\"))\n\nStandardized weighted residuals 2:\n    Min      1Q  Median      3Q     Max \n-6.1960 -0.5649 -0.3417  0.7115  1.8425 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.99928    0.08784 -56.913   &lt;2e-16 ***\nSiteman      1.26338    0.13630   9.269   &lt;2e-16 ***\nSitevhu      4.09928    0.09194  44.584   &lt;2e-16 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   4.3427     0.1141  38.052  &lt; 2e-16 ***\nSiteman      -1.6249     0.1679  -9.680  &lt; 2e-16 ***\nSitevhu      -1.1097     0.1441  -7.699 1.37e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  2136 on 6 Df\nPseudo R-squared: 0.6791\nNumber of iterations: 22 (BFGS) + 1 (Fisher scoring) \n\n\nIncrease of percent cover from the baseline northern site by factor of…\n\nexp(-4.99928) \n\n[1] 0.0067428\n\nexp(1.26338) # Percent cover of pocilloporids increased by a factor of 3.5 from the north to the west\n\n[1] 3.537358\n\nexp(4.09928) # Percent cover of pocilloporids increased by a factor of 60 from the north to the southeast\n\n[1] 60.29686\n\n\n\nconfint(p_cover_mod.beta2)\n\n                       2.5 %     97.5 %\n(Intercept)       -5.1714438 -4.8271137\nSiteman            0.9962311  1.5305252\nSitevhu            3.9190715  4.2794876\n(phi)_(Intercept)  4.1190202  4.5663779\n(phi)_Siteman     -1.9539058 -1.2958806\n(phi)_Sitevhu     -1.3921454 -0.8271694\n\n\nCIs for increase of percent cover from the baseline northern site by factor of…\n\nexp(-5.1714438)\n\n[1] 0.005676367\n\nexp(-4.8271137)\n\n[1] 0.008009606\n\nexp(0.9962311)  \n\n[1] 2.708056\n\nexp(1.5305252)\n\n[1] 4.620603\n\n\nThe function, Fcn.CreateSummary.betareg, doesn’t work with phi varying, so just fixed labels manually.\n\np_cover_mod.glm1 &lt;- glm(pland_decimal ~ Site, family = binomial, data = p_cover)\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\nprint(xtable(summary(p_cover_mod.glm1), digits = 3, caption = \" . \"), type = \"html\")\n\n&lt;!-- html table generated in R 4.3.2 by xtable 1.8-4 package --&gt;\n&lt;!-- Sun Dec  3 20:52:43 2023 --&gt;\n&lt;table border=1&gt;\n&lt;caption align=\"bottom\"&gt;  .  &lt;/caption&gt;\n&lt;tr&gt; &lt;th&gt;  &lt;/th&gt; &lt;th&gt; Estimate &lt;/th&gt; &lt;th&gt; Std. Error &lt;/th&gt; &lt;th&gt; z value &lt;/th&gt; &lt;th&gt; Pr(&gt;|z|) &lt;/th&gt;  &lt;/tr&gt;\n  &lt;tr&gt; &lt;td align=\"right\"&gt; (Intercept) &lt;/td&gt; &lt;td align=\"right\"&gt; -5.106 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.818 &lt;/td&gt; &lt;td align=\"right\"&gt; -6.246 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.000 &lt;/td&gt; &lt;/tr&gt;\n  &lt;tr&gt; &lt;td align=\"right\"&gt; Siteman &lt;/td&gt; &lt;td align=\"right\"&gt; 1.332 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.922 &lt;/td&gt; &lt;td align=\"right\"&gt; 1.445 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.149 &lt;/td&gt; &lt;/tr&gt;\n  &lt;tr&gt; &lt;td align=\"right\"&gt; Sitevhu &lt;/td&gt; &lt;td align=\"right\"&gt; 4.211 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.829 &lt;/td&gt; &lt;td align=\"right\"&gt; 5.077 &lt;/td&gt; &lt;td align=\"right\"&gt; 0.000 &lt;/td&gt; &lt;/tr&gt;\n   &lt;/table&gt;\n\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nz value\nPr(&gt;|z|)\n\n\n\n\n(Intercept)\n-4.129\n0.822\n-5.025\n0.000\n\n\nSiteman\n1.225\n0.929\n1.318\n0.187\n\n\nSitevhu\n3.233\n0.833\n3.880\n0.000\n\n\n\n\n\n\n\n\nExample diagnostic plots for beta regression)\n\n\n\n\n\n\n\n\n\nExample diagnostic plots for beta regression, variable phi)\n\n\n\n\nBuilt-in diagnostic plots for linear regression models\nLogit-transformed\n\npar(mfrow = c(3, 2), pty = 'm')\nplot(p_cover_mod.lm2)\nplot(cooks.distance(p_cover_mod.lm2))\n\n\n\n\nUntransformed\n\npar(mfrow = c(3, 2), pty = 'm')\nplot(p_cover_mod.lm1)\nplot(cooks.distance(p_cover_mod.lm1))\n\n\n\n\n\n\n\n\n\nComparison of default qqplots for beta and linear models. Beta models use weighted residuals 2 recommended in and linear model are the response residuals.\n\n\n\n\n\npar(mfrow = c(2,1), pty = 'm', cex = 1)\n\nplot(p_cover_mod.beta2, which = 5, type = \"sweighted2\", main = \"\")\nplot(p_cover_mod.lm2, which = 2, main = \"\")\n\n\n\n\n\nClassical Analysis\nFrom Douma & Weedon (2019)\n\n\np_cover.aov1 &lt;- aov(pland_decimal ~ Site, data = p_cover)\nsummary(p_cover.aov1)\n##              Df Sum Sq Mean Sq F value Pr(&gt;F)    \n## Site          2 12.699   6.350    2203 &lt;2e-16 ***\n## Residuals   747  2.153   0.003                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\np_cover.aov2 &lt;- aov(pland_decimal ~ Site + Error(plot_id), data = p_cover)\nsummary(p_cover.aov2)\n## \n## Error: plot_id\n##            Df Sum Sq Mean Sq F value Pr(&gt;F)\n## Residuals 249 0.7794 0.00313               \n## \n## Error: Within\n##            Df Sum Sq Mean Sq F value Pr(&gt;F)    \n## Site        2 12.699   6.350    2302 &lt;2e-16 ***\n## Residuals 498  1.373   0.003                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA very similar analysis can be conducted using the library nlme for mixed effects modeling.\n\np_cover.lme1 &lt;- lme(pland_decimal ~ Site, random = ~ 1 | plot_id, data = p_cover)\n\n\nanova(p_cover.lme1)\n\n            numDF denDF  F-value p-value\n(Intercept)     1   498 2698.541  &lt;.0001\nSite            2   498 2302.345  &lt;.0001\n\n\n\np_cover.lme_null &lt;- lme(pland_decimal ~ 1, random = ~ 1 | plot_id, data = p_cover)\n\n\nlmtest::lrtest(p_cover.lme1, p_cover.lme_null)\n\nLikelihood ratio test\n\nModel 1: pland_decimal ~ Site\nModel 2: pland_decimal ~ 1\n  #Df  LogLik Df Chisq Pr(&gt;Chisq)    \n1   5 1117.16                        \n2   3  402.18 -2  1430  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nBeta regression with no variable precision \\(\\phi\\)\nWe now turn to the beta regression model, that models the response variable as being generated from a beta distribution (i.e. that is bounded at 0 and 1).\nThe observations of percent cover are based on replicate quadrats replicated within three experimental plots.\nWe begin by attempting to fit a beta regression model, with pland_decimal as the response, and Site as the categorical predictor.\n\np_cover.bm1 &lt;- betareg(pland_decimal_scaled ~ Site, data = p_cover)\n\nbetareg will not accept values of 0 and 1 in the response variable.\nThere are two possible solutions here, rescaling the data to remove 0s and 1s, or fitting zero-inflated models. We start here with the rescaling solution. A suggested rescaling equation is:\n\\[ x^*_{i} = \\frac{x_i(n-1)+0.5}{n} \\]\nWhere \\(x^*_i\\) is the transformation of \\(x_i\\) and \\(n\\) is the total number of observations in the dataset.\nFor convenience we define this as a custom function tranform01 and apply it to the dataset:\n\ntransform01 &lt;- function(x) {\n  (x * (length(x) - 1) + 0.5) / (length(x))\n}\n\nWith this scaled data we can now successfully fit the model. And test its significance relative to a null model that assumes no effect of wave power on percent cover of pocilloporid corals. For reference we also fit a classical ANOVA model assuming normally distributed errors using lm.\n\np_cover.bmnull &lt;- betareg(pland_decimal_scaled ~ 1, data = p_cover)\nsummary(p_cover.bmnull)\n\n\nCall:\nbetareg(formula = pland_decimal_scaled ~ 1, data = p_cover)\n\nStandardized weighted residuals 2:\n    Min      1Q  Median      3Q     Max \n-0.8695 -0.8695  0.0151  0.8905  1.1783 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.18925    0.05919  -36.99   &lt;2e-16 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(&gt;|z|)    \n(phi)   3.0204     0.1916   15.76   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  1511 on 2 Df\nNumber of iterations: 15 (BFGS) + 1 (Fisher scoring) \n\n\n\np_cover.lm1 &lt;- lm(pland_decimal_scaled ~ Site, data = p_cover)\nsummary(p_cover.lm1)\n\n\nCall:\nlm(formula = pland_decimal_scaled ~ Site, data = p_cover)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.266731 -0.022414 -0.006013  0.015284  0.242053 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.006680   0.003391    1.97  0.04920 *  \nSiteman     0.016401   0.004795    3.42  0.00066 ***\nSitevhu     0.283499   0.004795   59.12  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05361 on 747 degrees of freedom\nMultiple R-squared:  0.8551,    Adjusted R-squared:  0.8547 \nF-statistic:  2203 on 2 and 747 DF,  p-value: &lt; 2.2e-16\n\n\n\nlmtest::lrtest(p_cover.bm1, p_cover.bmnull)\n\nLikelihood ratio test\n\nModel 1: pland_decimal_scaled ~ Site\nModel 2: pland_decimal_scaled ~ 1\n  #Df LogLik Df  Chisq Pr(&gt;Chisq)    \n1   4 2093.7                         \n2   2 1511.0 -2 1165.3  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nAIC(p_cover.bm1, p_cover.lm1, p_cover.bmnull)\n\n               df       AIC\np_cover.bm1     4 -4179.365\np_cover.lm1     4 -2255.582\np_cover.bmnull  2 -3018.031\n\n\nAccording to the likelihood-ratio test there is a significant difference between the null model and the treatment model. The AIC analysis supports this conclusion, but also highlights the improved model fit with beta regression relative to normal ANOVA (lm1). From this initial analysis we would tentatively conclude that using beta regresson improves our ability to model the algal cover, but that there is no effect of grazer manipulation treatment.\nIt is useful to plot the predictions derived from the model and compare them to the observed data. First we define two new functions to allow us to use the dbeta and rbeta functions with the \\(\\mu\\) and \\(\\phi\\) parameterization.\n\n\ndbeta2 &lt;- function(X, mu, phi, ...) {\n  dbeta(X, shape1 = mu * phi, shape2 = (1 - mu) * phi, ...)\n}\n\nrbeta2 &lt;- function(N, mu, phi, ...) {\n  rbeta(N, shape1 = mu * phi, shape2 = (1 - mu) * phi, ...)\n}\n\n\nWith this function we can plot the distributions corresponding to the MLE parameters for each treatment :\n\n\n# extract coefficients of beta regression model\ncoefs.bm1 &lt;- coef(p_cover.bm1)\n\n# create vector spanning the transformed 0-1 interval\n\nn.bm2 &lt;- length(fitted(p_cover.bm1))\nx.range &lt;- seq(0.5/n.bm2 , 1-0.5/n.bm2 , length.out = 200)\nx.range.bt &lt;- (x.range*n.bm2 - 0.5)/(n.bm2-1)\n\n\n# Anakena\nplot(x.range.bt, dbeta2(x.range, inv.logit(coefs.bm1[\"(Intercept)\"]), coefs.bm1[\"(phi)\"]),\n     type = \"l\", lty = 2, lwd = 2,\n     ylab = \"Probability density\", xlab = \"Proportion cover\",\n     ylim=c(0, 10)\n)\n\n# Manavai\nlines(x.range.bt, dbeta2(x.range, inv.logit(coefs.bm1[\"(Intercept)\"] + coefs.bm1[2]), coefs.bm1[\"(phi)\"]),lwd = 2, col = \"red\")\n\n# Vaihu\nlines(x.range.bt, dbeta2(x.range, inv.logit(coefs.bm1[\"(Intercept)\"] + coefs.bm1[3]), coefs.bm1[\"(phi)\"]), col = \"blue\", lwd = 2)\n\nrug(p_cover$pland_decimal[p_cover$Site == \"ana\"], lwd = 1.5, pos = 10)\n\nrug(p_cover$pland_decimal[p_cover$Site == \"man\"],col=\"red\", pos = 9.75, side = 3,lwd=1.5)\n\nrug(p_cover$pland_decimal[p_cover$Site == \"vhu\"], col=\"blue\", pos = 9.5, side = 3, lwd=1.5)\n\nlegend(\"topright\", lwd = 2, lty = c(2, 1, 1, 1), col = c(\"black\", \"red\", \"blue\"), legend = c(\"Anakena\", \"Manavai\", \"Vaihu\"), bty = \"n\")\n\n\n\n\n\nWe have added the original observations as ticks of the appropriate colour, and back-transformed the densities to allow fair visual comparisons between the fitted distributions and the original data using:\n\\[ x_{i} = \\frac{x^*_in-0.5}{(n-1)} \\]\nNote that the vertical positioning of the dots is merely to prevent overplotting.\nFrom this plot we can see that the model does a reasonable job of fitting beta distributions to each of the treatment levels… And that likewise, the variance of the groups …. This can be confirmed with a residual plot, using residuals calculated relative to their predicted variance.\n\nplot(resid(p_cover.bm1) ~ fitted(p_cover.bm1))\n\n\n\n\nIs this statement accurate?\nThe spread of the standardized residuals is strongly related to the fitted values, suggesting that variance is not being adequately modeled. This observation suggests the possible utility of allowing for the precision parameter \\(\\phi\\) to vary between treatment groups. The following section will show extension of the beta regression model to allow for this.\n\n\nVariable precision \\(\\phi\\)\nWe can repeat the above analysis using a model that allows \\(\\phi\\) to vary with predictors. This is achieved by adding a second part to the right hand side of the formula, separated with the | symbol. All covariates to the right of this | symbol will be used to model \\(\\phi\\). Note that they do not have to be the same covariates used to model \\(\\mu\\) (specified to the left of the |).\n\np_cover.bm2 &lt;- betareg(pland_decimal_scaled ~ Site | Site, data = p_cover)\n\nsummary(p_cover.bm2)\n\n\nCall:\nbetareg(formula = pland_decimal_scaled ~ Site | Site, data = p_cover)\n\nStandardized weighted residuals 2:\n    Min      1Q  Median      3Q     Max \n-6.1960 -0.5649 -0.3417  0.7115  1.8425 \n\nCoefficients (mean model with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.99928    0.08784 -56.913   &lt;2e-16 ***\nSiteman      1.26338    0.13630   9.269   &lt;2e-16 ***\nSitevhu      4.09928    0.09194  44.584   &lt;2e-16 ***\n\nPhi coefficients (precision model with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   4.3427     0.1141  38.052  &lt; 2e-16 ***\nSiteman      -1.6249     0.1679  -9.680  &lt; 2e-16 ***\nSitevhu      -1.1097     0.1441  -7.699 1.37e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  2136 on 6 Df\nPseudo R-squared: 0.6791\nNumber of iterations: 22 (BFGS) + 1 (Fisher scoring) \n\n\nFrom the Coefficients table we see that the estimate for \\(\\mu\\) in the Control treatment is inv.logit(-4.1313) = X = X% coral cover. Moreover, the estimates of \\(\\mu\\) for the other two Sites (treatments) are each significantly higher.\nFrom the Phi coefficients table we can see that the maximum likelihood estimate of the precision is highest in the Control treatment and is reduced significantly relative to this baseline in each of other treatment groups. In other words, the model fit confirms our impression from the previous two graphs that a fixed \\(\\phi\\) model overestimates variance in the Control treatment, and underestimates it in the other three treatments.\nWe can use likelihood-ratio tests to compare the new model to the fixed-\\(\\phi\\) and null models.\n\nlmtest::lrtest(p_cover.bm1, p_cover.bm2)\n\nLikelihood ratio test\n\nModel 1: pland_decimal_scaled ~ Site\nModel 2: pland_decimal_scaled ~ Site | Site\n  #Df LogLik Df  Chisq Pr(&gt;Chisq)    \n1   4 2093.7                         \n2   6 2135.7  2 84.034  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlmtest::lrtest(p_cover.bmnull, p_cover.bm1, p_cover.bm2)\n\nLikelihood ratio test\n\nModel 1: pland_decimal_scaled ~ 1\nModel 2: pland_decimal_scaled ~ Site\nModel 3: pland_decimal_scaled ~ Site | Site\n  #Df LogLik Df    Chisq Pr(&gt;Chisq)    \n1   2 1511.0                           \n2   4 2093.7  2 1165.334  &lt; 2.2e-16 ***\n3   6 2135.7  2   84.034  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe likelihood ratio tests indicate that the model with varying \\(\\phi\\) is significantly better than both the previous fixed \\(\\phi\\) model, and the null model. In this case the conclusion is that including the model for \\(\\phi\\) led to a better fitting model than both the fixed \\(\\phi\\) model and the null model.\nIt is possible to apply post-hoc tests to identify which pariwise contrasts of treatments levels are significant.\n\ntest(pairs(emmeans(p_cover.bm2, ~ Site, mode = \"link\")))\n\n contrast  estimate     SE  df z.ratio p.value\n ana - man    -1.26 0.1363 Inf  -9.269  &lt;.0001\n ana - vhu    -4.10 0.0919 Inf -44.584  &lt;.0001\n man - vhu    -2.84 0.1077 Inf -26.331  &lt;.0001\n\nResults are given on the log odds ratio (not the response) scale. \nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nWe conclude from this analysis that each Site treatment is significantly different to each other. This is an important point: correct modeling of \\(\\phi\\) can often be important for accurate inference on \\(\\mu\\).\nResidual plots confirm our conclusion that p_cover.bm2 provides a better fit to the observed data than p_cover.bm1. This is seen by the more even spread of residuals in the second plot below.\n\n\npar(mfrow = c(2, 1), oma = c(0, 0, 0, 0), mar = c(4, 4, 0.2, 0.2))\nplot(residuals(p_cover.bm1) ~ fitted(p_cover.bm1))\nplot(residuals(p_cover.bm2) ~ fitted(p_cover.bm2))\n\n\n\n\n\nAs above we can plot the MLE distributions for each of the treatments, based on the variable \\(\\phi\\) model:\n\n\n# plot distributions\nmuphi.bm2 &lt;- unique(data.frame(\n  mu = fitted(p_cover.bm2),\n  phi = predict(p_cover.bm2, type = \"precision\"),\n  treatment = p_cover$Site\n))\n\n\n\n\nplot(x.range.bt , dbeta2(x.range, muphi.bm2[1, 1], muphi.bm2[1, 2]),\n     type=\"l\",\n     xlab = \"Proportion cover\", ylab = \"Probability density\",\n     lty = 2, lwd = 2)\n\nfor (i in 2:3) {\n  lines(x.range.bt, dbeta2(x.range, muphi.bm2[i, 1], muphi.bm2[i, 2]), col = c(\"black\", \"red\", \"blue\")[i], lty = 1, lwd = 2)\n}\n\nlegend(\"topright\", lwd = 2, lty = c(2, 1, 1, 1), col = c(\"black\", \"red\", \"blue\"), legend = c(\"Anakena\", \"Manavai\", \"Vaihu\"), bty = \"n\")\n\n\n\n\n\nDue to the much narrower variance of the Control treatment group in this model, the probability density plots of the other treatments are rather distorted. The graph below rescales the Y axis for comparison to the fixed \\(\\phi\\) model above.\n\n\nplot(x.range.bt , dbeta2(x.range, muphi.bm2[1, \"mu\"], muphi.bm2[1, \"phi\"]),\n     type=\"l\",\n     xlab = \"Proportion cover\", ylab = \"Probability density\",\n     lty = 2, lwd = 2, ylim = c(0,10))\n\nfor (i in 2:3) {\n  lines(x.range.bt, dbeta2(x.range, muphi.bm2[i, \"mu\"], muphi.bm2[i, \"phi\"]), col = c(\"black\", \"red\", \"blue\")[i], lty = 1, lwd = 2)\n}\n  \nlegend(\"topright\", lwd = 2, lty = c(2, 1, 1, 1), col = c(\"black\", \"red\", \"blue\"), legend = c(\"Anakena\", \"Manavai\", \"Vaihu\"), bty = \"n\")\n\nrug(p_cover$pland_decimal[p_cover$Site == \"ana\"], lwd = 1.5, pos = 10)\n\nrug(p_cover$pland_decimal[p_cover$Site == \"man\"], col = \"red\", pos = 9.75, side = 3,lwd = 1.5)\n\nrug(p_cover$pland_decimal[p_cover$Site == \"vhu\"], col = \"blue\", pos = 9.5, side = 3, lwd = 1.5)\n\n\n\n\n\nThese plots support the conclusion from the likelihood ratio tests above. The best-fit distributions from the variable \\(\\phi\\) model better match the observed differences in dispersion between the different groups.\n\npoci_cover &lt;-\np_cover %&gt;%\n  as_tibble() %&gt;%\n#  mutate(size_cm = area*10000) %&gt;%\n  group_by(Site) %&gt;%\n  dplyr::summarize(mean = mean(pland_decimal), \n                   sd = sd(pland_decimal), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %&gt;%\n  mutate_at(vars(Site), factor) %&gt;%\n  add_column(\n          location = c('Anakena', 'Manavai', 'Southeast')\n          ) %&gt;%\n  mutate_at(vars(location), factor)\n\n\npoci_cover2 &lt;- \npoci_cover %&gt;%\n  add_column(\n          cld = c('a', 'b', 'c')\n          ) %&gt;%\nmutate_at(vars(cld), factor)\n\n\npoci_cover2\n\n# A tibble: 3 × 9\n  Site     mean     sd     n       se lower.ci upper.ci location  cld  \n  &lt;fct&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;\n1 ana   0.00602 0.0110   250 0.000696  0.00465  0.00739 Anakena   a    \n2 man   0.0224  0.0423   250 0.00268   0.0172   0.0277  Manavai   b    \n3 vhu   0.290   0.0821   250 0.00519   0.280    0.300   Southeast c    \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n# label_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\", \"25 m\" = \"25 m\")\n\n\npoci_cover.ggbarplot &lt;- ggplot(poci_cover2, aes(x = location, y = mean, fill = x_labels)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = lower.ci, ymax = upper.ci), size = 0.75) +\n  scale_y_continuous(expression(paste(\"Mean Percent Cover (%)\")), limits = c(0, 1)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) +\n#  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  geom_text(aes(label = cld, y = upper.ci), vjust = -0.5) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        plot.title = element_text(size = 11),\n        axis.title.y = element_text(size = 11),\n        legend.title = element_blank())\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\npoci_cover.ggbarplot"
  },
  {
    "objectID": "content/percent_cover_fieldwork2016.html",
    "href": "content/percent_cover_fieldwork2016.html",
    "title": "Percent Cover Transects & Photos 2016",
    "section": "",
    "text": "rpn_ana_sh &lt;- read.csv('ana_sh.csv') %&gt;%\n  as_tibble() %&gt;%\n  mutate_at(vars(location, depth, transect, photo, group), factor)\n\n\nrpn_ana_sh\n\n# A tibble: 420 × 7\n   location depth transect photo group    successes failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;        &lt;int&gt;    &lt;int&gt;\n 1 north    sh    t1       t1_1  abiotic          0      100\n 2 north    sh    t1       t1_1  biotic           0      100\n 3 north    sh    t1       t1_1  macro            2       98\n 4 north    sh    t1       t1_1  non-reef        12       88\n 5 north    sh    t1       t1_1  plob            85       15\n 6 north    sh    t1       t1_1  poci             0      100\n 7 north    sh    t1       t1_1  turf             1       99\n 8 north    sh    t1       t1_10 abiotic          0      100\n 9 north    sh    t1       t1_10 biotic           0      100\n10 north    sh    t1       t1_10 macro           13       87\n# ℹ 410 more rows\n\n\n\nrpn_ana_md &lt;- read.csv('ana_md.csv') %&gt;%\n  as_tibble() %&gt;%\n  mutate_at(vars(location, depth, transect, photo, group), factor)\n\n\nrpn_ana_md\n\n# A tibble: 420 × 7\n   location depth transect photo group    successes failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;        &lt;int&gt;    &lt;int&gt;\n 1 north    md    t1       t1_1  abiotic          0      100\n 2 north    md    t1       t1_1  biotic           0      100\n 3 north    md    t1       t1_1  macro            8       92\n 4 north    md    t1       t1_1  non-reef        27       73\n 5 north    md    t1       t1_1  plob            42       58\n 6 north    md    t1       t1_1  poci             5       95\n 7 north    md    t1       t1_1  turf            18       82\n 8 north    md    t1       t1_10 abiotic          0      100\n 9 north    md    t1       t1_10 biotic           0      100\n10 north    md    t1       t1_10 macro            8       92\n# ℹ 410 more rows\n\n\n\nrpn_ana_dp &lt;- read.csv('ana_dp.csv') %&gt;%\n  as_tibble() %&gt;%\n  mutate_at(vars(location, depth, transect, photo, group), factor)\n\n\nrpn_ana_dp\n\n# A tibble: 420 × 7\n   location depth transect photo group    successes failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;        &lt;int&gt;    &lt;int&gt;\n 1 north    dp    t1       t1_1  abiotic          1       99\n 2 north    dp    t1       t1_1  biotic           0      100\n 3 north    dp    t1       t1_1  macro           17       83\n 4 north    dp    t1       t1_1  non-reef        15       85\n 5 north    dp    t1       t1_1  plob            62       38\n 6 north    dp    t1       t1_1  poci             5       95\n 7 north    dp    t1       t1_1  turf             0      100\n 8 north    dp    t1       t1_10 abiotic          0      100\n 9 north    dp    t1       t1_10 biotic           0      100\n10 north    dp    t1       t1_10 macro           25       75\n# ℹ 410 more rows\n\n\n\nrpn_north &lt;- bind_rows(rpn_ana_sh, rpn_ana_md, rpn_ana_dp) %&gt;%\n  as_tibble() %&gt;%\n  mutate_at(vars(location, depth, transect, photo, group), factor)\n\n\nrpn_north\n\n# A tibble: 1,260 × 7\n   location depth transect photo group    successes failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;        &lt;int&gt;    &lt;int&gt;\n 1 north    sh    t1       t1_1  abiotic          0      100\n 2 north    sh    t1       t1_1  biotic           0      100\n 3 north    sh    t1       t1_1  macro            2       98\n 4 north    sh    t1       t1_1  non-reef        12       88\n 5 north    sh    t1       t1_1  plob            85       15\n 6 north    sh    t1       t1_1  poci             0      100\n 7 north    sh    t1       t1_1  turf             1       99\n 8 north    sh    t1       t1_10 abiotic          0      100\n 9 north    sh    t1       t1_10 biotic           0      100\n10 north    sh    t1       t1_10 macro           13       87\n# ℹ 1,250 more rows\n\n\n\nrpn_north_plob &lt;- rpn_north %&gt;%  \n  filter(group == \"plob\") %&gt;%\n  group_by(depth, transect, photo)\n\n\nrpn_north_plob\n\n# A tibble: 180 × 7\n# Groups:   depth, transect, photo [179]\n   location depth transect photo group successes failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;     &lt;int&gt;    &lt;int&gt;\n 1 north    sh    t1       t1_1  plob         85       15\n 2 north    sh    t1       t1_10 plob         81       19\n 3 north    sh    t1       t1_11 plob         81       19\n 4 north    sh    t1       t1_12 plob         56       44\n 5 north    sh    t1       t1_13 plob         68       32\n 6 north    sh    t1       t1_14 plob         93        7\n 7 north    sh    t1       t1_15 plob         57       43\n 8 north    sh    t1       t1_2  plob         81       19\n 9 north    sh    t1       t1_3  plob         82       18\n10 north    sh    t1       t1_4  plob         84       16\n# ℹ 170 more rows\n\n\n\nrpn_north.glm &lt;- glm(cbind(successes, failures) ~ depth, \n                  family = binomial(link = \"logit\"), data = rpn_north_plob)\n\n\nsummary(rpn_north.glm)\n\n\nCall:\nglm(formula = cbind(successes, failures) ~ depth, family = binomial(link = \"logit\"), \n    data = rpn_north_plob)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.10306    0.02985  36.957   &lt;2e-16 ***\ndepthmd     -0.10082    0.04171  -2.417   0.0156 *  \ndepthdp     -0.55221    0.04012 -13.765   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2859.7  on 179  degrees of freedom\nResidual deviance: 2638.2  on 177  degrees of freedom\nAIC: 3470.5\n\nNumber of Fisher Scoring iterations: 4\n\n\nAnova function from the car package\n\nAnova(rpn_north.glm, type = \"III\") # Type III because... \n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(successes, failures)\n      LR Chisq Df Pr(&gt;Chisq)    \ndepth   221.54  2  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_north_poci &lt;- rpn_north %&gt;%  \n  filter(group == \"poci\") %&gt;%\n  group_by(depth, transect, photo)\n\n\nrpn_north_poci\n\n# A tibble: 180 × 7\n# Groups:   depth, transect, photo [179]\n   location depth transect photo group successes failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;     &lt;int&gt;    &lt;int&gt;\n 1 north    sh    t1       t1_1  poci          0      100\n 2 north    sh    t1       t1_10 poci          0      100\n 3 north    sh    t1       t1_11 poci          0      100\n 4 north    sh    t1       t1_12 poci          0      100\n 5 north    sh    t1       t1_13 poci          0      100\n 6 north    sh    t1       t1_14 poci          0      100\n 7 north    sh    t1       t1_15 poci          0      100\n 8 north    sh    t1       t1_2  poci          0      100\n 9 north    sh    t1       t1_3  poci          0      100\n10 north    sh    t1       t1_4  poci          0      100\n# ℹ 170 more rows\n\n\n\nrpn_north_poci.glm &lt;- glm(cbind(successes, failures) ~ depth, \n                  family = binomial(link = \"logit\"), data = rpn_north_poci)\n\n\nsummary(rpn_north_poci.glm)\n\n\nCall:\nglm(formula = cbind(successes, failures) ~ depth, family = binomial(link = \"logit\"), \n    data = rpn_north_poci)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.064235   0.193055 -26.232   &lt;2e-16 ***\ndepthmd      0.008659   0.252491   0.034   0.9726    \ndepthdp      0.565436   0.229324   2.466   0.0137 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 391.76  on 162  degrees of freedom\nResidual deviance: 381.68  on 160  degrees of freedom\nAIC: 515.35\n\nNumber of Fisher Scoring iterations: 5\n\n\nAnova function from the car package\n\nAnova(rpn_north_poci.glm, type = \"III\") # Type III because... \n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(successes, failures)\n      LR Chisq Df Pr(&gt;Chisq)   \ndepth   10.083  2   0.006465 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "content/publishing.html",
    "href": "content/publishing.html",
    "title": "Publishing",
    "section": "",
    "text": "To get your Quarto webpage to show up with the url\nyou have a few steps."
  },
  {
    "objectID": "content/publishing.html#turn-on-github-pages-for-your-repo",
    "href": "content/publishing.html#turn-on-github-pages-for-your-repo",
    "title": "Publishing",
    "section": "Turn on GitHub Pages for your repo",
    "text": "Turn on GitHub Pages for your repo\n\nTurn on GitHub Pages under Settings &gt; Pages . You will set pages to be made from the gh-pages branch and the root directory.\nTurn on GitHub Actions under Settings &gt; Actions &gt; General\n\nThe GitHub Action will automatically recreate your website when you push to GitHub after you do the initial gh-pages set-up"
  },
  {
    "objectID": "content/publishing.html#do-your-first-publish-to-gh-pages",
    "href": "content/publishing.html#do-your-first-publish-to-gh-pages",
    "title": "Publishing",
    "section": "Do your first publish to gh-pages",
    "text": "Do your first publish to gh-pages\nThe first time you publish to gh-pages, you need to do so locally.\n\nOn your local computer, open a terminal window and cd to your repo directory. Here is what that cd command looks like for me. You command will look different because your local repo will be somewhere else on your computer.\n\ncd ~/Documents/GitHub/NOAA-quarto-simple\n\nPublish to the gh-pages. In the terminal type\n\nquarto publish gh-pages\nThis is going to render your webpage and then push the _site contents to the gh-pages branch."
  },
  {
    "objectID": "content/publishing.html#dont-like-using-gh-pages",
    "href": "content/publishing.html#dont-like-using-gh-pages",
    "title": "Publishing",
    "section": "Don’t like using gh-pages?",
    "text": "Don’t like using gh-pages?\nIn some cases, you don’t want your website on the gh-pages branch. For example, if you are creating releases and you want the website pages archived in that release, then you won’t want your website pages on the gh-pages branch.\nHere are the changes you need to make if you to avoid gh-pages branch.\n\nAt the top of _quarto.yml add the following:\n\nproject: \n  type: website\n  output-dir: docs\n\nOn GitHub under Settings &gt; Pages set pages to be made from the main branch and the docs directory.\nMake sure docs is not listed in .gitignore\nPublish the site the first time locally using quarto publish from the terminal\nChange the GitHub Action because you can’t use quarto publish gh-pages. You’ll need to push to the main branch yourself (in the GitHub Action)\n\non:\n  push:\n    branches: main\n\nname: Render and Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v2 \n        \n      - name: Set up R (needed for Rmd)\n        uses: r-lib/actions/setup-r@v2\n\n      - name: Install packages (needed for Rmd)\n        run: Rscript -e 'install.packages(c(\"rmarkdown\", \"knitr\", \"jsonlite\"))'\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        with:\n          # To install LaTeX to build PDF book \n          # tinytex: true \n          # uncomment below and fill to pin a version\n          # version: 0.9.600\n      \n      - name: Render Quarto Project\n        uses: quarto-dev/quarto-actions/render@v2\n        with:\n          to: html\n\n      - name: Set up Git\n        run: |\n          git config --local user.email \"actions@github.com\"\n          git config --local user.name \"GitHub Actions\"\n\n      - name: Commit all changes and push\n        run: |\n          git add -A && git commit -m 'Build site' || echo \"No changes to commit\"\n          git push origin || echo \"No changes to commit\""
  },
  {
    "objectID": "content/dispersion_presentation.html#different-patterns-of-dispersion",
    "href": "content/dispersion_presentation.html#different-patterns-of-dispersion",
    "title": "Pocilloporid Dispersion at Rapa Nui",
    "section": "Different patterns of dispersion",
    "text": "Different patterns of dispersion\n\nEnvironmental heterogeneity"
  },
  {
    "objectID": "content/rendering.html",
    "href": "content/rendering.html",
    "title": "Rendering",
    "section": "",
    "text": "The repo includes a GitHub Action that will render (build) the website automatically when you make changes to the files. It will be pushed to the gh-pages branch.\nBut when you are developing your content, you will want to render it locally."
  },
  {
    "objectID": "content/rendering.html#step-1.-make-sure-you-have-a-recent-rstudio",
    "href": "content/rendering.html#step-1.-make-sure-you-have-a-recent-rstudio",
    "title": "Rendering",
    "section": "Step 1. Make sure you have a recent RStudio",
    "text": "Step 1. Make sure you have a recent RStudio\nHave you updated RStudio since about August 2022? No? Then update to a newer version of RStudio. In general, you want to keep RStudio updated and it is required to have a recent version to use Quarto."
  },
  {
    "objectID": "content/rendering.html#step-2.-clone-and-create-rstudio-project",
    "href": "content/rendering.html#step-2.-clone-and-create-rstudio-project",
    "title": "Rendering",
    "section": "Step 2. Clone and create RStudio project",
    "text": "Step 2. Clone and create RStudio project\nFirst, clone the repo onto your local computer. How? You can click File &gt; New Project and then select “Version Control”. Paste in the url of the repository. That will clone the repo on to your local computer. When you make changes, you will need to push those up."
  },
  {
    "objectID": "content/rendering.html#step-3.-render-within-rstudio",
    "href": "content/rendering.html#step-3.-render-within-rstudio",
    "title": "Rendering",
    "section": "Step 3. Render within RStudio",
    "text": "Step 3. Render within RStudio\nRStudio will recognize that this is a Quarto project by the presence of the _quarto.yml file and will see the “Build” tab. Click the “Render website” button to render to the _site folder.\nPreviewing: You can either click index.html in the _site folder and specify “preview in browser” or set up RStudio to preview to the viewer panel. To do the latter, go to Tools &gt; Global Options &gt; R Markdown. Then select “Show output preview in: Viewer panel”."
  },
  {
    "objectID": "content/acknowledgements.html",
    "href": "content/acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "This repo and GitHub Action was based on the tutorial by Openscapes quarto-website-tutorial by Julia Lowndes and Stefanie Butland."
  },
  {
    "objectID": "content/research_strategy.html#spatial-pattern-of-reef-bulding-corals",
    "href": "content/research_strategy.html#spatial-pattern-of-reef-bulding-corals",
    "title": "Spatial patterns of competition between coral at Rapa Nui",
    "section": "Spatial pattern of reef-bulding corals",
    "text": "Spatial pattern of reef-bulding corals\n\nResult of positive and negative interactions between neighboring coral that compete for space on the reef to live\n\nImportant for ecological theory\n\nThree-dimensional structure that facilitates abundance and diversity of other reef organisms like fish and crustaceans\n\nImportant food sources to island communities"
  },
  {
    "objectID": "content/research_strategy.html#spatial-pattern-of-reef-bulding-corals-1",
    "href": "content/research_strategy.html#spatial-pattern-of-reef-bulding-corals-1",
    "title": "Spatial patterns of competition between coral at Rapa Nui",
    "section": "Spatial pattern of reef-bulding corals",
    "text": "Spatial pattern of reef-bulding corals\n\nDo the frequencies of positive and negative interactions between neighboring coral change over environmental gradients?\n\nImportant for ecological theory\n\nEnvironmental gradients may affect the three-dimensional structure of a reef and may respond in asymmetric ways to acute disturbances.\n\nImportant food sources to island communities"
  },
  {
    "objectID": "content/research_strategy.html#link-between-coral-interactions-and-community-structure",
    "href": "content/research_strategy.html#link-between-coral-interactions-and-community-structure",
    "title": "Spatial patterns of competition between coral at Rapa Nui",
    "section": "Link between coral interactions and community structure",
    "text": "Link between coral interactions and community structure\n\nAny ecological consequences of coral interactions must be manifested\n\nImportant for ecological theory\nBradbury & Young (1983)\n\nEnvironmental gradients may affect the three-dimensional structure of a reef and may respond in asymmetric ways to acute disturbances.\n\nImportant food sources to island communities"
  },
  {
    "objectID": "content/research_strategy.html#methodology",
    "href": "content/research_strategy.html#methodology",
    "title": "Spatial patterns of competition between coral at Rapa Nui",
    "section": "Methodology",
    "text": "Methodology\n\nLarge-area imaging (LAI)\n\nImportant for ecological theory\n\nRandomization tests for spatially structured ecological data\n\nBootstrapping technique\nMcTague, S. et al. in prep\n\nBradbury & Young (1983)"
  },
  {
    "objectID": "content/bleaching2.html",
    "href": "content/bleaching2.html",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "",
    "text": "rpn_bleach &lt;- read.csv('rpn_bleach_2015.csv') %&gt;%\n  as_tibble() %&gt;%\n  mutate_at(vars(location, depth, transect, group, status), factor)\nrpn_bleach\n\n# A tibble: 1,512 × 7\n   location depth transect point metric group status\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;int&gt;  &lt;int&gt; &lt;fct&gt; &lt;fct&gt; \n 1 north    sh    one          1      0 PLOB  PB    \n 2 north    sh    one          2     20 PLOB  PB    \n 3 north    sh    one          3     40 PLOB  PB    \n 4 north    sh    one          4     60 MA    HAL   \n 5 north    sh    one          5     80 TURF  na    \n 6 north    sh    one          6    100 TURF  na    \n 7 north    sh    one          7    120 TURF  na    \n 8 north    sh    one          8    140 PLOB  PB    \n 9 north    sh    one          9    160 PLOB  PB    \n10 north    sh    one         10    180 PLOB  PB    \n# ℹ 1,502 more rows\nrpn_summary &lt;- rpn_bleach %&gt;%  \n  group_by(location, depth, transect, group) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth', 'transect'. You can\noverride using the `.groups` argument.\nrpn_summary\n\n# A tibble: 65 × 5\n# Groups:   location, depth, transect [12]\n   location depth transect group total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;       &lt;int&gt;\n 1 north    dp    one      MA              5\n 2 north    dp    one      PLOB          104\n 3 north    dp    one      POCI            7\n 4 north    dp    one      SAND           10\n 5 north    dp    two      MA              7\n 6 north    dp    two      PLOB          113\n 7 north    dp    two      POCI            2\n 8 north    dp    two      SAND            1\n 9 north    dp    two      TURF            3\n10 north    sh    one      DC              8\n# ℹ 55 more rows\nrpn_PLOB &lt;- rpn_bleach %&gt;%  \n  filter(group == \"PLOB\") %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\nrpn_PLOB\n\n# A tibble: 12 × 4\n# Groups:   location, depth [6]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one              104\n 2 north    dp    two              113\n 3 north    sh    one               83\n 4 north    sh    two               88\n 5 se       dp    one               34\n 6 se       dp    two               28\n 7 se       sh    one               35\n 8 se       sh    two               15\n 9 west     dp    one               89\n10 west     dp    two               73\n11 west     sh    one               74\n12 west     sh    two              101\nrpn_plob &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"PLOB\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\nrpn_plob\n\n# A tibble: 12 × 8\n   location depth transect group total_count total_points cover failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;       &lt;int&gt;        &lt;int&gt; &lt;dbl&gt;    &lt;int&gt;\n 1 north    dp    one      PLOB          104          126 0.825       22\n 2 north    dp    two      PLOB          113          126 0.897       13\n 3 north    sh    one      PLOB           83          126 0.659       43\n 4 north    sh    two      PLOB           88          126 0.698       38\n 5 se       dp    one      PLOB           34          124 0.274       90\n 6 se       dp    two      PLOB           28          105 0.267       77\n 7 se       sh    one      PLOB           35          126 0.278       91\n 8 se       sh    two      PLOB           15          126 0.119      111\n 9 west     dp    one      PLOB           89          126 0.706       37\n10 west     dp    two      PLOB           73          126 0.579       53\n11 west     sh    one      PLOB           74          126 0.587       52\n12 west     sh    two      PLOB          101          126 0.802       25"
  },
  {
    "objectID": "content/bleaching2.html#porites",
    "href": "content/bleaching2.html#porites",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Porites",
    "text": "Porites\n\nGeneralized linear model\n\nplob.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_plob)\n\n\npar(mfrow = c(2, 2))\nplot(plob.glm)\n\n\n\n\n\nsummary(plob.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_plob)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            1.8245     0.1822  10.017  &lt; 2e-16 ***\nlocationse            -2.8154     0.2352 -11.973  &lt; 2e-16 ***\nlocationwest          -1.2368     0.2246  -5.506 3.68e-08 ***\ndepthsh               -1.0773     0.2267  -4.753 2.00e-06 ***\nlocationse:depthsh     0.6719     0.3138   2.142   0.0322 *  \nlocationwest:depthsh   1.3105     0.2956   4.434 9.25e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 396.020  on 11  degrees of freedom\nResidual deviance:  31.694  on  6  degrees of freedom\nAIC: 102.95\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nAnova(plob.glm, type = \"III\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(total_count, failures)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        186.616  2  &lt; 2.2e-16 ***\ndepth            24.219  1  8.599e-07 ***\nlocation:depth   20.391  2  3.735e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_plob$groups &lt;- interaction(rpn_plob$location, rpn_plob$depth)"
  },
  {
    "objectID": "content/bleaching2.html#create-a-post-hoc-model",
    "href": "content/bleaching2.html#create-a-post-hoc-model",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_plob &lt;- with(rpn_plob, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest",
    "href": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_plob, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0 -0.07377    0.19208  -0.384    0.795    \n(north.sh) - (west.dp) == 0  0.15943    0.18835   0.846    0.795    \n(north.sh) - (se.sh) == 0    2.14346    0.20771  10.319  &lt; 2e-16 ***\n(north.sh) - (se.dp) == 0    1.73807    0.20078   8.657  &lt; 2e-16 ***\n(north.dp) - (west.sh) == 0  1.00357    0.22777   4.406 3.16e-05 ***\n(north.dp) - (west.dp) == 0  1.23676    0.22464   5.506 1.47e-07 ***\n(north.dp) - (se.sh) == 0    3.22079    0.24110  13.359  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0    2.81541    0.23515  11.973  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0    -2.21723    0.20893 -10.612  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0    -1.98403    0.20551  -9.654  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0    -1.81184    0.20204  -8.968  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0    -1.57865    0.19850  -7.953 8.88e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_plob2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"PLOB\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_plob2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth  mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.861 0.0505      2 0.0357     0.407    1.31 \n2 north    sh    0.679 0.0281      2 0.0198     0.426    0.931\n3 se       dp    0.270 0.00532     2 0.00376    0.223    0.318\n4 se       sh    0.198 0.112       2 0.0794    -0.810    1.21 \n5 west     dp    0.643 0.0898      2 0.0635    -0.164    1.45 \n6 west     sh    0.694 0.152       2 0.107     -0.667    2.06 \n\n\n\nrpn_plob3 &lt;-\n  as_tibble(rpn_plob2)\n\n\nrpn_plob_summ &lt;-\n    rpn_plob3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_plob_summ\n\n# A tibble: 6 × 10\n  location depth  mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.861 0.0505      2 0.0357     0.407    1.31  North     15 m  \n2 north    sh    0.679 0.0281      2 0.0198     0.426    0.931 North     8 m   \n3 se       dp    0.270 0.00532     2 0.00376    0.223    0.318 Southeast 15 m  \n4 se       sh    0.198 0.112       2 0.0794    -0.810    1.21  Southeast 8 m   \n5 west     dp    0.643 0.0898      2 0.0635    -0.164    1.45  West      15 m  \n6 west     sh    0.694 0.152       2 0.107     -0.667    2.06  West      8 m   \n\n\n\nrpn_plob_summ.gg &lt;- rpn_plob_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_plob_summ.gg &lt;- rpn_plob_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_plob_summ.gg\n\n# A tibble: 6 × 10\n  location depth  mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.861 0.0505      2 0.0357     0.407    1.31  North     15 m  \n2 north    sh    0.679 0.0281      2 0.0198     0.426    0.931 North     8 m   \n3 se       dp    0.270 0.00532     2 0.00376    0.223    0.318 Southeast 15 m  \n4 se       sh    0.198 0.112       2 0.0794    -0.810    1.21  Southeast 8 m   \n5 west     dp    0.643 0.0898      2 0.0635    -0.164    1.45  West      15 m  \n6 west     sh    0.694 0.152       2 0.107     -0.667    2.06  West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_plob_2015.ggbarplot &lt;- ggplot(rpn_plob_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_plob_2015.ggbarplot &lt;- ggplot(rpn_plob_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_plob_2015.ggbarplot\n\n\n\n\n\nrpn_plob_bleach &lt;- rpn_bleach %&gt;%  \n  filter(group == 'PLOB' & status == 'BL') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_pb &lt;- rpn_bleach %&gt;% \n  filter(group == 'PLOB' & status == 'PB') %&gt;% \n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_pb\n\n# A tibble: 9 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                5\n2 north    dp    two               49\n3 north    sh    one               40\n4 north    sh    two               31\n5 se       dp    two                2\n6 west     dp    one               70\n7 west     dp    two               55\n8 west     sh    one               64\n9 west     sh    two               46\n\n\n\nrpn_plob_pb2 &lt;-\nas.data.frame(rpn_plob_pb) %&gt;%\n  add_row(location = 'se', depth = 'dp', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'se', depth = 'sh', transect = 'one', total_count = 0) %&gt;%\n  add_row(location = 'se', depth = 'sh', transect = 'two', total_count = 0)\n\n\nrpn_plob_pb.main &lt;- rpn_plob_pb2 %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_plob_pb.main\n\n   location depth transect total_count      cover failures\n1     north    dp      one           5 0.03968254      121\n2     north    dp      two          49 0.38888889       77\n3     north    sh      one          40 0.31746032       86\n4     north    sh      two          31 0.24603175       95\n5        se    dp      two           2 0.01587302      124\n6      west    dp      one          70 0.55555556       56\n7      west    dp      two          55 0.43650794       71\n8      west    sh      one          64 0.50793651       62\n9      west    sh      two          46 0.36507937       80\n10       se    dp      two           0 0.00000000      126\n11       se    sh      one           0 0.00000000      126\n12       se    sh      two           0 0.00000000      126\n\n\n\nrpn_plob_pale &lt;- rpn_bleach %&gt;%  \n  filter(group == 'PLOB' & status == 'P') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_pale\n\n# A tibble: 12 × 4\n# Groups:   location, depth [6]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one               87\n 2 north    dp    two               52\n 3 north    sh    one               28\n 4 north    sh    two               37\n 5 se       dp    one               23\n 6 se       dp    two                2\n 7 se       sh    one               29\n 8 se       sh    two                9\n 9 west     dp    one               17\n10 west     dp    two               16\n11 west     sh    one                5\n12 west     sh    two               55\n\n\n\nrpn_plob_pale.main &lt;- rpn_plob_pale %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_plob_pale.main\n\n# A tibble: 12 × 6\n# Groups:   location, depth [6]\n   location depth transect total_count  cover failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 north    dp    one               87 0.690        39\n 2 north    dp    two               52 0.413        74\n 3 north    sh    one               28 0.222        98\n 4 north    sh    two               37 0.294        89\n 5 se       dp    one               23 0.183       103\n 6 se       dp    two                2 0.0159      124\n 7 se       sh    one               29 0.230        97\n 8 se       sh    two                9 0.0714      117\n 9 west     dp    one               17 0.135       109\n10 west     dp    two               16 0.127       110\n11 west     sh    one                5 0.0397      121\n12 west     sh    two               55 0.437        71\n\n\n\nrpn_plob_healthy &lt;- rpn_bleach %&gt;%  \n  filter(group == 'PLOB' & status == 'H') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_healthy\n\n# A tibble: 10 × 4\n# Groups:   location, depth [6]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one               12\n 2 north    dp    two               12\n 3 north    sh    one               15\n 4 north    sh    two               20\n 5 se       dp    one               11\n 6 se       sh    one                6\n 7 se       sh    two                6\n 8 west     dp    one                2\n 9 west     dp    two                2\n10 west     sh    one                5\n\n\n\nrpn_plob_healthy2 &lt;-\nas.data.frame(rpn_plob_healthy) %&gt;%\n  add_row(location = 'se', depth = 'dp', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'west', depth = 'sh', transect = 'two', total_count = 0)\n\n\nrpn_plob_healthy2\n\n   location depth transect total_count\n1     north    dp      one          12\n2     north    dp      two          12\n3     north    sh      one          15\n4     north    sh      two          20\n5        se    dp      one          11\n6        se    sh      one           6\n7        se    sh      two           6\n8      west    dp      one           2\n9      west    dp      two           2\n10     west    sh      one           5\n11       se    dp      two           0\n12     west    sh      two           0\n\n\n\nrpn_plob_healthy.main &lt;- rpn_plob_healthy2 %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_plob_healthy.main \n\n   location depth transect total_count      cover failures\n1     north    dp      one          12 0.09523810      114\n2     north    dp      two          12 0.09523810      114\n3     north    sh      one          15 0.11904762      111\n4     north    sh      two          20 0.15873016      106\n5        se    dp      one          11 0.08730159      115\n6        se    sh      one           6 0.04761905      120\n7        se    sh      two           6 0.04761905      120\n8      west    dp      one           2 0.01587302      124\n9      west    dp      two           2 0.01587302      124\n10     west    sh      one           5 0.03968254      121\n11       se    dp      two           0 0.00000000      126\n12     west    sh      two           0 0.00000000      126"
  },
  {
    "objectID": "content/bleaching2.html#pocillopora",
    "href": "content/bleaching2.html#pocillopora",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Pocillopora",
    "text": "Pocillopora\n\nrpn_bleach &lt;- read.csv('rpn_bleach_2015.csv') %&gt;%\n  as_tibble() %&gt;%\n  mutate_at(vars(location, depth, transect, group, status), factor)\n\n\nrpn_bleach\n\n# A tibble: 1,512 × 7\n   location depth transect point metric group status\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;int&gt;  &lt;int&gt; &lt;fct&gt; &lt;fct&gt; \n 1 north    sh    one          1      0 PLOB  PB    \n 2 north    sh    one          2     20 PLOB  PB    \n 3 north    sh    one          3     40 PLOB  PB    \n 4 north    sh    one          4     60 MA    HAL   \n 5 north    sh    one          5     80 TURF  na    \n 6 north    sh    one          6    100 TURF  na    \n 7 north    sh    one          7    120 TURF  na    \n 8 north    sh    one          8    140 PLOB  PB    \n 9 north    sh    one          9    160 PLOB  PB    \n10 north    sh    one         10    180 PLOB  PB    \n# ℹ 1,502 more rows\n\n\n\nrpn_summary &lt;- rpn_bleach %&gt;%  \n  group_by(location, depth, transect, group) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth', 'transect'. You can\noverride using the `.groups` argument.\n\n\n\nrpn_POCI &lt;- rpn_bleach %&gt;%  \n  filter(group == \"POCI\") %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_POCI\n\n# A tibble: 11 × 4\n# Groups:   location, depth [6]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one                7\n 2 north    dp    two                2\n 3 north    sh    two                1\n 4 se       dp    one               57\n 5 se       dp    two               58\n 6 se       sh    one               75\n 7 se       sh    two               60\n 8 west     dp    one               13\n 9 west     dp    two               14\n10 west     sh    one               15\n11 west     sh    two               18\n\n\n\nrpn_poci &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"POCI\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nrpn_plob\n\n# A tibble: 12 × 9\n   location depth transect group total_count total_points cover failures groups \n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;       &lt;int&gt;        &lt;int&gt; &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;  \n 1 north    dp    one      PLOB          104          126 0.825       22 north.…\n 2 north    dp    two      PLOB          113          126 0.897       13 north.…\n 3 north    sh    one      PLOB           83          126 0.659       43 north.…\n 4 north    sh    two      PLOB           88          126 0.698       38 north.…\n 5 se       dp    one      PLOB           34          124 0.274       90 se.dp  \n 6 se       dp    two      PLOB           28          105 0.267       77 se.dp  \n 7 se       sh    one      PLOB           35          126 0.278       91 se.sh  \n 8 se       sh    two      PLOB           15          126 0.119      111 se.sh  \n 9 west     dp    one      PLOB           89          126 0.706       37 west.dp\n10 west     dp    two      PLOB           73          126 0.579       53 west.dp\n11 west     sh    one      PLOB           74          126 0.587       52 west.sh\n12 west     sh    two      PLOB          101          126 0.802       25 west.sh"
  },
  {
    "objectID": "content/bleaching2.html#pocillopora-1",
    "href": "content/bleaching2.html#pocillopora-1",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Pocillopora",
    "text": "Pocillopora\n\nGeneralized linear model\n\npoci.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_poci)\n\n\npar(mfrow = c(2, 2))\nplot(poci.glm)\n\n\n\n\n\nsummary(poci.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_poci)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -3.2958     0.3395  -9.709  &lt; 2e-16 ***\nlocationse             3.3046     0.3643   9.072  &lt; 2e-16 ***\nlocationwest           1.1756     0.3959   2.970  0.00298 ** \ndepthsh               -2.2296     1.0579  -2.108  0.03507 *  \nlocationse:depthsh     2.3640     1.0736   2.202  0.02767 *  \nlocationwest:depthsh   2.4573     1.0934   2.247  0.02462 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 436.578  on 11  degrees of freedom\nResidual deviance:  10.347  on  6  degrees of freedom\nAIC: 69.293\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_poci$groups &lt;- interaction(rpn_poci$location, rpn_poci$depth)"
  },
  {
    "objectID": "content/bleaching2.html#create-a-post-hoc-model-1",
    "href": "content/bleaching2.html#create-a-post-hoc-model-1",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_poci &lt;- with(rpn_poci, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-1",
    "href": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-1",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_poci, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  -3.6329     1.0192  -3.564  0.00117 ** \n(north.sh) - (west.dp) == 0  -3.4052     1.0225  -3.330  0.00173 ** \n(north.sh) - (se.sh) == 0    -5.6686     1.0099  -5.613 1.19e-07 ***\n(north.sh) - (se.dp) == 0    -5.5342     1.0107  -5.476 2.18e-07 ***\n(north.dp) - (west.sh) == 0  -1.4033     0.3874  -3.622  0.00117 ** \n(north.dp) - (west.dp) == 0  -1.1756     0.3959  -2.970  0.00298 ** \n(north.dp) - (se.sh) == 0    -3.4389     0.3622  -9.495  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0    -3.3046     0.3643  -9.072  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0      2.0357     0.2254   9.030  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0      2.2634     0.2397   9.444  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0      1.9013     0.2288   8.311  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0      2.1290     0.2428   8.769  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_poci2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"POCI\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_poci2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth    mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288 \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544\n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29  \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158 \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282 \n\n\n\nrpn_poci3 &lt;-\n  as_tibble(rpn_poci2)\n\n\nrpn_poci_summ &lt;-\n    rpn_poci3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_poci_summ\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_poci_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching2.html#create-a-post-hoc-model-2",
    "href": "content/bleaching2.html#create-a-post-hoc-model-2",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_poci &lt;- with(rpn_poci, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-2",
    "href": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-2",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_poci, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  -3.6329     1.0192  -3.564  0.00117 ** \n(north.sh) - (west.dp) == 0  -3.4052     1.0225  -3.330  0.00173 ** \n(north.sh) - (se.sh) == 0    -5.6686     1.0099  -5.613 1.19e-07 ***\n(north.sh) - (se.dp) == 0    -5.5342     1.0107  -5.476 2.18e-07 ***\n(north.dp) - (west.sh) == 0  -1.4033     0.3874  -3.622  0.00117 ** \n(north.dp) - (west.dp) == 0  -1.1756     0.3959  -2.970  0.00298 ** \n(north.dp) - (se.sh) == 0    -3.4389     0.3622  -9.495  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0    -3.3046     0.3643  -9.072  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0      2.0357     0.2254   9.030  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0      2.2634     0.2397   9.444  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0      1.9013     0.2288   8.311  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0      2.1290     0.2428   8.769  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_poci_bleach &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'BL') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_bleach\n\n# A tibble: 6 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                1\n2 se       dp    one                1\n3 se       dp    two                2\n4 se       sh    two                1\n5 west     dp    one                4\n6 west     sh    two                2\n\n\n\nrpn_poci_pb &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'PB') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_pb\n\n# A tibble: 8 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                2\n2 north    dp    two                1\n3 se       dp    one               27\n4 se       dp    two                9\n5 se       sh    one                2\n6 se       sh    two                5\n7 west     dp    two                2\n8 west     sh    one                1\n\n\n\nrpn_poci_pale &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'P') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_pale\n\n# A tibble: 10 × 4\n# Groups:   location, depth [5]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one                3\n 2 north    dp    two                1\n 3 se       dp    one               19\n 4 se       dp    two               16\n 5 se       sh    one               59\n 6 se       sh    two               45\n 7 west     dp    one                7\n 8 west     dp    two                8\n 9 west     sh    one               13\n10 west     sh    two                9\n\n\n\nrpn_poci_healthy &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'H') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_healthy\n\n# A tibble: 9 × 4\n# Groups:   location, depth [6]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                1\n2 north    sh    two                1\n3 se       dp    one               10\n4 se       sh    one               14\n5 se       sh    two                9\n6 west     dp    one                2\n7 west     dp    two                4\n8 west     sh    one                1\n9 west     sh    two                7"
  },
  {
    "objectID": "content/bleaching2.html#examine-bleaching-response-of-coral-groups",
    "href": "content/bleaching2.html#examine-bleaching-response-of-coral-groups",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Examine bleaching response of coral groups",
    "text": "Examine bleaching response of coral groups\n\nrpn_plob_pb.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                family = binomial(link = \"logit\"), \n                data = rpn_plob_pb.main)\n\n\npar(mfrow = c(2, 2))\nplot(rpn_plob_pb.glm)\n\n\n\n\n\nsummary(rpn_plob_pb.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_plob_pb.main)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -1.2993     0.1535  -8.463  &lt; 2e-16 ***\nlocationse             -3.5290     0.7263  -4.859 1.18e-06 ***\nlocationwest            1.2834     0.1986   6.462 1.03e-10 ***\ndepthsh                 0.3635     0.2078   1.749   0.0803 .  \nlocationse:depthsh    -17.0748  1817.2897  -0.009   0.9925    \nlocationwest:depthsh   -0.6029     0.2742  -2.199   0.0279 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 449.568  on 11  degrees of freedom\nResidual deviance:  64.609  on  6  degrees of freedom\nAIC: 119.1\n\nNumber of Fisher Scoring iterations: 16\n\n\nAnova function from the car package\n\nAnova(rpn_plob_pb.glm, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(total_count, failures)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        197.689  2    &lt; 2e-16 ***\ndepth             3.082  1    0.07916 .  \nlocation:depth    7.657  2    0.02174 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_plob_pb.main\n\n   location depth transect total_count      cover failures\n1     north    dp      one           5 0.03968254      121\n2     north    dp      two          49 0.38888889       77\n3     north    sh      one          40 0.31746032       86\n4     north    sh      two          31 0.24603175       95\n5        se    dp      two           2 0.01587302      124\n6      west    dp      one          70 0.55555556       56\n7      west    dp      two          55 0.43650794       71\n8      west    sh      one          64 0.50793651       62\n9      west    sh      two          46 0.36507937       80\n10       se    dp      two           0 0.00000000      126\n11       se    sh      one           0 0.00000000      126\n12       se    sh      two           0 0.00000000      126\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_plob_pb.main$groups &lt;- interaction(rpn_plob_pb.main$location, rpn_plob_pb.main$depth)"
  },
  {
    "objectID": "content/bleaching2.html#create-a-post-hoc-model-3",
    "href": "content/bleaching2.html#create-a-post-hoc-model-3",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nrpn_plob_pb.lm &lt;- with(rpn_plob_pb.main, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-3",
    "href": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-3",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(rpn_plob_pb.lm, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0   -0.6805     0.1891  -3.599   0.0016 ** \n(north.sh) - (west.dp) == 0   -0.9199     0.1884  -4.884 7.29e-06 ***\n(north.sh) - (se.sh) == 0     20.6038  1817.2895   0.011   1.0000    \n(north.sh) - (se.dp) == 0      3.8925     0.7236   5.379 6.73e-07 ***\n(north.dp) - (west.sh) == 0   -1.0439     0.1993  -5.239 1.29e-06 ***\n(north.dp) - (west.dp) == 0   -1.2834     0.1986  -6.462 1.14e-09 ***\n(north.dp) - (se.sh) == 0     20.2403  1817.2895   0.011   1.0000    \n(north.dp) - (se.dp) == 0      3.5290     0.7263   4.859 7.29e-06 ***\n(se.sh) - (west.sh) == 0     -21.2843  1817.2895  -0.012   1.0000    \n(se.sh) - (west.dp) == 0     -21.5238  1817.2895  -0.012   1.0000    \n(se.dp) - (west.sh) == 0      -4.5730     0.7212  -6.341 2.29e-09 ***\n(se.dp) - (west.dp) == 0      -4.8124     0.7210  -6.674 2.98e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)"
  },
  {
    "objectID": "content/bleaching2.html#pocillopora-2",
    "href": "content/bleaching2.html#pocillopora-2",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Pocillopora",
    "text": "Pocillopora\n\nGeneralized linear model\n\npoci.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_poci)\n\n\npar(mfrow = c(2, 2))\nplot(poci.glm)\n\n\n\n\n\nsummary(poci.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_poci)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -3.2958     0.3395  -9.709  &lt; 2e-16 ***\nlocationse             3.3046     0.3643   9.072  &lt; 2e-16 ***\nlocationwest           1.1756     0.3959   2.970  0.00298 ** \ndepthsh               -2.2296     1.0579  -2.108  0.03507 *  \nlocationse:depthsh     2.3640     1.0736   2.202  0.02767 *  \nlocationwest:depthsh   2.4573     1.0934   2.247  0.02462 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 436.578  on 11  degrees of freedom\nResidual deviance:  10.347  on  6  degrees of freedom\nAIC: 69.293\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_poci$groups &lt;- interaction(rpn_poci$location, rpn_poci$depth)"
  },
  {
    "objectID": "content/bleaching2.html#create-a-post-hoc-model-4",
    "href": "content/bleaching2.html#create-a-post-hoc-model-4",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_poci &lt;- with(rpn_poci, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-4",
    "href": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-4",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_poci, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  -3.6329     1.0192  -3.564  0.00117 ** \n(north.sh) - (west.dp) == 0  -3.4052     1.0225  -3.330  0.00173 ** \n(north.sh) - (se.sh) == 0    -5.6686     1.0099  -5.613 1.19e-07 ***\n(north.sh) - (se.dp) == 0    -5.5342     1.0107  -5.476 2.18e-07 ***\n(north.dp) - (west.sh) == 0  -1.4033     0.3874  -3.622  0.00117 ** \n(north.dp) - (west.dp) == 0  -1.1756     0.3959  -2.970  0.00298 ** \n(north.dp) - (se.sh) == 0    -3.4389     0.3622  -9.495  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0    -3.3046     0.3643  -9.072  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0      2.0357     0.2254   9.030  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0      2.2634     0.2397   9.444  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0      1.9013     0.2288   8.311  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0      2.1290     0.2428   8.769  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_poci2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"POCI\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_poci2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth    mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288 \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544\n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29  \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158 \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282 \n\n\n\nrpn_poci3 &lt;-\n  as_tibble(rpn_poci2)\n\n\nrpn_poci_summ &lt;-\n    rpn_poci3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_poci_summ\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_poci_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching2.html#macroalgae",
    "href": "content/bleaching2.html#macroalgae",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Macroalgae",
    "text": "Macroalgae\n\nGeneralized linear model\n\nrpn_ma &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"MA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nma.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_ma)\n\n\npar(mfrow = c(2, 2))\nplot(ma.glm)\n\n\n\n\n\nsummary(ma.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_ma)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -2.9957     0.2958 -10.127   &lt;2e-16 ***\nlocationse            -19.4459  2992.7957  -0.006    0.995    \nlocationwest           -0.1906     0.4378  -0.435    0.663    \ndepthsh                -0.3001     0.4503  -0.667    0.505    \nlocationse:depthsh     17.2163  2992.7959   0.006    0.995    \nlocationwest:depthsh   -0.2271     0.6911  -0.329    0.742    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 45.822  on 11  degrees of freedom\nResidual deviance: 20.051  on  6  degrees of freedom\nAIC: 57.317\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_ma$groups &lt;- interaction(rpn_ma$location, rpn_ma$depth)"
  },
  {
    "objectID": "content/bleaching2.html#create-a-post-hoc-model-5",
    "href": "content/bleaching2.html#create-a-post-hoc-model-5",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_ma &lt;- with(rpn_ma, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-5",
    "href": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-5",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_ma, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)\n(north.sh) - (west.sh) == 0    0.4177     0.5348   0.781    1.000\n(north.sh) - (west.dp) == 0   -0.1095     0.4684  -0.234    1.000\n(north.sh) - (se.sh) == 0      2.2296     1.0579   2.108    0.351\n(north.sh) - (se.dp) == 0     19.1458  2992.7957   0.006    1.000\n(north.dp) - (west.sh) == 0    0.7178     0.5082   1.413    1.000\n(north.dp) - (west.dp) == 0    0.1906     0.4378   0.435    1.000\n(north.dp) - (se.sh) == 0      2.5297     1.0447   2.421    0.186\n(north.dp) - (se.dp) == 0     19.4459  2992.7957   0.006    1.000\n(se.sh) - (west.sh) == 0      -1.8119     1.0838  -1.672    0.851\n(se.sh) - (west.dp) == 0      -2.3391     1.0527  -2.222    0.289\n(se.dp) - (west.sh) == 0     -18.7281  2992.7957  -0.006    1.000\n(se.dp) - (west.dp) == 0     -19.2553  2992.7957  -0.006    1.000\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_ma2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"MA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_ma2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth    mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0476  0.0112      2 0.00794  -0.0532   0.148 \n2 north    sh    0.0357  0.0168      2 0.0119   -0.116    0.187 \n3 se       dp    0       0           2 0         0        0     \n4 se       sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544\n5 west     dp    0.0397  0.0561      2 0.0397   -0.465    0.544 \n6 west     sh    0.0238  0.0224      2 0.0159   -0.178    0.225 \n\n\n\nrpn_ma3 &lt;-\n  as_tibble(rpn_ma2)\n\n\nrpn_ma_summ &lt;-\n    rpn_ma3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_ma_summ\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0476  0.0112      2 0.00794  -0.0532   0.148  North    15 m  \n2 north    sh    0.0357  0.0168      2 0.0119   -0.116    0.187  North    8 m   \n3 se       dp    0       0           2 0         0        0      Southea… 15 m  \n4 se       sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 Southea… 8 m   \n5 west     dp    0.0397  0.0561      2 0.0397   -0.465    0.544  West     15 m  \n6 west     sh    0.0238  0.0224      2 0.0159   -0.178    0.225  West     8 m   \n\n\n\nrpn_ma_summ.gg &lt;- rpn_ma_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_ma_summ.gg &lt;- rpn_ma_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_ma_summ.gg\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0476  0.0112      2 0.00794  -0.0532   0.148  North    15 m  \n2 north    sh    0.0357  0.0168      2 0.0119   -0.116    0.187  North    8 m   \n3 se       dp    0       0           2 0         0        0      Southea… 15 m  \n4 se       sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 Southea… 8 m   \n5 west     dp    0.0397  0.0561      2 0.0397   -0.465    0.544  West     15 m  \n6 west     sh    0.0238  0.0224      2 0.0159   -0.178    0.225  West     8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_ma_2015.ggbarplot &lt;- ggplot(rpn_ma_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_ma_2015.ggbarplot &lt;- ggplot(rpn_ma_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Macrolagae \")))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_ma_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching2.html#turf",
    "href": "content/bleaching2.html#turf",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Turf",
    "text": "Turf\n\nGeneralized linear model\n\nrpn_turf &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"TURF\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) \n\n\nturf.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_turf)\n\n\npar(mfrow = c(2, 2))\nplot(turf.glm)\n\n\n\n\n\nsummary(turf.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_turf)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -4.4188     0.5808  -7.608 2.78e-14 ***\nlocationse            -18.0228  2992.7958  -0.006    0.995    \nlocationwest            0.8635     0.6959   1.241    0.215    \ndepthsh                 0.7053     0.7128   0.989    0.322    \nlocationse:depthsh     17.3175  2992.7958   0.006    0.995    \nlocationwest:depthsh   -0.2368     0.8661  -0.273    0.785    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 34.021  on 11  degrees of freedom\nResidual deviance: 16.535  on  6  degrees of freedom\nAIC: 52.682\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_turf$groups &lt;- interaction(rpn_turf$location, rpn_turf$depth)"
  },
  {
    "objectID": "content/bleaching2.html#create-a-post-hoc-model-6",
    "href": "content/bleaching2.html#create-a-post-hoc-model-6",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_turf &lt;- with(rpn_turf, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-6",
    "href": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-6",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_turf, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                              Estimate Std. Error z value Pr(&gt;|z|)\n(north.sh) - (west.sh) == 0 -6.267e-01  5.155e-01  -1.216    1.000\n(north.sh) - (west.dp) == 0 -1.582e-01  5.636e-01  -0.281    1.000\n(north.sh) - (se.sh) == 0    7.053e-01  7.128e-01   0.989    1.000\n(north.sh) - (se.dp) == 0    1.873e+01  2.993e+03   0.006    1.000\n(north.dp) - (west.sh) == 0 -1.332e+00  6.576e-01  -2.026    0.514\n(north.dp) - (west.dp) == 0 -8.635e-01  6.959e-01  -1.241    1.000\n(north.dp) - (se.sh) == 0    1.567e-15  8.214e-01   0.000    1.000\n(north.dp) - (se.dp) == 0    1.802e+01  2.993e+03   0.006    1.000\n(se.sh) - (west.sh) == 0    -1.332e+00  6.576e-01  -2.026    0.514\n(se.sh) - (west.dp) == 0    -8.635e-01  6.959e-01  -1.241    1.000\n(se.dp) - (west.sh) == 0    -1.935e+01  2.993e+03  -0.006    1.000\n(se.dp) - (west.dp) == 0    -1.889e+01  2.993e+03  -0.006    1.000\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_turf2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"TURF\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_turf2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0119 0.0168      2 0.0119   -0.139    0.163 \n2 north    sh    0.0238 0.0224      2 0.0159   -0.178    0.225 \n3 se       dp    0      0           2 0         0        0     \n4 se       sh    0.0119 0.0168      2 0.0119   -0.139    0.163 \n5 west     dp    0.0278 0.00561     2 0.00397  -0.0226   0.0782\n6 west     sh    0.0437 0.0393      2 0.0278   -0.309    0.397 \n\n\n\nrpn_turf3 &lt;-\n  as_tibble(rpn_turf2)\n\n\nrpn_turf_summ &lt;-\n    rpn_turf3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_turf_summ\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0119 0.0168      2 0.0119   -0.139    0.163  North     15 m  \n2 north    sh    0.0238 0.0224      2 0.0159   -0.178    0.225  North     8 m   \n3 se       dp    0      0           2 0         0        0      Southeast 15 m  \n4 se       sh    0.0119 0.0168      2 0.0119   -0.139    0.163  Southeast 8 m   \n5 west     dp    0.0278 0.00561     2 0.00397  -0.0226   0.0782 West      15 m  \n6 west     sh    0.0437 0.0393      2 0.0278   -0.309    0.397  West      8 m   \n\n\n\nrpn_turf_summ.gg &lt;- rpn_turf_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_turf_summ.gg &lt;- rpn_turf_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_turf_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0119 0.0168      2 0.0119   -0.139    0.163  North     15 m  \n2 north    sh    0.0238 0.0224      2 0.0159   -0.178    0.225  North     8 m   \n3 se       dp    0      0           2 0         0        0      Southeast 15 m  \n4 se       sh    0.0119 0.0168      2 0.0119   -0.139    0.163  Southeast 8 m   \n5 west     dp    0.0278 0.00561     2 0.00397  -0.0226   0.0782 West      15 m  \n6 west     sh    0.0437 0.0393      2 0.0278   -0.309    0.397  West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_turf_2015.ggbarplot &lt;- ggplot(rpn_turf_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_turf_2015.ggbarplot &lt;- ggplot(rpn_turf_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" turfllopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_turf_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching2.html#sand",
    "href": "content/bleaching2.html#sand",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Sand",
    "text": "Sand\n\nGeneralized linear model\n\nrpn_sand &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"SAND\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nsand.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_sand)\n\n\npar(mfrow = c(2, 2))\nplot(sand.glm)\n\n\n\n\n\nsummary(sand.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_sand)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -3.0869     0.3083 -10.012  &lt; 2e-16 ***\nlocationse            -19.3547  2992.7957  -0.006    0.995    \nlocationwest            1.4486     0.3524   4.111 3.95e-05 ***\ndepthsh                 1.6140     0.3482   4.636 3.55e-06 ***\nlocationse:depthsh     -1.7120  4234.8629   0.000    1.000    \nlocationwest:depthsh   -2.5407     0.4584  -5.542 2.99e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 161.962  on 11  degrees of freedom\nResidual deviance:  28.599  on  6  degrees of freedom\nAIC: 72.931\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_sand$groups &lt;- interaction(rpn_sand$location, rpn_sand$depth)"
  },
  {
    "objectID": "content/bleaching2.html#create-a-post-hoc-model-7",
    "href": "content/bleaching2.html#create-a-post-hoc-model-7",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_sand &lt;- with(rpn_sand, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-7",
    "href": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-7",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_sand, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0    1.0921     0.2932   3.724 0.002154 ** \n(north.sh) - (west.dp) == 0    0.1654     0.2351   0.704 1.000000    \n(north.sh) - (se.sh) == 0     21.0668  2996.2039   0.007 1.000000    \n(north.sh) - (se.dp) == 0     20.9688  2992.7957   0.007 1.000000    \n(north.dp) - (west.sh) == 0   -0.5220     0.3936  -1.326 1.000000    \n(north.dp) - (west.dp) == 0   -1.4486     0.3524  -4.111 0.000473 ***\n(north.dp) - (se.sh) == 0     19.4527  2996.2039   0.006 1.000000    \n(north.dp) - (se.dp) == 0     19.3547  2992.7957   0.006 1.000000    \n(se.sh) - (west.sh) == 0     -19.9747  2996.2039  -0.007 1.000000    \n(se.sh) - (west.dp) == 0     -20.9013  2996.2039  -0.007 1.000000    \n(se.dp) - (west.sh) == 0     -19.8767  2992.7957  -0.007 1.000000    \n(se.dp) - (west.dp) == 0     -20.8034  2992.7957  -0.007 1.000000    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_sand2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"SAND\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_sand2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0437 0.0505      2 0.0357    -0.410    0.497\n2 north    sh    0.187  0.00561     2 0.00397    0.136    0.237\n3 se       dp    0      0           2 0          0        0    \n4 se       sh    0      0           2 0          0        0    \n5 west     dp    0.163  0.118       2 0.0833    -0.896    1.22 \n6 west     sh    0.0714 0.0561      2 0.0397    -0.433    0.576\n\n\n\nrpn_sand3 &lt;-\n  as_tibble(rpn_sand2)\n\n\nrpn_sand_summ &lt;-\n    rpn_sand3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_sand_summ\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0437 0.0505      2 0.0357    -0.410    0.497 North     15 m  \n2 north    sh    0.187  0.00561     2 0.00397    0.136    0.237 North     8 m   \n3 se       dp    0      0           2 0          0        0     Southeast 15 m  \n4 se       sh    0      0           2 0          0        0     Southeast 8 m   \n5 west     dp    0.163  0.118       2 0.0833    -0.896    1.22  West      15 m  \n6 west     sh    0.0714 0.0561      2 0.0397    -0.433    0.576 West      8 m   \n\n\n\nrpn_sand_summ.gg &lt;- rpn_sand_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_sand_summ.gg &lt;- rpn_sand_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_sand_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0437 0.0505      2 0.0357    -0.410    0.497 North     15 m  \n2 north    sh    0.187  0.00561     2 0.00397    0.136    0.237 North     8 m   \n3 se       dp    0      0           2 0          0        0     Southeast 15 m  \n4 se       sh    0      0           2 0          0        0     Southeast 8 m   \n5 west     dp    0.163  0.118       2 0.0833    -0.896    1.22  West      15 m  \n6 west     sh    0.0714 0.0561      2 0.0397    -0.433    0.576 West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_sand_2015.ggbarplot &lt;- ggplot(rpn_sand_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_sand_2015.ggbarplot &lt;- ggplot(rpn_sand_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Sand \")))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_sand_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching2.html#bare-substrate",
    "href": "content/bleaching2.html#bare-substrate",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Bare substrate",
    "text": "Bare substrate\n\nGeneralized linear model\n\nrpn_bare &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"BARE\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nbare.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_bare)\n\n\npar(mfrow = c(2, 2))\nplot(bare.glm)\n\n\n\n\n\nsummary(bare.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_bare)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)            -22.54    2996.20  -0.008    0.994\nlocationse              21.16    2996.20   0.007    0.994\nlocationwest            18.64    2996.20   0.006    0.995\ndepthsh                 19.97    2996.20   0.007    0.995\nlocationse:depthsh     -19.89    2996.20  -0.007    0.995\nlocationwest:depthsh   -38.61    4237.27  -0.009    0.993\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 221.002  on 11  degrees of freedom\nResidual deviance:  42.405  on  6  degrees of freedom\nAIC: 86.079\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_bare$groups &lt;- interaction(rpn_bare$location, rpn_bare$depth)"
  },
  {
    "objectID": "content/bleaching2.html#create-a-post-hoc-model-8",
    "href": "content/bleaching2.html#create-a-post-hoc-model-8",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_bare &lt;- with(rpn_bare, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-8",
    "href": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-8",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_bare, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  1.997e+01  2.996e+03   0.007 1.000000    \n(north.sh) - (west.dp) == 0  1.335e+00  5.137e-01   2.599 0.074830 .  \n(north.sh) - (se.sh) == 0   -1.266e+00  2.888e-01  -4.383 0.000117 ***\n(north.sh) - (se.dp) == 0   -1.184e+00  2.950e-01  -4.014 0.000538 ***\n(north.dp) - (west.sh) == 0 -6.022e-11  4.237e+03   0.000 1.000000    \n(north.dp) - (west.dp) == 0 -1.864e+01  2.996e+03  -0.006 1.000000    \n(north.dp) - (se.sh) == 0   -2.124e+01  2.996e+03  -0.007 1.000000    \n(north.dp) - (se.dp) == 0   -2.116e+01  2.996e+03  -0.007 1.000000    \n(se.sh) - (west.sh) == 0     2.124e+01  2.996e+03   0.007 1.000000    \n(se.sh) - (west.dp) == 0     2.601e+00  4.771e-01   5.451 6.01e-07 ***\n(se.dp) - (west.sh) == 0     2.116e+01  2.996e+03   0.007 1.000000    \n(se.dp) - (west.dp) == 0     2.519e+00  4.809e-01   5.238 1.78e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_bare2 &lt;- read.csv('rpn_cover.csv')\n\n\nrpn_bare2\n\n   location depth transect  group total_count total_points\n1     north    dp      one   BARE           0          126\n2     north    dp      one    CCA           0          126\n3     north    dp      one     MA           5          126\n4     north    dp      one   PLOB         104          126\n5     north    dp      one   POCI           7          126\n6     north    dp      one   SAND          10          126\n7     north    dp      one SPONGE           0          126\n8     north    dp      one   TURF           0          126\n9     north    dp      two   BARE           0          126\n10    north    dp      two    CCA           0          126\n11    north    dp      two     MA           7          126\n12    north    dp      two   PLOB         113          126\n13    north    dp      two   POCI           2          126\n14    north    dp      two   SAND           1          126\n15    north    dp      two SPONGE           0          126\n16    north    dp      two   TURF           3          126\n17    north    sh      one   BARE           8          126\n18    north    sh      one    CCA           0          126\n19    north    sh      one     MA           6          126\n20    north    sh      one   PLOB          83          126\n21    north    sh      one   POCI           0          126\n22    north    sh      one   SAND          24          126\n23    north    sh      one SPONGE           0          126\n24    north    sh      one   TURF           5          126\n25    north    sh      two   BARE          10          126\n26    north    sh      two    CCA           0          126\n27    north    sh      two     MA           3          126\n28    north    sh      two   PLOB          88          126\n29    north    sh      two   POCI           1          126\n30    north    sh      two   SAND          23          126\n31    north    sh      two SPONGE           0          126\n32    north    sh      two   TURF           1          126\n33       se    dp      one   BARE          33          124\n34       se    dp      one    CCA           0          124\n35       se    dp      one     MA           0          124\n36       se    dp      one   PLOB          34          124\n37       se    dp      one   POCI          57          124\n38       se    dp      one   SAND           0          124\n39       se    dp      one SPONGE           0          124\n40       se    dp      one   TURF           0          124\n41       se    dp      two   BARE          13          105\n42       se    dp      two    CCA           6          105\n43       se    dp      two     MA           0          105\n44       se    dp      two   PLOB          28          105\n45       se    dp      two   POCI          58          105\n46       se    dp      two   SAND           0          105\n47       se    dp      two SPONGE           0          105\n48       se    dp      two   TURF           0          105\n49       se    sh      one   BARE           9          126\n50       se    sh      one    CCA           4          126\n51       se    sh      one     MA           0          126\n52       se    sh      one   PLOB          35          126\n53       se    sh      one   POCI          75          126\n54       se    sh      one   SAND           0          126\n55       se    sh      one SPONGE           0          126\n56       se    sh      one   TURF           3          126\n57       se    sh      two   BARE          45          126\n58       se    sh      two    CCA           5          126\n59       se    sh      two     MA           1          126\n60       se    sh      two   PLOB          15          126\n61       se    sh      two   POCI          60          126\n62       se    sh      two   SAND           0          126\n63       se    sh      two SPONGE           0          126\n64       se    sh      two   TURF           0          126\n65     west    dp      one   BARE           1          126\n66     west    dp      one    CCA           0          126\n67     west    dp      one     MA          10          126\n68     west    dp      one   PLOB          89          126\n69     west    dp      one   POCI          13          126\n70     west    dp      one   SAND          10          126\n71     west    dp      one SPONGE           0          126\n72     west    dp      one   TURF           3          126\n73     west    dp      two   BARE           4          126\n74     west    dp      two    CCA           0          126\n75     west    dp      two     MA           0          126\n76     west    dp      two   PLOB          73          126\n77     west    dp      two   POCI          14          126\n78     west    dp      two   SAND          31          126\n79     west    dp      two SPONGE           0          126\n80     west    dp      two   TURF           4          126\n81     west    sh      one   BARE           0          126\n82     west    sh      one    CCA           0          126\n83     west    sh      one     MA           5          126\n84     west    sh      one   PLOB          74          126\n85     west    sh      one   POCI          15          126\n86     west    sh      one   SAND          14          126\n87     west    sh      one SPONGE           9          126\n88     west    sh      one   TURF           9          126\n89     west    sh      two   BARE           0          126\n90     west    sh      two    CCA           0          126\n91     west    sh      two     MA           1          126\n92     west    sh      two   PLOB         101          126\n93     west    sh      two   POCI          18          126\n94     west    sh      two   SAND           4          126\n95     west    sh      two SPONGE           0          126\n96     west    sh      two   TURF           2          126\n\n\n\nrpn_bare2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"BARE\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_bare2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean     sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0      0          2 0         0         0    \n2 north    sh    0.0714 0.0112     2 0.00794  -0.0294    0.172\n3 se       dp    0.195  0.101      2 0.0712   -0.709     1.10 \n4 se       sh    0.214  0.202      2 0.143    -1.60      2.03 \n5 west     dp    0.0198 0.0168     2 0.0119   -0.131     0.171\n6 west     sh    0      0          2 0         0         0    \n\n\n\nrpn_bare3 &lt;-\n  as_tibble(rpn_bare2)\n\n\nrpn_bare_summ &lt;-\n    rpn_bare3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_bare_summ\n\n# A tibble: 6 × 10\n  location depth   mean     sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0          2 0         0         0     North     15 m  \n2 north    sh    0.0714 0.0112     2 0.00794  -0.0294    0.172 North     8 m   \n3 se       dp    0.195  0.101      2 0.0712   -0.709     1.10  Southeast 15 m  \n4 se       sh    0.214  0.202      2 0.143    -1.60      2.03  Southeast 8 m   \n5 west     dp    0.0198 0.0168     2 0.0119   -0.131     0.171 West      15 m  \n6 west     sh    0      0          2 0         0         0     West      8 m   \n\n\n\nrpn_bare_summ.gg &lt;- rpn_bare_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_bare_summ.gg &lt;- rpn_bare_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_bare_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean     sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0          2 0         0         0     North     15 m  \n2 north    sh    0.0714 0.0112     2 0.00794  -0.0294    0.172 North     8 m   \n3 se       dp    0.195  0.101      2 0.0712   -0.709     1.10  Southeast 15 m  \n4 se       sh    0.214  0.202      2 0.143    -1.60      2.03  Southeast 8 m   \n5 west     dp    0.0198 0.0168     2 0.0119   -0.131     0.171 West      15 m  \n6 west     sh    0      0          2 0         0         0     West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_bare_2015.ggbarplot &lt;- ggplot(rpn_bare_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_bare_2015.ggbarplot &lt;- ggplot(rpn_bare_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Bare \")))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_bare_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching2.html#cca-substrate",
    "href": "content/bleaching2.html#cca-substrate",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "cca substrate",
    "text": "cca substrate\n\nGeneralized linear model\n\nrpn_cca &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"CCA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\ncca.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_cca)\n\n\npar(mfrow = c(2, 2))\nplot(cca.glm)\n\n\n\n\n\nsummary(cca.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_cca)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)          -2.454e+01  8.145e+03  -0.003    0.998\nlocationse            2.092e+01  8.145e+03   0.003    0.998\nlocationwest         -9.358e-09  1.152e+04   0.000    1.000\ndepthsh              -2.366e-08  1.152e+04   0.000    1.000\nlocationse:depthsh    3.196e-01  1.152e+04   0.000    1.000\nlocationwest:depthsh  2.365e-08  1.629e+04   0.000    1.000\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 44.2469  on 11  degrees of freedom\nResidual deviance:  9.6636  on  6  degrees of freedom\nAIC: 31.936\n\nNumber of Fisher Scoring iterations: 19\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_cca$groups &lt;- interaction(rpn_cca$location, rpn_cca$depth)"
  },
  {
    "objectID": "content/bleaching2.html#create-a-post-hoc-model-9",
    "href": "content/bleaching2.html#create-a-post-hoc-model-9",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_cca &lt;- with(rpn_cca, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-9",
    "href": "content/bleaching2.html#determine-the-post-hoc-comparisons-of-interest-9",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_cca, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                              Estimate Std. Error z value Pr(&gt;|z|)\n(north.sh) - (west.sh) == 0  3.412e-12  1.152e+04   0.000        1\n(north.sh) - (west.dp) == 0  3.501e-15  1.152e+04   0.000        1\n(north.sh) - (se.sh) == 0   -2.124e+01  8.145e+03  -0.003        1\n(north.sh) - (se.dp) == 0   -2.092e+01  8.145e+03  -0.003        1\n(north.dp) - (west.sh) == 0 -1.819e-08  1.152e+04   0.000        1\n(north.dp) - (west.dp) == 0 -1.819e-08  1.152e+04   0.000        1\n(north.dp) - (se.sh) == 0   -2.124e+01  8.145e+03  -0.003        1\n(north.dp) - (se.dp) == 0   -2.092e+01  8.145e+03  -0.003        1\n(se.sh) - (west.sh) == 0     2.124e+01  8.145e+03   0.003        1\n(se.sh) - (west.dp) == 0     2.124e+01  8.145e+03   0.003        1\n(se.dp) - (west.sh) == 0     2.092e+01  8.145e+03   0.003        1\n(se.dp) - (west.dp) == 0     2.092e+01  8.145e+03   0.003        1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_cca2 &lt;- read.csv('rpn_cover.csv')\n\n\nrpn_cca2\n\n   location depth transect  group total_count total_points\n1     north    dp      one   BARE           0          126\n2     north    dp      one    CCA           0          126\n3     north    dp      one     MA           5          126\n4     north    dp      one   PLOB         104          126\n5     north    dp      one   POCI           7          126\n6     north    dp      one   SAND          10          126\n7     north    dp      one SPONGE           0          126\n8     north    dp      one   TURF           0          126\n9     north    dp      two   BARE           0          126\n10    north    dp      two    CCA           0          126\n11    north    dp      two     MA           7          126\n12    north    dp      two   PLOB         113          126\n13    north    dp      two   POCI           2          126\n14    north    dp      two   SAND           1          126\n15    north    dp      two SPONGE           0          126\n16    north    dp      two   TURF           3          126\n17    north    sh      one   BARE           8          126\n18    north    sh      one    CCA           0          126\n19    north    sh      one     MA           6          126\n20    north    sh      one   PLOB          83          126\n21    north    sh      one   POCI           0          126\n22    north    sh      one   SAND          24          126\n23    north    sh      one SPONGE           0          126\n24    north    sh      one   TURF           5          126\n25    north    sh      two   BARE          10          126\n26    north    sh      two    CCA           0          126\n27    north    sh      two     MA           3          126\n28    north    sh      two   PLOB          88          126\n29    north    sh      two   POCI           1          126\n30    north    sh      two   SAND          23          126\n31    north    sh      two SPONGE           0          126\n32    north    sh      two   TURF           1          126\n33       se    dp      one   BARE          33          124\n34       se    dp      one    CCA           0          124\n35       se    dp      one     MA           0          124\n36       se    dp      one   PLOB          34          124\n37       se    dp      one   POCI          57          124\n38       se    dp      one   SAND           0          124\n39       se    dp      one SPONGE           0          124\n40       se    dp      one   TURF           0          124\n41       se    dp      two   BARE          13          105\n42       se    dp      two    CCA           6          105\n43       se    dp      two     MA           0          105\n44       se    dp      two   PLOB          28          105\n45       se    dp      two   POCI          58          105\n46       se    dp      two   SAND           0          105\n47       se    dp      two SPONGE           0          105\n48       se    dp      two   TURF           0          105\n49       se    sh      one   BARE           9          126\n50       se    sh      one    CCA           4          126\n51       se    sh      one     MA           0          126\n52       se    sh      one   PLOB          35          126\n53       se    sh      one   POCI          75          126\n54       se    sh      one   SAND           0          126\n55       se    sh      one SPONGE           0          126\n56       se    sh      one   TURF           3          126\n57       se    sh      two   BARE          45          126\n58       se    sh      two    CCA           5          126\n59       se    sh      two     MA           1          126\n60       se    sh      two   PLOB          15          126\n61       se    sh      two   POCI          60          126\n62       se    sh      two   SAND           0          126\n63       se    sh      two SPONGE           0          126\n64       se    sh      two   TURF           0          126\n65     west    dp      one   BARE           1          126\n66     west    dp      one    CCA           0          126\n67     west    dp      one     MA          10          126\n68     west    dp      one   PLOB          89          126\n69     west    dp      one   POCI          13          126\n70     west    dp      one   SAND          10          126\n71     west    dp      one SPONGE           0          126\n72     west    dp      one   TURF           3          126\n73     west    dp      two   BARE           4          126\n74     west    dp      two    CCA           0          126\n75     west    dp      two     MA           0          126\n76     west    dp      two   PLOB          73          126\n77     west    dp      two   POCI          14          126\n78     west    dp      two   SAND          31          126\n79     west    dp      two SPONGE           0          126\n80     west    dp      two   TURF           4          126\n81     west    sh      one   BARE           0          126\n82     west    sh      one    CCA           0          126\n83     west    sh      one     MA           5          126\n84     west    sh      one   PLOB          74          126\n85     west    sh      one   POCI          15          126\n86     west    sh      one   SAND          14          126\n87     west    sh      one SPONGE           9          126\n88     west    sh      one   TURF           9          126\n89     west    sh      two   BARE           0          126\n90     west    sh      two    CCA           0          126\n91     west    sh      two     MA           1          126\n92     west    sh      two   PLOB         101          126\n93     west    sh      two   POCI          18          126\n94     west    sh      two   SAND           4          126\n95     west    sh      two SPONGE           0          126\n96     west    sh      two   TURF           2          126\n\n\n\nrpn_cca2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"CCA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_cca2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0      0           2 0         0        0     \n2 north    sh    0      0           2 0         0        0     \n3 se       dp    0.0286 0.0404      2 0.0286   -0.334    0.392 \n4 se       sh    0.0357 0.00561     2 0.00397  -0.0147   0.0861\n5 west     dp    0      0           2 0         0        0     \n6 west     sh    0      0           2 0         0        0     \n\n\n\nrpn_cca3 &lt;-\n  as_tibble(rpn_cca2)\n\n\nrpn_cca_summ &lt;-\n    rpn_cca3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_cca_summ\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0           2 0         0        0      North     15 m  \n2 north    sh    0      0           2 0         0        0      North     8 m   \n3 se       dp    0.0286 0.0404      2 0.0286   -0.334    0.392  Southeast 15 m  \n4 se       sh    0.0357 0.00561     2 0.00397  -0.0147   0.0861 Southeast 8 m   \n5 west     dp    0      0           2 0         0        0      West      15 m  \n6 west     sh    0      0           2 0         0        0      West      8 m   \n\n\n\nrpn_cca_summ.gg &lt;- rpn_cca_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_cca_summ.gg &lt;- rpn_cca_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_cca_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0           2 0         0        0      North     15 m  \n2 north    sh    0      0           2 0         0        0      North     8 m   \n3 se       dp    0.0286 0.0404      2 0.0286   -0.334    0.392  Southeast 15 m  \n4 se       sh    0.0357 0.00561     2 0.00397  -0.0147   0.0861 Southeast 8 m   \n5 west     dp    0      0           2 0         0        0      West      15 m  \n6 west     sh    0      0           2 0         0        0      West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_cca_2015.ggbarplot &lt;- ggplot(rpn_cca_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_cca_2015.ggbarplot &lt;- ggplot(rpn_cca_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" ccallopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_cca_2015.ggbarplot\n\n\n\n\n\nrpn_crw &lt;- read_delim('rpn_crw.txt', delim = \" \")\n\nNew names:\n• `` -&gt; `...8`\n• `` -&gt; `...9`\n• `` -&gt; `...10`\n• `` -&gt; `...11`\n• `` -&gt; `...13`\n• `` -&gt; `...14`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 14005 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (3): MM, DD, BAA_7day_max\ndbl (6): YYYY, SST_MIN, SST_MAX, SST, ...11, 90th_HS\nlgl (8):        SSTA    , ...8, ...9, ...10, ...13, ...14, DHW,         \n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n#{r} #rpn_crw.main &lt;- write_csv(rpn_crw, 'rpn_crw.csv') #\n\nrpn_crw.main &lt;- read_csv('rpn_crw.csv')\n\nRows: 14005 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (7): year, month, day, sst_min, sst_max, sst, dhw\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nrpn_crw.main\n\n# A tibble: 14,005 × 7\n    year month   day sst_min sst_max   sst   dhw\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  1985     1     1    24.1    24.2  24.1     0\n 2  1985     1     2    24.2    24.3  24.2     0\n 3  1985     1     3    24.3    24.3  24.3     0\n 4  1985     1     4    24.4    24.4  24.4     0\n 5  1985     1     5    24.5    24.6  24.5     0\n 6  1985     1     6    25.2    25.3  25.3     0\n 7  1985     1     7    25.0    25.2  25.2     0\n 8  1985     1     8    25.7    25.9  25.9     0\n 9  1985     1     9    26      26.2  26.2     0\n10  1985     1    10    26.2    26.3  26.3     0\n# ℹ 13,995 more rows\n\n\n\nrpn_crw.main2 &lt;- \n  rpn_crw.main %&gt;%\n  mutate(date = make_date(year, month, day)) \n\n#%&gt;%\n#  filter(date &gt; 2015-01-01)\n\n\nrpn_crw.main2\n\n# A tibble: 14,005 × 8\n    year month   day sst_min sst_max   sst   dhw date      \n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;    \n 1  1985     1     1    24.1    24.2  24.1     0 1985-01-01\n 2  1985     1     2    24.2    24.3  24.2     0 1985-01-02\n 3  1985     1     3    24.3    24.3  24.3     0 1985-01-03\n 4  1985     1     4    24.4    24.4  24.4     0 1985-01-04\n 5  1985     1     5    24.5    24.6  24.5     0 1985-01-05\n 6  1985     1     6    25.2    25.3  25.3     0 1985-01-06\n 7  1985     1     7    25.0    25.2  25.2     0 1985-01-07\n 8  1985     1     8    25.7    25.9  25.9     0 1985-01-08\n 9  1985     1     9    26      26.2  26.2     0 1985-01-09\n10  1985     1    10    26.2    26.3  26.3     0 1985-01-10\n# ℹ 13,995 more rows\n\n\n\nrpn_crw.main3 &lt;- \n  rpn_crw.main2 %&gt;%\n  filter(date &gt;= '2014-01-01',\n         date &lt;= '2015-12-31') %&gt;% \n  dplyr::select(sst_max, dhw, date) %&gt;%\n  pivot_longer(!date, names_to = \"metric\", values_to = \"value\")\n\n\nrpn_crw.main3\n\n# A tibble: 1,460 × 3\n   date       metric  value\n   &lt;date&gt;     &lt;chr&gt;   &lt;dbl&gt;\n 1 2014-01-01 sst_max  24.3\n 2 2014-01-01 dhw       0  \n 3 2014-01-02 sst_max  23.9\n 4 2014-01-02 dhw       0  \n 5 2014-01-03 sst_max  23.8\n 6 2014-01-03 dhw       0  \n 7 2014-01-04 sst_max  23.7\n 8 2014-01-04 dhw       0  \n 9 2014-01-05 sst_max  23.8\n10 2014-01-05 dhw       0  \n# ℹ 1,450 more rows\n\n\n\nrpn_crw.main4 &lt;- \n  rpn_crw.main3 %&gt;%\n  pivot_wider(names_from = metric, values_from = value)\n\n\nrpn_crw.main4\n\n# A tibble: 730 × 3\n   date       sst_max   dhw\n   &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 2014-01-01    24.3     0\n 2 2014-01-02    23.9     0\n 3 2014-01-03    23.8     0\n 4 2014-01-04    23.7     0\n 5 2014-01-05    23.8     0\n 6 2014-01-06    24.0     0\n 7 2014-01-07    24.2     0\n 8 2014-01-08    24.4     0\n 9 2014-01-09    24.4     0\n10 2014-01-10    24.4     0\n# ℹ 720 more rows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create long labels to be wrapped\niris$Species = paste(iris$Species, \n                     \"random text to make the labels much much longer than the original labels\")\n\n\nrpn_crw.main.gg &lt;- ggplot(data = rpn_crw.main4, aes(x = date, y = sst_max)) +\n  geom_line(aes(color = \"SST Max (°C)\")) +\n#  ylim(0, 30) +\n#  scale_fill_discrete(name = \"Dose\", labels = c(\"A\", \"B\")) +\n  geom_line(aes(y = dhw, color = \"Degree Heating Week\")) +\n  scale_y_continuous(limits = c(0, 30), breaks = c(0, 5, 10, 15, 20, 25, 30)) +\n  #scale_x_continuous(breaks = seq(0, 336, 24)) +\n  scale_x_date(date_labels = \"%b %y\") +\n  scale_color_manual(values = c(\"red2\", \"blue\"))+\n  labs(x = NULL) +\n  theme(#strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        #strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        #panel.spacing.x = unit(1, \"cm\"),\n        #panel.spacing.y = unit(0.5, \"cm\"),\n        #panel.spacing = unit(1, \"lines\"),\n        axis.ticks.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        legend.position = 'right',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        #axis.text.x = element_text(size = 12),\n        axis.text.x = element_text(angle = 60, hjust = 0.25, size = 8),\n        axis.title.y = element_blank(),\n        legend.title = element_blank())\n\n\nrpn_crw.main.gg\n\n\n\n\n\nscale = 0.25\n\n\npkpd &lt;- ggplot(data = rpn_crw.main4, aes(x = date, y = sst_max)) +\n#  scale_y_continuous(breaks = c(5, 5), limits = c(0, 50)) +\n#  ylim(0, 40) +\n  geom_line(aes(color = \"Maximum Sea Surface Temperature\")) +\n  geom_line(aes(y = dhw * scale, color = \"Degree Heating Week\"))+\n#  scale_x_continuous(breaks = seq(0, 336, 24)) +\n  scale_y_continuous(sec.axis = sec_axis(~.*scale, name = \"DHW\")) +\n  labs(x = \"Date\", y = \"SST Max (C)\", color = \"\") +\n  scale_color_manual(values = c(\"orange2\", \"gray50\"))\n\nprint(pkpd)\n\n\n\n\n\n#-----------------------------------------------------------------------------\n# Rescale the second y axis by \n#   - subtracting its minimum value (to set it to start at 0)\n#   - scaling so that it has the same range as the 'y1' variable\n#   - offsettting it by the minimum value of y1\n#-----------------------------------------------------------------------------\na            &lt;- range(rpn_crw.main4[['sst_max']])\n\n\na\n\n[1] 19.39 26.99\n\n\n\nb            &lt;- range(rpn_crw.main4[['dhw']])\n\n\nscale_factor &lt;- diff(a)/diff(b)\n\n\nrpn_crw.main4[['sst_max']]      &lt;- ((rpn_crw.main4[['sst_max']] - b[1]) * scale_factor) + a[1]\n\n\n#-----------------------------------------------------------------------------\n# Need to define the second axis transformation to be the inverse of the data\n# transformation to everything cancels out appropriately\n#-----------------------------------------------------------------------------\ntrans &lt;- ~ ((. - a[1]) / scale_factor) + b[1]\n\n\npkpd &lt;- ggplot(data = rpn_crw.main4, aes(x = date, y = sst_max)) +\n#  scale_y_continuous(breaks = c(5, 5), limits = c(0, 50)) +\n#  ylim(0, 40) +\n  geom_line(aes(color = \"Maximum Sea Surface Temperature\")) +\n  geom_line(aes(y = dhw * scale, color = \"Degree Heating Week\"))+\n#  scale_x_continuous(breaks = seq(0, 336, 24)) +\n  scale_y_continuous(sec.axis = sec_axis(trans = trans, name = 'dhw'), \n                     breaks = c(0, 500)) +\n  labs(x = \"Date\", y = \"SST Max (C)\", color = \"\") +\n  scale_color_manual(values = c(\"orange2\", \"gray50\"))\n\nprint(pkpd)\n\n\n\n\n\nmy_data &lt;- read_tsv(\"https://coralreefwatch.noaa.gov/product/vs/data/easter_island.txt\")\n\nRows: 14229 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): Name:\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhead(my_data)\n\n# A tibble: 6 × 1\n  `Name:`                       \n  &lt;chr&gt;                         \n1 Easter Island, Chile          \n2 Polygon Middle Longitude:     \n3 -109.3250                     \n4 Polygon Middle Latitude:      \n5 -27.1750                      \n6 Averaged Maximum Monthly Mean:\n\n\n\nwrite_csv(rpn_crw, \".csv\")"
  },
  {
    "objectID": "content/customizing.html",
    "href": "content/customizing.html",
    "title": "Customization",
    "section": "",
    "text": "Quarto allow many bells and whistles to make nice output. Read the documentation here Quarto documentation."
  },
  {
    "objectID": "content/customizing.html#quarto-documentation",
    "href": "content/customizing.html#quarto-documentation",
    "title": "Customization",
    "section": "",
    "text": "Quarto allow many bells and whistles to make nice output. Read the documentation here Quarto documentation."
  },
  {
    "objectID": "content/customizing.html#examples",
    "href": "content/customizing.html#examples",
    "title": "Customization",
    "section": "Examples",
    "text": "Examples\nLooking at other people’s Quarto code is a great way to figure out how to do stuff. Most will have a link to a GitHub repo where you can see the raw code. Look for a link to edit page or see source code. This will usually be on the right. Or look for the GitHub icon somewhere.\n\nQuarto gallery\nnmfs-openscapes\nFaye lab manual\nquarto-titlepages Note the link to edit is broken. Go to repo and look in documentation directory."
  },
  {
    "objectID": "content/bleaching_results_supp_material.html",
    "href": "content/bleaching_results_supp_material.html",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "",
    "text": "rpn_plob\n\n# A tibble: 12 × 8\n   location depth transect group total_count total_points cover failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;       &lt;int&gt;        &lt;int&gt; &lt;dbl&gt;    &lt;int&gt;\n 1 north    dp    one      PLOB          104          126 0.825       22\n 2 north    dp    two      PLOB          113          126 0.897       13\n 3 north    sh    one      PLOB           83          126 0.659       43\n 4 north    sh    two      PLOB           88          126 0.698       38\n 5 se       dp    one      PLOB           34          124 0.274       90\n 6 se       dp    two      PLOB           28          105 0.267       77\n 7 se       sh    one      PLOB           35          126 0.278       91\n 8 se       sh    two      PLOB           15          126 0.119      111\n 9 west     dp    one      PLOB           89          126 0.706       37\n10 west     dp    two      PLOB           73          126 0.579       53\n11 west     sh    one      PLOB           74          126 0.587       52\n12 west     sh    two      PLOB          101          126 0.802       25"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#porites",
    "href": "content/bleaching_results_supp_material.html#porites",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Porites",
    "text": "Porites\n\nGeneralized linear model\n\nplob.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_plob)\n\n\npar(mfrow = c(2, 2))\nplot(plob.glm)\n\n\n\n\n\nsummary(plob.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_plob)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            1.8245     0.1822  10.017  &lt; 2e-16 ***\nlocationse            -2.8154     0.2352 -11.973  &lt; 2e-16 ***\nlocationwest          -1.2368     0.2246  -5.506 3.68e-08 ***\ndepthsh               -1.0773     0.2267  -4.753 2.00e-06 ***\nlocationse:depthsh     0.6719     0.3138   2.142   0.0322 *  \nlocationwest:depthsh   1.3105     0.2956   4.434 9.25e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 396.020  on 11  degrees of freedom\nResidual deviance:  31.694  on  6  degrees of freedom\nAIC: 102.95\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nAnova(plob.glm, type = 'III')\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(total_count, failures)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        186.616  2  &lt; 2.2e-16 ***\ndepth            24.219  1  8.599e-07 ***\nlocation:depth   20.391  2  3.735e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_plob$groups &lt;- interaction(rpn_plob$location, rpn_plob$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#create-a-post-hoc-model",
    "href": "content/bleaching_results_supp_material.html#create-a-post-hoc-model",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_plob &lt;- with(rpn_plob, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest",
    "href": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_plob, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (north.dp) = 0\",\n                       \"(west.sh) - (west.dp) = 0\",\n                       \"(se.sh) - (se.dp) = 0\",\n                       \"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (north.dp) == 0 -1.07733    0.22666  -4.753 1.20e-05 ***\n(west.sh) - (west.dp) == 0    0.23319    0.18970   1.229    0.657    \n(se.sh) - (se.dp) == 0       -0.40539    0.21695  -1.869    0.247    \n(north.sh) - (west.sh) == 0  -0.07377    0.19208  -0.384    0.795    \n(north.sh) - (west.dp) == 0   0.15943    0.18835   0.846    0.795    \n(north.sh) - (se.sh) == 0     2.14346    0.20771  10.319  &lt; 2e-16 ***\n(north.sh) - (se.dp) == 0     1.73807    0.20078   8.657  &lt; 2e-16 ***\n(north.dp) - (west.sh) == 0   1.00357    0.22777   4.406 5.27e-05 ***\n(north.dp) - (west.dp) == 0   1.23676    0.22464   5.506 2.58e-07 ***\n(north.dp) - (se.sh) == 0     3.22079    0.24110  13.359  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0     2.81541    0.23515  11.973  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0     -2.21723    0.20893 -10.612  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0     -1.98403    0.20551  -9.654  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0     -1.81184    0.20204  -8.968  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0     -1.57865    0.19850  -7.953 1.42e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#plob-bleaching",
    "href": "content/bleaching_results_supp_material.html#plob-bleaching",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "PLOB Bleaching",
    "text": "PLOB Bleaching\n\nrpn_plob_bleach &lt;- rpn_bleach %&gt;%  \n  filter(group == 'PLOB' & status == 'BL') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_pb &lt;- rpn_bleach %&gt;% \n  filter(group == 'PLOB' & status == 'PB') %&gt;% \n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_pb\n\n# A tibble: 9 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                5\n2 north    dp    two               49\n3 north    sh    one               40\n4 north    sh    two               31\n5 se       dp    two                2\n6 west     dp    one               70\n7 west     dp    two               55\n8 west     sh    one               64\n9 west     sh    two               46\n\n\n\nrpn_plob_pb2 &lt;-\nas.data.frame(rpn_plob_pb) %&gt;%\n  add_row(location = 'se', depth = 'dp', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'se', depth = 'sh', transect = 'one', total_count = 0) %&gt;%\n  add_row(location = 'se', depth = 'sh', transect = 'two', total_count = 0)\n\n\nrpn_plob_pb.main &lt;- rpn_plob_pb2 %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_plob_pb.main\n\n   location depth transect total_count      cover failures\n1     north    dp      one           5 0.03968254      121\n2     north    dp      two          49 0.38888889       77\n3     north    sh      one          40 0.31746032       86\n4     north    sh      two          31 0.24603175       95\n5        se    dp      two           2 0.01587302      124\n6      west    dp      one          70 0.55555556       56\n7      west    dp      two          55 0.43650794       71\n8      west    sh      one          64 0.50793651       62\n9      west    sh      two          46 0.36507937       80\n10       se    dp      two           0 0.00000000      126\n11       se    sh      one           0 0.00000000      126\n12       se    sh      two           0 0.00000000      126\n\n\n\nrpn_plob_pale &lt;- rpn_bleach %&gt;%  \n  filter(group == 'PLOB' & status == 'P') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_pale\n\n# A tibble: 12 × 4\n# Groups:   location, depth [6]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one               87\n 2 north    dp    two               52\n 3 north    sh    one               28\n 4 north    sh    two               37\n 5 se       dp    one               23\n 6 se       dp    two                2\n 7 se       sh    one               29\n 8 se       sh    two                9\n 9 west     dp    one               17\n10 west     dp    two               16\n11 west     sh    one                5\n12 west     sh    two               55\n\n\n\nrpn_plob_pale.main &lt;- rpn_plob_pale %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_plob_pale.main\n\n# A tibble: 12 × 6\n# Groups:   location, depth [6]\n   location depth transect total_count  cover failures\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 north    dp    one               87 0.690        39\n 2 north    dp    two               52 0.413        74\n 3 north    sh    one               28 0.222        98\n 4 north    sh    two               37 0.294        89\n 5 se       dp    one               23 0.183       103\n 6 se       dp    two                2 0.0159      124\n 7 se       sh    one               29 0.230        97\n 8 se       sh    two                9 0.0714      117\n 9 west     dp    one               17 0.135       109\n10 west     dp    two               16 0.127       110\n11 west     sh    one                5 0.0397      121\n12 west     sh    two               55 0.437        71\n\n\n\nrpn_plob_healthy &lt;- rpn_bleach %&gt;%  \n  filter(group == 'PLOB' & status == 'H') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_plob_healthy\n\n# A tibble: 10 × 4\n# Groups:   location, depth [6]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one               12\n 2 north    dp    two               12\n 3 north    sh    one               15\n 4 north    sh    two               20\n 5 se       dp    one               11\n 6 se       sh    one                6\n 7 se       sh    two                6\n 8 west     dp    one                2\n 9 west     dp    two                2\n10 west     sh    one                5\n\n\n\nrpn_plob_healthy2 &lt;-\nas.data.frame(rpn_plob_healthy) %&gt;%\n  add_row(location = 'se', depth = 'dp', transect = 'two', total_count = 0) %&gt;%\n  add_row(location = 'west', depth = 'sh', transect = 'two', total_count = 0)\n\n\nrpn_plob_healthy2\n\n   location depth transect total_count\n1     north    dp      one          12\n2     north    dp      two          12\n3     north    sh      one          15\n4     north    sh      two          20\n5        se    dp      one          11\n6        se    sh      one           6\n7        se    sh      two           6\n8      west    dp      one           2\n9      west    dp      two           2\n10     west    sh      one           5\n11       se    dp      two           0\n12     west    sh      two           0\n\n\n\nrpn_plob_healthy.main &lt;- rpn_plob_healthy2 %&gt;%\n  #as_tibble() %&gt;%\n  #filter(group == \"PLOB\") %&gt;%\n  #mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/126,\n  failures = 126 - total_count\n    )\n\n\nrpn_plob_healthy.main \n\n   location depth transect total_count      cover failures\n1     north    dp      one          12 0.09523810      114\n2     north    dp      two          12 0.09523810      114\n3     north    sh      one          15 0.11904762      111\n4     north    sh      two          20 0.15873016      106\n5        se    dp      one          11 0.08730159      115\n6        se    sh      one           6 0.04761905      120\n7        se    sh      two           6 0.04761905      120\n8      west    dp      one           2 0.01587302      124\n9      west    dp      two           2 0.01587302      124\n10     west    sh      one           5 0.03968254      121\n11       se    dp      two           0 0.00000000      126\n12     west    sh      two           0 0.00000000      126"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#pocillopora",
    "href": "content/bleaching_results_supp_material.html#pocillopora",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Pocillopora",
    "text": "Pocillopora\n\nrpn_bleach &lt;- read.csv('rpn_bleach_2015.csv') %&gt;%\n  as_tibble() %&gt;%\n  mutate_at(vars(location, depth, transect, group, status), factor)\n\n\nrpn_bleach\n\n# A tibble: 1,512 × 7\n   location depth transect point metric group status\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;int&gt;  &lt;int&gt; &lt;fct&gt; &lt;fct&gt; \n 1 north    sh    one          1      0 PLOB  PB    \n 2 north    sh    one          2     20 PLOB  PB    \n 3 north    sh    one          3     40 PLOB  PB    \n 4 north    sh    one          4     60 MA    HAL   \n 5 north    sh    one          5     80 TURF  na    \n 6 north    sh    one          6    100 TURF  na    \n 7 north    sh    one          7    120 TURF  na    \n 8 north    sh    one          8    140 PLOB  PB    \n 9 north    sh    one          9    160 PLOB  PB    \n10 north    sh    one         10    180 PLOB  PB    \n# ℹ 1,502 more rows\n\n\n\nrpn_summary &lt;- rpn_bleach %&gt;%  \n  group_by(location, depth, transect, group) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth', 'transect'. You can\noverride using the `.groups` argument.\n\n\n\nrpn_POCI &lt;- rpn_bleach %&gt;%  \n  filter(group == \"POCI\") %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_POCI\n\n# A tibble: 11 × 4\n# Groups:   location, depth [6]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one                7\n 2 north    dp    two                2\n 3 north    sh    two                1\n 4 se       dp    one               57\n 5 se       dp    two               58\n 6 se       sh    one               75\n 7 se       sh    two               60\n 8 west     dp    one               13\n 9 west     dp    two               14\n10 west     sh    one               15\n11 west     sh    two               18\n\n\n\nrpn_poci &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"POCI\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nrpn_plob\n\n# A tibble: 12 × 9\n   location depth transect group total_count total_points cover failures groups \n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;       &lt;int&gt;        &lt;int&gt; &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;  \n 1 north    dp    one      PLOB          104          126 0.825       22 north.…\n 2 north    dp    two      PLOB          113          126 0.897       13 north.…\n 3 north    sh    one      PLOB           83          126 0.659       43 north.…\n 4 north    sh    two      PLOB           88          126 0.698       38 north.…\n 5 se       dp    one      PLOB           34          124 0.274       90 se.dp  \n 6 se       dp    two      PLOB           28          105 0.267       77 se.dp  \n 7 se       sh    one      PLOB           35          126 0.278       91 se.sh  \n 8 se       sh    two      PLOB           15          126 0.119      111 se.sh  \n 9 west     dp    one      PLOB           89          126 0.706       37 west.dp\n10 west     dp    two      PLOB           73          126 0.579       53 west.dp\n11 west     sh    one      PLOB           74          126 0.587       52 west.sh\n12 west     sh    two      PLOB          101          126 0.802       25 west.sh"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#pocillopora-1",
    "href": "content/bleaching_results_supp_material.html#pocillopora-1",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Pocillopora",
    "text": "Pocillopora\n\nGeneralized linear model\n\npoci.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_poci)\n\n\npar(mfrow = c(2, 2))\nplot(poci.glm)\n\n\n\n\n\nsummary(poci.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_poci)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -3.2958     0.3395  -9.709  &lt; 2e-16 ***\nlocationse             3.3046     0.3643   9.072  &lt; 2e-16 ***\nlocationwest           1.1756     0.3959   2.970  0.00298 ** \ndepthsh               -2.2296     1.0579  -2.108  0.03507 *  \nlocationse:depthsh     2.3640     1.0736   2.202  0.02767 *  \nlocationwest:depthsh   2.4573     1.0934   2.247  0.02462 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 436.578  on 11  degrees of freedom\nResidual deviance:  10.347  on  6  degrees of freedom\nAIC: 69.293\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nAnova(poci.glm, type = 'III')\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(total_count, failures)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        178.902  2  &lt; 2.2e-16 ***\ndepth             7.491  1   0.006201 ** \nlocation:depth    8.513  2   0.014171 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_poci$groups &lt;- interaction(rpn_poci$location, rpn_poci$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-1",
    "href": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-1",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_poci &lt;- with(rpn_poci, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-1",
    "href": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-1",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_poci, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (north.dp) = 0\",\n                       \"(west.sh) - (west.dp) = 0\",\n                       \"(se.sh) - (se.dp) = 0\",\n                       \"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (north.dp) == 0  -2.2296     1.0579  -2.108  0.10521    \n(west.sh) - (west.dp) == 0     0.2277     0.2763   0.824  0.81982    \n(se.sh) - (se.dp) == 0         0.1344     0.1828   0.735  0.81982    \n(north.sh) - (west.sh) == 0   -3.6329     1.0192  -3.564  0.00219 ** \n(north.sh) - (west.dp) == 0   -3.4052     1.0225  -3.330  0.00434 ** \n(north.sh) - (se.sh) == 0     -5.6686     1.0099  -5.613 1.79e-07 ***\n(north.sh) - (se.dp) == 0     -5.5342     1.0107  -5.476 3.48e-07 ***\n(north.dp) - (west.sh) == 0   -1.4033     0.3874  -3.622  0.00205 ** \n(north.dp) - (west.dp) == 0   -1.1756     0.3959  -2.970  0.01193 *  \n(north.dp) - (se.sh) == 0     -3.4389     0.3622  -9.495  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0     -3.3046     0.3643  -9.072  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0       2.0357     0.2254   9.030  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0       2.2634     0.2397   9.444  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0       1.9013     0.2288   8.311  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0       2.1290     0.2428   8.769  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_poci2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"POCI\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_poci2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth    mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288 \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544\n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29  \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158 \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282 \n\n\n\nrpn_poci3 &lt;-\n  as_tibble(rpn_poci2)\n\n\nrpn_poci_summ &lt;-\n    rpn_poci3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_poci_summ\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_poci_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-2",
    "href": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-2",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_poci &lt;- with(rpn_poci, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-2",
    "href": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-2",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_poci, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  -3.6329     1.0192  -3.564  0.00117 ** \n(north.sh) - (west.dp) == 0  -3.4052     1.0225  -3.330  0.00173 ** \n(north.sh) - (se.sh) == 0    -5.6686     1.0099  -5.613 1.19e-07 ***\n(north.sh) - (se.dp) == 0    -5.5342     1.0107  -5.476 2.18e-07 ***\n(north.dp) - (west.sh) == 0  -1.4033     0.3874  -3.622  0.00117 ** \n(north.dp) - (west.dp) == 0  -1.1756     0.3959  -2.970  0.00298 ** \n(north.dp) - (se.sh) == 0    -3.4389     0.3622  -9.495  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0    -3.3046     0.3643  -9.072  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0      2.0357     0.2254   9.030  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0      2.2634     0.2397   9.444  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0      1.9013     0.2288   8.311  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0      2.1290     0.2428   8.769  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_poci_bleach &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'BL') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_bleach\n\n# A tibble: 6 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                1\n2 se       dp    one                1\n3 se       dp    two                2\n4 se       sh    two                1\n5 west     dp    one                4\n6 west     sh    two                2\n\n\n\nrpn_poci_pb &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'PB') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_pb\n\n# A tibble: 8 × 4\n# Groups:   location, depth [5]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                2\n2 north    dp    two                1\n3 se       dp    one               27\n4 se       dp    two                9\n5 se       sh    one                2\n6 se       sh    two                5\n7 west     dp    two                2\n8 west     sh    one                1\n\n\n\nrpn_poci_pale &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'P') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_pale\n\n# A tibble: 10 × 4\n# Groups:   location, depth [5]\n   location depth transect total_count\n   &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n 1 north    dp    one                3\n 2 north    dp    two                1\n 3 se       dp    one               19\n 4 se       dp    two               16\n 5 se       sh    one               59\n 6 se       sh    two               45\n 7 west     dp    one                7\n 8 west     dp    two                8\n 9 west     sh    one               13\n10 west     sh    two                9\n\n\n\nrpn_poci_healthy &lt;- rpn_bleach %&gt;%  \n  filter(group == 'POCI' & status == 'H') %&gt;%\n  group_by(location, depth, transect) %&gt;%\n  dplyr::summarise(total_count = n())\n\n`summarise()` has grouped output by 'location', 'depth'. You can override using\nthe `.groups` argument.\n\n\n\nrpn_poci_healthy\n\n# A tibble: 9 × 4\n# Groups:   location, depth [6]\n  location depth transect total_count\n  &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;          &lt;int&gt;\n1 north    dp    one                1\n2 north    sh    two                1\n3 se       dp    one               10\n4 se       sh    one               14\n5 se       sh    two                9\n6 west     dp    one                2\n7 west     dp    two                4\n8 west     sh    one                1\n9 west     sh    two                7"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#examine-bleaching-response-of-coral-groups",
    "href": "content/bleaching_results_supp_material.html#examine-bleaching-response-of-coral-groups",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Examine bleaching response of coral groups",
    "text": "Examine bleaching response of coral groups\n\nrpn_plob_pb.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                family = binomial(link = \"logit\"), \n                data = rpn_plob_pb.main)\n\n\npar(mfrow = c(2, 2))\nplot(rpn_plob_pb.glm)\n\n\n\n\n\nsummary(rpn_plob_pb.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_plob_pb.main)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -1.2993     0.1535  -8.463  &lt; 2e-16 ***\nlocationse             -3.5290     0.7263  -4.859 1.18e-06 ***\nlocationwest            1.2834     0.1986   6.462 1.03e-10 ***\ndepthsh                 0.3635     0.2078   1.749   0.0803 .  \nlocationse:depthsh    -17.0748  1817.2897  -0.009   0.9925    \nlocationwest:depthsh   -0.6029     0.2742  -2.199   0.0279 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 449.568  on 11  degrees of freedom\nResidual deviance:  64.609  on  6  degrees of freedom\nAIC: 119.1\n\nNumber of Fisher Scoring iterations: 16\n\n\nAnova function from the car package\n\nAnova(rpn_plob_pb.glm, type = \"III\") # Type III because...\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(total_count, failures)\n               LR Chisq Df Pr(&gt;Chisq)    \nlocation        197.689  2    &lt; 2e-16 ***\ndepth             3.082  1    0.07916 .  \nlocation:depth    7.657  2    0.02174 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nrpn_plob_pb.main\n\n   location depth transect total_count      cover failures\n1     north    dp      one           5 0.03968254      121\n2     north    dp      two          49 0.38888889       77\n3     north    sh      one          40 0.31746032       86\n4     north    sh      two          31 0.24603175       95\n5        se    dp      two           2 0.01587302      124\n6      west    dp      one          70 0.55555556       56\n7      west    dp      two          55 0.43650794       71\n8      west    sh      one          64 0.50793651       62\n9      west    sh      two          46 0.36507937       80\n10       se    dp      two           0 0.00000000      126\n11       se    sh      one           0 0.00000000      126\n12       se    sh      two           0 0.00000000      126\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_plob_pb.main$groups &lt;- interaction(rpn_plob_pb.main$location, rpn_plob_pb.main$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-3",
    "href": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-3",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nrpn_plob_pb.lm &lt;- with(rpn_plob_pb.main, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-3",
    "href": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-3",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(rpn_plob_pb.lm, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0   -0.6805     0.1891  -3.599   0.0016 ** \n(north.sh) - (west.dp) == 0   -0.9199     0.1884  -4.884 7.29e-06 ***\n(north.sh) - (se.sh) == 0     20.6038  1817.2895   0.011   1.0000    \n(north.sh) - (se.dp) == 0      3.8925     0.7236   5.379 6.73e-07 ***\n(north.dp) - (west.sh) == 0   -1.0439     0.1993  -5.239 1.29e-06 ***\n(north.dp) - (west.dp) == 0   -1.2834     0.1986  -6.462 1.14e-09 ***\n(north.dp) - (se.sh) == 0     20.2403  1817.2895   0.011   1.0000    \n(north.dp) - (se.dp) == 0      3.5290     0.7263   4.859 7.29e-06 ***\n(se.sh) - (west.sh) == 0     -21.2843  1817.2895  -0.012   1.0000    \n(se.sh) - (west.dp) == 0     -21.5238  1817.2895  -0.012   1.0000    \n(se.dp) - (west.sh) == 0      -4.5730     0.7212  -6.341 2.29e-09 ***\n(se.dp) - (west.dp) == 0      -4.8124     0.7210  -6.674 2.98e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#pocillopora-2",
    "href": "content/bleaching_results_supp_material.html#pocillopora-2",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Pocillopora",
    "text": "Pocillopora\n\nGeneralized linear model\n\npoci.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_poci)\n\n\npar(mfrow = c(2, 2))\nplot(poci.glm)\n\n\n\n\n\nsummary(poci.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_poci)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -3.2958     0.3395  -9.709  &lt; 2e-16 ***\nlocationse             3.3046     0.3643   9.072  &lt; 2e-16 ***\nlocationwest           1.1756     0.3959   2.970  0.00298 ** \ndepthsh               -2.2296     1.0579  -2.108  0.03507 *  \nlocationse:depthsh     2.3640     1.0736   2.202  0.02767 *  \nlocationwest:depthsh   2.4573     1.0934   2.247  0.02462 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 436.578  on 11  degrees of freedom\nResidual deviance:  10.347  on  6  degrees of freedom\nAIC: 69.293\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_poci$groups &lt;- interaction(rpn_poci$location, rpn_poci$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-4",
    "href": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-4",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_poci &lt;- with(rpn_poci, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-4",
    "href": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-4",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_poci, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  -3.6329     1.0192  -3.564  0.00117 ** \n(north.sh) - (west.dp) == 0  -3.4052     1.0225  -3.330  0.00173 ** \n(north.sh) - (se.sh) == 0    -5.6686     1.0099  -5.613 1.19e-07 ***\n(north.sh) - (se.dp) == 0    -5.5342     1.0107  -5.476 2.18e-07 ***\n(north.dp) - (west.sh) == 0  -1.4033     0.3874  -3.622  0.00117 ** \n(north.dp) - (west.dp) == 0  -1.1756     0.3959  -2.970  0.00298 ** \n(north.dp) - (se.sh) == 0    -3.4389     0.3622  -9.495  &lt; 2e-16 ***\n(north.dp) - (se.dp) == 0    -3.3046     0.3643  -9.072  &lt; 2e-16 ***\n(se.sh) - (west.sh) == 0      2.0357     0.2254   9.030  &lt; 2e-16 ***\n(se.sh) - (west.dp) == 0      2.2634     0.2397   9.444  &lt; 2e-16 ***\n(se.dp) - (west.sh) == 0      1.9013     0.2288   8.311  &lt; 2e-16 ***\n(se.dp) - (west.dp) == 0      2.1290     0.2428   8.769  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_poci2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"POCI\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_poci2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth    mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288 \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544\n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29  \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158 \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282 \n\n\n\nrpn_poci3 &lt;-\n  as_tibble(rpn_poci2)\n\n\nrpn_poci_summ &lt;-\n    rpn_poci3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_poci_summ\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg &lt;- rpn_poci_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_poci_summ.gg\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0357  0.0281      2 0.0198   -0.216    0.288  North    15 m  \n2 north    sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 North    8 m   \n3 se       dp    0.506   0.0656      2 0.0464   -0.0829   1.09   Southea… 15 m  \n4 se       sh    0.536   0.0842      2 0.0595   -0.221    1.29   Southea… 8 m   \n5 west     dp    0.107   0.00561     2 0.00397   0.0567   0.158  West     15 m  \n6 west     sh    0.131   0.0168      2 0.0119   -0.0203   0.282  West     8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_poci_2015.ggbarplot &lt;- ggplot(rpn_poci_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" Pocillopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_poci_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#macroalgae",
    "href": "content/bleaching_results_supp_material.html#macroalgae",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Macroalgae",
    "text": "Macroalgae\n\nGeneralized linear model\n\nrpn_ma &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"MA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nma.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_ma)\n\n\npar(mfrow = c(2, 2))\nplot(ma.glm)\n\n\n\n\n\nsummary(ma.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_ma)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -2.9957     0.2958 -10.127   &lt;2e-16 ***\nlocationse            -19.4459  2992.7957  -0.006    0.995    \nlocationwest           -0.1906     0.4378  -0.435    0.663    \ndepthsh                -0.3001     0.4503  -0.667    0.505    \nlocationse:depthsh     17.2163  2992.7959   0.006    0.995    \nlocationwest:depthsh   -0.2271     0.6911  -0.329    0.742    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 45.822  on 11  degrees of freedom\nResidual deviance: 20.051  on  6  degrees of freedom\nAIC: 57.317\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_ma$groups &lt;- interaction(rpn_ma$location, rpn_ma$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-5",
    "href": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-5",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_ma &lt;- with(rpn_ma, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-5",
    "href": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-5",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_ma, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)\n(north.sh) - (west.sh) == 0    0.4177     0.5348   0.781    1.000\n(north.sh) - (west.dp) == 0   -0.1095     0.4684  -0.234    1.000\n(north.sh) - (se.sh) == 0      2.2296     1.0579   2.108    0.351\n(north.sh) - (se.dp) == 0     19.1458  2992.7957   0.006    1.000\n(north.dp) - (west.sh) == 0    0.7178     0.5082   1.413    1.000\n(north.dp) - (west.dp) == 0    0.1906     0.4378   0.435    1.000\n(north.dp) - (se.sh) == 0      2.5297     1.0447   2.421    0.186\n(north.dp) - (se.dp) == 0     19.4459  2992.7957   0.006    1.000\n(se.sh) - (west.sh) == 0      -1.8119     1.0838  -1.672    0.851\n(se.sh) - (west.dp) == 0      -2.3391     1.0527  -2.222    0.289\n(se.dp) - (west.sh) == 0     -18.7281  2992.7957  -0.006    1.000\n(se.dp) - (west.dp) == 0     -19.2553  2992.7957  -0.006    1.000\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_ma2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"MA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_ma2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth    mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0476  0.0112      2 0.00794  -0.0532   0.148 \n2 north    sh    0.0357  0.0168      2 0.0119   -0.116    0.187 \n3 se       dp    0       0           2 0         0        0     \n4 se       sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544\n5 west     dp    0.0397  0.0561      2 0.0397   -0.465    0.544 \n6 west     sh    0.0238  0.0224      2 0.0159   -0.178    0.225 \n\n\n\nrpn_ma3 &lt;-\n  as_tibble(rpn_ma2)\n\n\nrpn_ma_summ &lt;-\n    rpn_ma3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_ma_summ\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0476  0.0112      2 0.00794  -0.0532   0.148  North    15 m  \n2 north    sh    0.0357  0.0168      2 0.0119   -0.116    0.187  North    8 m   \n3 se       dp    0       0           2 0         0        0      Southea… 15 m  \n4 se       sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 Southea… 8 m   \n5 west     dp    0.0397  0.0561      2 0.0397   -0.465    0.544  West     15 m  \n6 west     sh    0.0238  0.0224      2 0.0159   -0.178    0.225  West     8 m   \n\n\n\nrpn_ma_summ.gg &lt;- rpn_ma_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_ma_summ.gg &lt;- rpn_ma_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_ma_summ.gg\n\n# A tibble: 6 × 10\n  location depth    mean      sd     n      se lower.ci upper.ci coast    depth2\n  &lt;fct&gt;    &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt; \n1 north    dp    0.0476  0.0112      2 0.00794  -0.0532   0.148  North    15 m  \n2 north    sh    0.0357  0.0168      2 0.0119   -0.116    0.187  North    8 m   \n3 se       dp    0       0           2 0         0        0      Southea… 15 m  \n4 se       sh    0.00397 0.00561     2 0.00397  -0.0465   0.0544 Southea… 8 m   \n5 west     dp    0.0397  0.0561      2 0.0397   -0.465    0.544  West     15 m  \n6 west     sh    0.0238  0.0224      2 0.0159   -0.178    0.225  West     8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_ma_2015.ggbarplot &lt;- ggplot(rpn_ma_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_ma_2015.ggbarplot &lt;- ggplot(rpn_ma_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Macrolagae \")))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_ma_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#turf",
    "href": "content/bleaching_results_supp_material.html#turf",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Turf",
    "text": "Turf\n\nGeneralized linear model\n\nrpn_turf &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"TURF\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) \n\n\nturf.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_turf)\n\n\npar(mfrow = c(2, 2))\nplot(turf.glm)\n\n\n\n\n\nsummary(turf.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_turf)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -4.4188     0.5808  -7.608 2.78e-14 ***\nlocationse            -18.0228  2992.7958  -0.006    0.995    \nlocationwest            0.8635     0.6959   1.241    0.215    \ndepthsh                 0.7053     0.7128   0.989    0.322    \nlocationse:depthsh     17.3175  2992.7958   0.006    0.995    \nlocationwest:depthsh   -0.2368     0.8661  -0.273    0.785    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 34.021  on 11  degrees of freedom\nResidual deviance: 16.535  on  6  degrees of freedom\nAIC: 52.682\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_turf$groups &lt;- interaction(rpn_turf$location, rpn_turf$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-6",
    "href": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-6",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_turf &lt;- with(rpn_turf, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-6",
    "href": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-6",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_turf, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                              Estimate Std. Error z value Pr(&gt;|z|)\n(north.sh) - (west.sh) == 0 -6.267e-01  5.155e-01  -1.216    1.000\n(north.sh) - (west.dp) == 0 -1.582e-01  5.636e-01  -0.281    1.000\n(north.sh) - (se.sh) == 0    7.053e-01  7.128e-01   0.989    1.000\n(north.sh) - (se.dp) == 0    1.873e+01  2.993e+03   0.006    1.000\n(north.dp) - (west.sh) == 0 -1.332e+00  6.576e-01  -2.026    0.514\n(north.dp) - (west.dp) == 0 -8.635e-01  6.959e-01  -1.241    1.000\n(north.dp) - (se.sh) == 0    1.567e-15  8.214e-01   0.000    1.000\n(north.dp) - (se.dp) == 0    1.802e+01  2.993e+03   0.006    1.000\n(se.sh) - (west.sh) == 0    -1.332e+00  6.576e-01  -2.026    0.514\n(se.sh) - (west.dp) == 0    -8.635e-01  6.959e-01  -1.241    1.000\n(se.dp) - (west.sh) == 0    -1.935e+01  2.993e+03  -0.006    1.000\n(se.dp) - (west.dp) == 0    -1.889e+01  2.993e+03  -0.006    1.000\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_turf2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"TURF\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_turf2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0119 0.0168      2 0.0119   -0.139    0.163 \n2 north    sh    0.0238 0.0224      2 0.0159   -0.178    0.225 \n3 se       dp    0      0           2 0         0        0     \n4 se       sh    0.0119 0.0168      2 0.0119   -0.139    0.163 \n5 west     dp    0.0278 0.00561     2 0.00397  -0.0226   0.0782\n6 west     sh    0.0437 0.0393      2 0.0278   -0.309    0.397 \n\n\n\nrpn_turf3 &lt;-\n  as_tibble(rpn_turf2)\n\n\nrpn_turf_summ &lt;-\n    rpn_turf3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_turf_summ\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0119 0.0168      2 0.0119   -0.139    0.163  North     15 m  \n2 north    sh    0.0238 0.0224      2 0.0159   -0.178    0.225  North     8 m   \n3 se       dp    0      0           2 0         0        0      Southeast 15 m  \n4 se       sh    0.0119 0.0168      2 0.0119   -0.139    0.163  Southeast 8 m   \n5 west     dp    0.0278 0.00561     2 0.00397  -0.0226   0.0782 West      15 m  \n6 west     sh    0.0437 0.0393      2 0.0278   -0.309    0.397  West      8 m   \n\n\n\nrpn_turf_summ.gg &lt;- rpn_turf_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_turf_summ.gg &lt;- rpn_turf_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_turf_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0119 0.0168      2 0.0119   -0.139    0.163  North     15 m  \n2 north    sh    0.0238 0.0224      2 0.0159   -0.178    0.225  North     8 m   \n3 se       dp    0      0           2 0         0        0      Southeast 15 m  \n4 se       sh    0.0119 0.0168      2 0.0119   -0.139    0.163  Southeast 8 m   \n5 west     dp    0.0278 0.00561     2 0.00397  -0.0226   0.0782 West      15 m  \n6 west     sh    0.0437 0.0393      2 0.0278   -0.309    0.397  West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_turf_2015.ggbarplot &lt;- ggplot(rpn_turf_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_turf_2015.ggbarplot &lt;- ggplot(rpn_turf_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" turfllopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_turf_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#sand",
    "href": "content/bleaching_results_supp_material.html#sand",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Sand",
    "text": "Sand\n\nGeneralized linear model\n\nrpn_sand &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"SAND\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nsand.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_sand)\n\n\npar(mfrow = c(2, 2))\nplot(sand.glm)\n\n\n\n\n\nsummary(sand.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_sand)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -3.0869     0.3083 -10.012  &lt; 2e-16 ***\nlocationse            -19.3547  2992.7957  -0.006    0.995    \nlocationwest            1.4486     0.3524   4.111 3.95e-05 ***\ndepthsh                 1.6140     0.3482   4.636 3.55e-06 ***\nlocationse:depthsh     -1.7120  4234.8629   0.000    1.000    \nlocationwest:depthsh   -2.5407     0.4584  -5.542 2.99e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 161.962  on 11  degrees of freedom\nResidual deviance:  28.599  on  6  degrees of freedom\nAIC: 72.931\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_sand$groups &lt;- interaction(rpn_sand$location, rpn_sand$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-7",
    "href": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-7",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_sand &lt;- with(rpn_sand, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-7",
    "href": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-7",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_sand, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0    1.0921     0.2932   3.724 0.002154 ** \n(north.sh) - (west.dp) == 0    0.1654     0.2351   0.704 1.000000    \n(north.sh) - (se.sh) == 0     21.0668  2996.2039   0.007 1.000000    \n(north.sh) - (se.dp) == 0     20.9688  2992.7957   0.007 1.000000    \n(north.dp) - (west.sh) == 0   -0.5220     0.3936  -1.326 1.000000    \n(north.dp) - (west.dp) == 0   -1.4486     0.3524  -4.111 0.000473 ***\n(north.dp) - (se.sh) == 0     19.4527  2996.2039   0.006 1.000000    \n(north.dp) - (se.dp) == 0     19.3547  2992.7957   0.006 1.000000    \n(se.sh) - (west.sh) == 0     -19.9747  2996.2039  -0.007 1.000000    \n(se.sh) - (west.dp) == 0     -20.9013  2996.2039  -0.007 1.000000    \n(se.dp) - (west.sh) == 0     -19.8767  2992.7957  -0.007 1.000000    \n(se.dp) - (west.dp) == 0     -20.8034  2992.7957  -0.007 1.000000    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_sand2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"SAND\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_sand2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0.0437 0.0505      2 0.0357    -0.410    0.497\n2 north    sh    0.187  0.00561     2 0.00397    0.136    0.237\n3 se       dp    0      0           2 0          0        0    \n4 se       sh    0      0           2 0          0        0    \n5 west     dp    0.163  0.118       2 0.0833    -0.896    1.22 \n6 west     sh    0.0714 0.0561      2 0.0397    -0.433    0.576\n\n\n\nrpn_sand3 &lt;-\n  as_tibble(rpn_sand2)\n\n\nrpn_sand_summ &lt;-\n    rpn_sand3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_sand_summ\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0437 0.0505      2 0.0357    -0.410    0.497 North     15 m  \n2 north    sh    0.187  0.00561     2 0.00397    0.136    0.237 North     8 m   \n3 se       dp    0      0           2 0          0        0     Southeast 15 m  \n4 se       sh    0      0           2 0          0        0     Southeast 8 m   \n5 west     dp    0.163  0.118       2 0.0833    -0.896    1.22  West      15 m  \n6 west     sh    0.0714 0.0561      2 0.0397    -0.433    0.576 West      8 m   \n\n\n\nrpn_sand_summ.gg &lt;- rpn_sand_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_sand_summ.gg &lt;- rpn_sand_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_sand_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0.0437 0.0505      2 0.0357    -0.410    0.497 North     15 m  \n2 north    sh    0.187  0.00561     2 0.00397    0.136    0.237 North     8 m   \n3 se       dp    0      0           2 0          0        0     Southeast 15 m  \n4 se       sh    0      0           2 0          0        0     Southeast 8 m   \n5 west     dp    0.163  0.118       2 0.0833    -0.896    1.22  West      15 m  \n6 west     sh    0.0714 0.0561      2 0.0397    -0.433    0.576 West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_sand_2015.ggbarplot &lt;- ggplot(rpn_sand_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_sand_2015.ggbarplot &lt;- ggplot(rpn_sand_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Sand \")))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_sand_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#bare-substrate",
    "href": "content/bleaching_results_supp_material.html#bare-substrate",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Bare substrate",
    "text": "Bare substrate\n\nGeneralized linear model\n\nrpn_bare &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"BARE\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\nbare.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_bare)\n\n\npar(mfrow = c(2, 2))\nplot(bare.glm)\n\n\n\n\n\nsummary(bare.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_bare)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)            -22.54    2996.20  -0.008    0.994\nlocationse              21.16    2996.20   0.007    0.994\nlocationwest            18.64    2996.20   0.006    0.995\ndepthsh                 19.97    2996.20   0.007    0.995\nlocationse:depthsh     -19.89    2996.20  -0.007    0.995\nlocationwest:depthsh   -38.61    4237.27  -0.009    0.993\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 221.002  on 11  degrees of freedom\nResidual deviance:  42.405  on  6  degrees of freedom\nAIC: 86.079\n\nNumber of Fisher Scoring iterations: 17\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_bare$groups &lt;- interaction(rpn_bare$location, rpn_bare$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-8",
    "href": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-8",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_bare &lt;- with(rpn_bare, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-8",
    "href": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-8",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_bare, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(north.sh) - (west.sh) == 0  1.997e+01  2.996e+03   0.007 1.000000    \n(north.sh) - (west.dp) == 0  1.335e+00  5.137e-01   2.599 0.074830 .  \n(north.sh) - (se.sh) == 0   -1.266e+00  2.888e-01  -4.383 0.000117 ***\n(north.sh) - (se.dp) == 0   -1.184e+00  2.950e-01  -4.014 0.000538 ***\n(north.dp) - (west.sh) == 0 -6.022e-11  4.237e+03   0.000 1.000000    \n(north.dp) - (west.dp) == 0 -1.864e+01  2.996e+03  -0.006 1.000000    \n(north.dp) - (se.sh) == 0   -2.124e+01  2.996e+03  -0.007 1.000000    \n(north.dp) - (se.dp) == 0   -2.116e+01  2.996e+03  -0.007 1.000000    \n(se.sh) - (west.sh) == 0     2.124e+01  2.996e+03   0.007 1.000000    \n(se.sh) - (west.dp) == 0     2.601e+00  4.771e-01   5.451 6.01e-07 ***\n(se.dp) - (west.sh) == 0     2.116e+01  2.996e+03   0.007 1.000000    \n(se.dp) - (west.dp) == 0     2.519e+00  4.809e-01   5.238 1.78e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_bare2 &lt;- read.csv('rpn_cover.csv')\n\n\nrpn_bare2\n\n   location depth transect  group total_count total_points\n1     north    dp      one   BARE           0          126\n2     north    dp      one    CCA           0          126\n3     north    dp      one     MA           5          126\n4     north    dp      one   PLOB         104          126\n5     north    dp      one   POCI           7          126\n6     north    dp      one   SAND          10          126\n7     north    dp      one SPONGE           0          126\n8     north    dp      one   TURF           0          126\n9     north    dp      two   BARE           0          126\n10    north    dp      two    CCA           0          126\n11    north    dp      two     MA           7          126\n12    north    dp      two   PLOB         113          126\n13    north    dp      two   POCI           2          126\n14    north    dp      two   SAND           1          126\n15    north    dp      two SPONGE           0          126\n16    north    dp      two   TURF           3          126\n17    north    sh      one   BARE           8          126\n18    north    sh      one    CCA           0          126\n19    north    sh      one     MA           6          126\n20    north    sh      one   PLOB          83          126\n21    north    sh      one   POCI           0          126\n22    north    sh      one   SAND          24          126\n23    north    sh      one SPONGE           0          126\n24    north    sh      one   TURF           5          126\n25    north    sh      two   BARE          10          126\n26    north    sh      two    CCA           0          126\n27    north    sh      two     MA           3          126\n28    north    sh      two   PLOB          88          126\n29    north    sh      two   POCI           1          126\n30    north    sh      two   SAND          23          126\n31    north    sh      two SPONGE           0          126\n32    north    sh      two   TURF           1          126\n33       se    dp      one   BARE          33          124\n34       se    dp      one    CCA           0          124\n35       se    dp      one     MA           0          124\n36       se    dp      one   PLOB          34          124\n37       se    dp      one   POCI          57          124\n38       se    dp      one   SAND           0          124\n39       se    dp      one SPONGE           0          124\n40       se    dp      one   TURF           0          124\n41       se    dp      two   BARE          13          105\n42       se    dp      two    CCA           6          105\n43       se    dp      two     MA           0          105\n44       se    dp      two   PLOB          28          105\n45       se    dp      two   POCI          58          105\n46       se    dp      two   SAND           0          105\n47       se    dp      two SPONGE           0          105\n48       se    dp      two   TURF           0          105\n49       se    sh      one   BARE           9          126\n50       se    sh      one    CCA           4          126\n51       se    sh      one     MA           0          126\n52       se    sh      one   PLOB          35          126\n53       se    sh      one   POCI          75          126\n54       se    sh      one   SAND           0          126\n55       se    sh      one SPONGE           0          126\n56       se    sh      one   TURF           3          126\n57       se    sh      two   BARE          45          126\n58       se    sh      two    CCA           5          126\n59       se    sh      two     MA           1          126\n60       se    sh      two   PLOB          15          126\n61       se    sh      two   POCI          60          126\n62       se    sh      two   SAND           0          126\n63       se    sh      two SPONGE           0          126\n64       se    sh      two   TURF           0          126\n65     west    dp      one   BARE           1          126\n66     west    dp      one    CCA           0          126\n67     west    dp      one     MA          10          126\n68     west    dp      one   PLOB          89          126\n69     west    dp      one   POCI          13          126\n70     west    dp      one   SAND          10          126\n71     west    dp      one SPONGE           0          126\n72     west    dp      one   TURF           3          126\n73     west    dp      two   BARE           4          126\n74     west    dp      two    CCA           0          126\n75     west    dp      two     MA           0          126\n76     west    dp      two   PLOB          73          126\n77     west    dp      two   POCI          14          126\n78     west    dp      two   SAND          31          126\n79     west    dp      two SPONGE           0          126\n80     west    dp      two   TURF           4          126\n81     west    sh      one   BARE           0          126\n82     west    sh      one    CCA           0          126\n83     west    sh      one     MA           5          126\n84     west    sh      one   PLOB          74          126\n85     west    sh      one   POCI          15          126\n86     west    sh      one   SAND          14          126\n87     west    sh      one SPONGE           9          126\n88     west    sh      one   TURF           9          126\n89     west    sh      two   BARE           0          126\n90     west    sh      two    CCA           0          126\n91     west    sh      two     MA           1          126\n92     west    sh      two   PLOB         101          126\n93     west    sh      two   POCI          18          126\n94     west    sh      two   SAND           4          126\n95     west    sh      two SPONGE           0          126\n96     west    sh      two   TURF           2          126\n\n\n\nrpn_bare2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"BARE\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_bare2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean     sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0      0          2 0         0         0    \n2 north    sh    0.0714 0.0112     2 0.00794  -0.0294    0.172\n3 se       dp    0.195  0.101      2 0.0712   -0.709     1.10 \n4 se       sh    0.214  0.202      2 0.143    -1.60      2.03 \n5 west     dp    0.0198 0.0168     2 0.0119   -0.131     0.171\n6 west     sh    0      0          2 0         0         0    \n\n\n\nrpn_bare3 &lt;-\n  as_tibble(rpn_bare2)\n\n\nrpn_bare_summ &lt;-\n    rpn_bare3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_bare_summ\n\n# A tibble: 6 × 10\n  location depth   mean     sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0          2 0         0         0     North     15 m  \n2 north    sh    0.0714 0.0112     2 0.00794  -0.0294    0.172 North     8 m   \n3 se       dp    0.195  0.101      2 0.0712   -0.709     1.10  Southeast 15 m  \n4 se       sh    0.214  0.202      2 0.143    -1.60      2.03  Southeast 8 m   \n5 west     dp    0.0198 0.0168     2 0.0119   -0.131     0.171 West      15 m  \n6 west     sh    0      0          2 0         0         0     West      8 m   \n\n\n\nrpn_bare_summ.gg &lt;- rpn_bare_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_bare_summ.gg &lt;- rpn_bare_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_bare_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean     sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0          2 0         0         0     North     15 m  \n2 north    sh    0.0714 0.0112     2 0.00794  -0.0294    0.172 North     8 m   \n3 se       dp    0.195  0.101      2 0.0712   -0.709     1.10  Southeast 15 m  \n4 se       sh    0.214  0.202      2 0.143    -1.60      2.03  Southeast 8 m   \n5 west     dp    0.0198 0.0168     2 0.0119   -0.131     0.171 West      15 m  \n6 west     sh    0      0          2 0         0         0     West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_bare_2015.ggbarplot &lt;- ggplot(rpn_bare_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_bare_2015.ggbarplot &lt;- ggplot(rpn_bare_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  ggtitle(expression(paste(italic(\" Bare \")))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_bare_2015.ggbarplot"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#cca-substrate",
    "href": "content/bleaching_results_supp_material.html#cca-substrate",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "cca substrate",
    "text": "cca substrate\n\nGeneralized linear model\n\nrpn_cca &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"CCA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    )\n\n\ncca.glm &lt;- glm(cbind(total_count, failures) ~ location * depth, \n                    family = binomial(link = \"logit\"), \n                    data = rpn_cca)\n\n\npar(mfrow = c(2, 2))\nplot(cca.glm)\n\n\n\n\n\nsummary(cca.glm)\n\n\nCall:\nglm(formula = cbind(total_count, failures) ~ location * depth, \n    family = binomial(link = \"logit\"), data = rpn_cca)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)          -2.454e+01  8.145e+03  -0.003    0.998\nlocationse            2.092e+01  8.145e+03   0.003    0.998\nlocationwest         -9.358e-09  1.152e+04   0.000    1.000\ndepthsh              -2.366e-08  1.152e+04   0.000    1.000\nlocationse:depthsh    3.196e-01  1.152e+04   0.000    1.000\nlocationwest:depthsh  2.365e-08  1.629e+04   0.000    1.000\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 44.2469  on 11  degrees of freedom\nResidual deviance:  9.6636  on  6  degrees of freedom\nAIC: 31.936\n\nNumber of Fisher Scoring iterations: 19\n\n\n\nhttps://www.rpubs.com/daharo_calpoly/502695\n\nrpn_cca$groups &lt;- interaction(rpn_cca$location, rpn_cca$depth)"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-9",
    "href": "content/bleaching_results_supp_material.html#create-a-post-hoc-model-9",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Create a post-hoc model",
    "text": "Create a post-hoc model\n\nmodel_cca &lt;- with(rpn_cca, glm(cbind(total_count, failures) ~ groups, family = binomial))"
  },
  {
    "objectID": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-9",
    "href": "content/bleaching_results_supp_material.html#determine-the-post-hoc-comparisons-of-interest-9",
    "title": "Percent Cover and Bleaching in 2015",
    "section": "Determine the post-hoc comparisons of interest",
    "text": "Determine the post-hoc comparisons of interest\n\nsummary(glht(model_cca, \n             linfct = mcp(groups =\n                     #Is the difference between these groups different from zero?\n                     c(\"(north.sh) - (west.sh) = 0\",\n                       \"(north.sh) - (west.dp) = 0\",\n                       \"(north.sh) - (se.sh) = 0\",\n                       \"(north.sh) - (se.dp) = 0\",\n                       \"(north.dp) - (west.sh) = 0\",\n                       \"(north.dp) - (west.dp) = 0\",\n                       \"(north.dp) - (se.sh) = 0\",\n                       \"(north.dp) - (se.dp) = 0\",\n                       \"(se.sh) - (west.sh) = 0\",\n                       \"(se.sh) - (west.dp) = 0\",\n                       \"(se.dp) - (west.sh) = 0\",\n                       \"(se.dp) - (west.dp) = 0\"))),\n        test = adjusted(\"holm\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: glm(formula = cbind(total_count, failures) ~ groups, family = binomial)\n\nLinear Hypotheses:\n                              Estimate Std. Error z value Pr(&gt;|z|)\n(north.sh) - (west.sh) == 0  3.412e-12  1.152e+04   0.000        1\n(north.sh) - (west.dp) == 0  3.501e-15  1.152e+04   0.000        1\n(north.sh) - (se.sh) == 0   -2.124e+01  8.145e+03  -0.003        1\n(north.sh) - (se.dp) == 0   -2.092e+01  8.145e+03  -0.003        1\n(north.dp) - (west.sh) == 0 -1.819e-08  1.152e+04   0.000        1\n(north.dp) - (west.dp) == 0 -1.819e-08  1.152e+04   0.000        1\n(north.dp) - (se.sh) == 0   -2.124e+01  8.145e+03  -0.003        1\n(north.dp) - (se.dp) == 0   -2.092e+01  8.145e+03  -0.003        1\n(se.sh) - (west.sh) == 0     2.124e+01  8.145e+03   0.003        1\n(se.sh) - (west.dp) == 0     2.124e+01  8.145e+03   0.003        1\n(se.dp) - (west.sh) == 0     2.092e+01  8.145e+03   0.003        1\n(se.dp) - (west.dp) == 0     2.092e+01  8.145e+03   0.003        1\n(Adjusted p values reported -- holm method)\n\n\n\nrpn_cca2 &lt;- read.csv('rpn_cover.csv')\n\n\nrpn_cca2\n\n   location depth transect  group total_count total_points\n1     north    dp      one   BARE           0          126\n2     north    dp      one    CCA           0          126\n3     north    dp      one     MA           5          126\n4     north    dp      one   PLOB         104          126\n5     north    dp      one   POCI           7          126\n6     north    dp      one   SAND          10          126\n7     north    dp      one SPONGE           0          126\n8     north    dp      one   TURF           0          126\n9     north    dp      two   BARE           0          126\n10    north    dp      two    CCA           0          126\n11    north    dp      two     MA           7          126\n12    north    dp      two   PLOB         113          126\n13    north    dp      two   POCI           2          126\n14    north    dp      two   SAND           1          126\n15    north    dp      two SPONGE           0          126\n16    north    dp      two   TURF           3          126\n17    north    sh      one   BARE           8          126\n18    north    sh      one    CCA           0          126\n19    north    sh      one     MA           6          126\n20    north    sh      one   PLOB          83          126\n21    north    sh      one   POCI           0          126\n22    north    sh      one   SAND          24          126\n23    north    sh      one SPONGE           0          126\n24    north    sh      one   TURF           5          126\n25    north    sh      two   BARE          10          126\n26    north    sh      two    CCA           0          126\n27    north    sh      two     MA           3          126\n28    north    sh      two   PLOB          88          126\n29    north    sh      two   POCI           1          126\n30    north    sh      two   SAND          23          126\n31    north    sh      two SPONGE           0          126\n32    north    sh      two   TURF           1          126\n33       se    dp      one   BARE          33          124\n34       se    dp      one    CCA           0          124\n35       se    dp      one     MA           0          124\n36       se    dp      one   PLOB          34          124\n37       se    dp      one   POCI          57          124\n38       se    dp      one   SAND           0          124\n39       se    dp      one SPONGE           0          124\n40       se    dp      one   TURF           0          124\n41       se    dp      two   BARE          13          105\n42       se    dp      two    CCA           6          105\n43       se    dp      two     MA           0          105\n44       se    dp      two   PLOB          28          105\n45       se    dp      two   POCI          58          105\n46       se    dp      two   SAND           0          105\n47       se    dp      two SPONGE           0          105\n48       se    dp      two   TURF           0          105\n49       se    sh      one   BARE           9          126\n50       se    sh      one    CCA           4          126\n51       se    sh      one     MA           0          126\n52       se    sh      one   PLOB          35          126\n53       se    sh      one   POCI          75          126\n54       se    sh      one   SAND           0          126\n55       se    sh      one SPONGE           0          126\n56       se    sh      one   TURF           3          126\n57       se    sh      two   BARE          45          126\n58       se    sh      two    CCA           5          126\n59       se    sh      two     MA           1          126\n60       se    sh      two   PLOB          15          126\n61       se    sh      two   POCI          60          126\n62       se    sh      two   SAND           0          126\n63       se    sh      two SPONGE           0          126\n64       se    sh      two   TURF           0          126\n65     west    dp      one   BARE           1          126\n66     west    dp      one    CCA           0          126\n67     west    dp      one     MA          10          126\n68     west    dp      one   PLOB          89          126\n69     west    dp      one   POCI          13          126\n70     west    dp      one   SAND          10          126\n71     west    dp      one SPONGE           0          126\n72     west    dp      one   TURF           3          126\n73     west    dp      two   BARE           4          126\n74     west    dp      two    CCA           0          126\n75     west    dp      two     MA           0          126\n76     west    dp      two   PLOB          73          126\n77     west    dp      two   POCI          14          126\n78     west    dp      two   SAND          31          126\n79     west    dp      two SPONGE           0          126\n80     west    dp      two   TURF           4          126\n81     west    sh      one   BARE           0          126\n82     west    sh      one    CCA           0          126\n83     west    sh      one     MA           5          126\n84     west    sh      one   PLOB          74          126\n85     west    sh      one   POCI          15          126\n86     west    sh      one   SAND          14          126\n87     west    sh      one SPONGE           9          126\n88     west    sh      one   TURF           9          126\n89     west    sh      two   BARE           0          126\n90     west    sh      two    CCA           0          126\n91     west    sh      two     MA           1          126\n92     west    sh      two   PLOB         101          126\n93     west    sh      two   POCI          18          126\n94     west    sh      two   SAND           4          126\n95     west    sh      two SPONGE           0          126\n96     west    sh      two   TURF           2          126\n\n\n\nrpn_cca2 &lt;- read.csv('rpn_cover.csv') %&gt;%\n  as_tibble() %&gt;%\n  filter(group == \"CCA\") %&gt;%\n  mutate_at(vars(location, depth, transect, group), factor) %&gt;%\n  mutate(\n  cover = total_count/total_points,\n  failures = total_points - total_count\n    ) %&gt;%\n  group_by(location, depth) %&gt;%\n  dplyr::summarize(mean = mean(cover), \n                   sd = sd(cover), \n                   n = n(),\n                   se = sd/sqrt(n)\n  ) %&gt;%\n  mutate(se = sd / sqrt(n),\n         lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,\n         upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\n`summarise()` has grouped output by 'location'. You can override using the\n`.groups` argument.\n\n\n\nrpn_cca2\n\n# A tibble: 6 × 8\n# Groups:   location [3]\n  location depth   mean      sd     n      se lower.ci upper.ci\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 north    dp    0      0           2 0         0        0     \n2 north    sh    0      0           2 0         0        0     \n3 se       dp    0.0286 0.0404      2 0.0286   -0.334    0.392 \n4 se       sh    0.0357 0.00561     2 0.00397  -0.0147   0.0861\n5 west     dp    0      0           2 0         0        0     \n6 west     sh    0      0           2 0         0        0     \n\n\n\nrpn_cca3 &lt;-\n  as_tibble(rpn_cca2)\n\n\nrpn_cca_summ &lt;-\n    rpn_cca3 %&gt;%\n    add_column(coast = rep(c('North', 'Southeast', 'West'), each = 2)) %&gt;%\n    add_column(depth2 = rep(c('15 m', '8 m'), times = 3)) %&gt;%\n    mutate_at(vars(coast, depth2), factor)\n\n\nrpn_cca_summ\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0           2 0         0        0      North     15 m  \n2 north    sh    0      0           2 0         0        0      North     8 m   \n3 se       dp    0.0286 0.0404      2 0.0286   -0.334    0.392  Southeast 15 m  \n4 se       sh    0.0357 0.00561     2 0.00397  -0.0147   0.0861 Southeast 8 m   \n5 west     dp    0      0           2 0         0        0      West      15 m  \n6 west     sh    0      0           2 0         0        0      West      8 m   \n\n\n\nrpn_cca_summ.gg &lt;- rpn_cca_summ %&gt;%\n  mutate(coast = factor(coast, levels = c(\"North\", \"West\", \"Southeast\")),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_cca_summ.gg &lt;- rpn_cca_summ %&gt;%\n  mutate(coast = factor(coast, levels = c('North', 'West', 'Southeast')),\n          depth2 = factor(depth2, levels = c('8 m', '15 m')\n                                )\n                )\n\n\nrpn_cca_summ.gg\n\n# A tibble: 6 × 10\n  location depth   mean      sd     n      se lower.ci upper.ci coast     depth2\n  &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; \n1 north    dp    0      0           2 0         0        0      North     15 m  \n2 north    sh    0      0           2 0         0        0      North     8 m   \n3 se       dp    0.0286 0.0404      2 0.0286   -0.334    0.392  Southeast 15 m  \n4 se       sh    0.0357 0.00561     2 0.00397  -0.0147   0.0861 Southeast 8 m   \n5 west     dp    0      0           2 0         0        0      West      15 m  \n6 west     sh    0      0           2 0         0        0      West      8 m   \n\n\n\nx_labels = c(\"North\", \"West\", \"Southeast\")\n\n\nlabel_names = c(\"8 m\" = \"8 m\", \"15 m\" = \"15 m\")\n\n\nrpn_cca_2015.ggbarplot &lt;- ggplot(rpn_cca_summ.gg, aes(x = coast, y = mean, fill = coast)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1)\n\n\nrpn_cca_2015.ggbarplot &lt;- ggplot(rpn_cca_summ.gg, aes(x = factor(coast, x_labels), y = mean, fill = coast)) +   \n  geom_bar(stat = \"identity\", width = 0.75, color = \"black\", linewidth = 0.50, alpha = 0.6) +\n  geom_linerange(aes(ymin = mean, ymax = mean + sd), linewidth = 0.75) +\n  scale_y_continuous(expression(paste(\"Percent Cover\")), limits = c(0, 1.0), \n                     labels = function(x) paste0(x*100)) + \n  scale_x_discrete(expand = c(0, 1), labels = x_labels) + \n  scale_fill_manual(values = c(\"#FFC74E\", \"#82A5C0\", \"#ABC178\")) + #\n  facet_wrap( ~ depth2, labeller = as_labeller(label_names), dir = \"v\", ncol = 1) + \n  #ggtitle(expression(paste(italic(\" ccallopora \"), \"spp.\"))) +\n  #geom_text(aes(label = cld, y = upper.ci), vjust = -0.5, size = 10) +\n  #scale_y_log10(expression(paste(\"Colony Size (\", cm^2, \")\"), limits = c(0, 100000))) +\n  labs(x = NULL) +\n  theme(strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        panel.spacing.x = unit(1, \"cm\"),\n        panel.spacing.y = unit(0.5, \"cm\"),\n        panel.spacing = unit(1, \"lines\"),\n        axis.ticks = element_blank(),\n        legend.position = 'none',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 14),\n        legend.title = element_blank())\n\n\nrpn_cca_2015.ggbarplot\n\n\n\n\n\nrpn_crw &lt;- read_delim('rpn_crw.txt', delim = \" \")\n\nNew names:\n• `` -&gt; `...8`\n• `` -&gt; `...9`\n• `` -&gt; `...10`\n• `` -&gt; `...11`\n• `` -&gt; `...13`\n• `` -&gt; `...14`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 14005 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (3): MM, DD, BAA_7day_max\ndbl (6): YYYY, SST_MIN, SST_MAX, SST, ...11, 90th_HS\nlgl (8):        SSTA    , ...8, ...9, ...10, ...13, ...14, DHW,         \n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n#{r} #rpn_crw.main &lt;- write_csv(rpn_crw, 'rpn_crw.csv') #\n\nrpn_crw.main &lt;- read_csv('rpn_crw.csv')\n\nRows: 14005 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (7): year, month, day, sst_min, sst_max, sst, dhw\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nrpn_crw.main\n\n# A tibble: 14,005 × 7\n    year month   day sst_min sst_max   sst   dhw\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  1985     1     1    24.1    24.2  24.1     0\n 2  1985     1     2    24.2    24.3  24.2     0\n 3  1985     1     3    24.3    24.3  24.3     0\n 4  1985     1     4    24.4    24.4  24.4     0\n 5  1985     1     5    24.5    24.6  24.5     0\n 6  1985     1     6    25.2    25.3  25.3     0\n 7  1985     1     7    25.0    25.2  25.2     0\n 8  1985     1     8    25.7    25.9  25.9     0\n 9  1985     1     9    26      26.2  26.2     0\n10  1985     1    10    26.2    26.3  26.3     0\n# ℹ 13,995 more rows\n\n\n\nrpn_crw.main2 &lt;- \n  rpn_crw.main %&gt;%\n  mutate(date = make_date(year, month, day)) \n\n#%&gt;%\n#  filter(date &gt; 2015-01-01)\n\n\nrpn_crw.main2\n\n# A tibble: 14,005 × 8\n    year month   day sst_min sst_max   sst   dhw date      \n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;    \n 1  1985     1     1    24.1    24.2  24.1     0 1985-01-01\n 2  1985     1     2    24.2    24.3  24.2     0 1985-01-02\n 3  1985     1     3    24.3    24.3  24.3     0 1985-01-03\n 4  1985     1     4    24.4    24.4  24.4     0 1985-01-04\n 5  1985     1     5    24.5    24.6  24.5     0 1985-01-05\n 6  1985     1     6    25.2    25.3  25.3     0 1985-01-06\n 7  1985     1     7    25.0    25.2  25.2     0 1985-01-07\n 8  1985     1     8    25.7    25.9  25.9     0 1985-01-08\n 9  1985     1     9    26      26.2  26.2     0 1985-01-09\n10  1985     1    10    26.2    26.3  26.3     0 1985-01-10\n# ℹ 13,995 more rows\n\n\n\nrpn_crw.main3 &lt;- \n  rpn_crw.main2 %&gt;%\n  filter(date &gt;= '2014-01-01',\n         date &lt;= '2015-12-31') %&gt;% \n  dplyr::select(sst_max, dhw, date) %&gt;%\n  pivot_longer(!date, names_to = \"metric\", values_to = \"value\")\n\n\nrpn_crw.main3\n\n# A tibble: 1,460 × 3\n   date       metric  value\n   &lt;date&gt;     &lt;chr&gt;   &lt;dbl&gt;\n 1 2014-01-01 sst_max  24.3\n 2 2014-01-01 dhw       0  \n 3 2014-01-02 sst_max  23.9\n 4 2014-01-02 dhw       0  \n 5 2014-01-03 sst_max  23.8\n 6 2014-01-03 dhw       0  \n 7 2014-01-04 sst_max  23.7\n 8 2014-01-04 dhw       0  \n 9 2014-01-05 sst_max  23.8\n10 2014-01-05 dhw       0  \n# ℹ 1,450 more rows\n\n\n\nrpn_crw.main4 &lt;- \n  rpn_crw.main3 %&gt;%\n  pivot_wider(names_from = metric, values_from = value)\n\n\nrpn_crw.main4\n\n# A tibble: 730 × 3\n   date       sst_max   dhw\n   &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 2014-01-01    24.3     0\n 2 2014-01-02    23.9     0\n 3 2014-01-03    23.8     0\n 4 2014-01-04    23.7     0\n 5 2014-01-05    23.8     0\n 6 2014-01-06    24.0     0\n 7 2014-01-07    24.2     0\n 8 2014-01-08    24.4     0\n 9 2014-01-09    24.4     0\n10 2014-01-10    24.4     0\n# ℹ 720 more rows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create long labels to be wrapped\niris$Species = paste(iris$Species, \n                     \"random text to make the labels much much longer than the original labels\")\n\n\nrpn_crw.main.gg &lt;- ggplot(data = rpn_crw.main4, aes(x = date, y = sst_max)) +\n  geom_line(aes(color = \"SST Max (°C)\")) +\n#  ylim(0, 30) +\n#  scale_fill_discrete(name = \"Dose\", labels = c(\"A\", \"B\")) +\n  geom_line(aes(y = dhw, color = \"Degree Heating Week\")) +\n  scale_y_continuous(limits = c(0, 30), breaks = c(0, 5, 10, 15, 20, 25, 30)) +\n  #scale_x_continuous(breaks = seq(0, 336, 24)) +\n  scale_x_date(date_labels = \"%b %y\") +\n  scale_color_manual(values = c(\"red2\", \"blue\"))+\n  labs(x = NULL) +\n  theme(#strip.text = element_text(size = 10, color = \"black\", hjust = 0.50),\n        #strip.background = element_rect(fill = \"#FFFFFF\", color = NA),    \n        panel.background = element_rect(fill = \"#FFFFFF\", color = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.y = element_line(color = \"#b2b2b2\"),\n        #panel.spacing.x = unit(1, \"cm\"),\n        #panel.spacing.y = unit(0.5, \"cm\"),\n        #panel.spacing = unit(1, \"lines\"),\n        axis.ticks.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        legend.position = 'right',\n        #plot.title = element_text(size = 11),\n        axis.text.y = element_text(size = 10),\n        #axis.text.x = element_text(size = 12),\n        axis.text.x = element_text(angle = 60, hjust = 0.25, size = 8),\n        axis.title.y = element_blank(),\n        legend.title = element_blank())\n\n\nrpn_crw.main.gg\n\n\n\n\n\nscale = 0.25\n\n\npkpd &lt;- ggplot(data = rpn_crw.main4, aes(x = date, y = sst_max)) +\n#  scale_y_continuous(breaks = c(5, 5), limits = c(0, 50)) +\n#  ylim(0, 40) +\n  geom_line(aes(color = \"Maximum Sea Surface Temperature\")) +\n  geom_line(aes(y = dhw * scale, color = \"Degree Heating Week\"))+\n#  scale_x_continuous(breaks = seq(0, 336, 24)) +\n  scale_y_continuous(sec.axis = sec_axis(~.*scale, name = \"DHW\")) +\n  labs(x = \"Date\", y = \"SST Max (C)\", color = \"\") +\n  scale_color_manual(values = c(\"orange2\", \"gray50\"))\n\nprint(pkpd)\n\n\n\n\n\n#-----------------------------------------------------------------------------\n# Rescale the second y axis by \n#   - subtracting its minimum value (to set it to start at 0)\n#   - scaling so that it has the same range as the 'y1' variable\n#   - offsettting it by the minimum value of y1\n#-----------------------------------------------------------------------------\na            &lt;- range(rpn_crw.main4[['sst_max']])\n\n\na\n\n[1] 19.39 26.99\n\n\n\nb            &lt;- range(rpn_crw.main4[['dhw']])\n\n\nscale_factor &lt;- diff(a)/diff(b)\n\n\nrpn_crw.main4[['sst_max']]      &lt;- ((rpn_crw.main4[['sst_max']] - b[1]) * scale_factor) + a[1]\n\n\n#-----------------------------------------------------------------------------\n# Need to define the second axis transformation to be the inverse of the data\n# transformation to everything cancels out appropriately\n#-----------------------------------------------------------------------------\ntrans &lt;- ~ ((. - a[1]) / scale_factor) + b[1]\n\n\npkpd &lt;- ggplot(data = rpn_crw.main4, aes(x = date, y = sst_max)) +\n#  scale_y_continuous(breaks = c(5, 5), limits = c(0, 50)) +\n#  ylim(0, 40) +\n  geom_line(aes(color = \"Maximum Sea Surface Temperature\")) +\n  geom_line(aes(y = dhw * scale, color = \"Degree Heating Week\"))+\n#  scale_x_continuous(breaks = seq(0, 336, 24)) +\n  scale_y_continuous(sec.axis = sec_axis(trans = trans, name = 'dhw'), \n                     breaks = c(0, 500)) +\n  labs(x = \"Date\", y = \"SST Max (C)\", color = \"\") +\n  scale_color_manual(values = c(\"orange2\", \"gray50\"))\n\nprint(pkpd)\n\n\n\n\n\nmy_data &lt;- read_tsv(\"https://coralreefwatch.noaa.gov/product/vs/data/easter_island.txt\")\n\nRows: 14229 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): Name:\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhead(my_data)\n\n# A tibble: 6 × 1\n  `Name:`                       \n  &lt;chr&gt;                         \n1 Easter Island, Chile          \n2 Polygon Middle Longitude:     \n3 -109.3250                     \n4 Polygon Middle Latitude:      \n5 -27.1750                      \n6 Averaged Maximum Monthly Mean:\n\n\n\nwrite_csv(rpn_crw, \".csv\")"
  },
  {
    "objectID": "content/add-content.html",
    "href": "content/add-content.html",
    "title": "Customize",
    "section": "",
    "text": "Edit the qmd or md files in the content folder. qmd files can include code (R, Python, Julia) and lots of Quarto markdown bells and whistles (like call-outs, cross-references, auto-citations and much more).\nEach page should start with\n---\ntitle: your title\n---\nand the first header will be the 2nd level, so ##. Note, there are situations where you leave off\n---\ntitle: your title\n---\nand start the qmd file with a level header #, but if using the default title yaml (in the --- fence) is a good habit since it makes it easy for Quarto convert your qmd file to other formats (like into a presentation)."
  },
  {
    "objectID": "content/add-content.html#edit-and-add-your-pages",
    "href": "content/add-content.html#edit-and-add-your-pages",
    "title": "Customize",
    "section": "",
    "text": "Edit the qmd or md files in the content folder. qmd files can include code (R, Python, Julia) and lots of Quarto markdown bells and whistles (like call-outs, cross-references, auto-citations and much more).\nEach page should start with\n---\ntitle: your title\n---\nand the first header will be the 2nd level, so ##. Note, there are situations where you leave off\n---\ntitle: your title\n---\nand start the qmd file with a level header #, but if using the default title yaml (in the --- fence) is a good habit since it makes it easy for Quarto convert your qmd file to other formats (like into a presentation)."
  },
  {
    "objectID": "content/add-content.html#add-your-pages-the-project",
    "href": "content/add-content.html#add-your-pages-the-project",
    "title": "Customize",
    "section": "Add your pages the project",
    "text": "Add your pages the project\n\nAdd the files to _quarto.yml"
  }
]